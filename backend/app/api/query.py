"""
æ™ºèƒ½é—®ç­”API
"""

import logging
import time
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, HTTPException, Query as QueryParam
from sqlalchemy.orm import Session
from datetime import datetime
from typing import List, Optional

from app.db.init_db import get_db_session
from app.models.schemas import (
    QueryRequest, QueryResponse, Citation,
    TokenStats, Confidence, ModelType, StreamMessage, QueryStage
)
from app.services.rag_engine import get_rag_engine
from app.core.error_handlers import NovelNotFoundError
from app.models.database import Novel, Query

router = APIRouter(prefix="/api/query", tags=["æ™ºèƒ½é—®ç­”"])
logger = logging.getLogger(__name__)


@router.post("", response_model=QueryResponse, summary="éæµå¼æŸ¥è¯¢")
async def query_novel(
    request: QueryRequest,
    db: Session = Depends(get_db_session)
):
    """
    éæµå¼æ™ºèƒ½é—®ç­”
    
    - åŸºç¡€RAGæ£€ç´¢
    - å®Œæ•´ç­”æ¡ˆè¿”å›
    - åŒ…å«å¼•ç”¨å’Œç»Ÿè®¡ä¿¡æ¯
    """
    start_time = time.time()
    
    try:
        # éªŒè¯å°è¯´æ˜¯å¦å­˜åœ¨
        novel = db.query(Novel).filter(Novel.id == request.novel_id).first()
        if not novel:
            raise NovelNotFoundError(request.novel_id)
        
        # Tokenè®¡æ•°å™¨
        from app.utils.token_counter import get_token_counter
        token_counter = get_token_counter()
        
        # ç»Ÿè®¡Embedding tokens
        embedding_tokens = token_counter.count_tokens(request.query)
        
        # æ‰§è¡ŒRAGæŸ¥è¯¢
        rag_engine = get_rag_engine()
        answer, citations, stats = rag_engine.query(
            db=db,
            novel_id=request.novel_id,
            query=request.query,
            model=request.model.value
        )
        
        # ç»Ÿè®¡Promptå’ŒCompletion tokens
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ä¼°ç®—ï¼Œå› ä¸ºéæµå¼æ¥å£ä¸è¿”å›å®é™…çš„usageä¿¡æ¯
        # å¯ä»¥é€šè¿‡é‡æ–°æ„å»ºpromptæ¥è®¡ç®—ï¼Œæˆ–è€…ä¼°ç®—
        query_embedding = rag_engine.query_embedding(request.query)
        vector_results = rag_engine.vector_search(request.novel_id, query_embedding)
        reranked_chunks = rag_engine.rerank(request.query, vector_results, None)
        
        # æ„å»ºpromptç”¨äºè®¡ç®—tokens
        prompt = rag_engine.build_prompt(db, request.novel_id, request.query, reranked_chunks)
        prompt_tokens = token_counter.count_tokens(prompt)
        completion_tokens = token_counter.count_tokens(answer)
        
        total_tokens = embedding_tokens + prompt_tokens + completion_tokens
        
        response_time = time.time() - start_time
        
        # ä¿å­˜æŸ¥è¯¢å†å²
        query_record = Query(
            novel_id=request.novel_id,
            query_text=request.query,
            answer_text=answer,
            model_used=request.model.value,
            response_time=response_time,
            total_tokens=total_tokens
        )
        db.add(query_record)
        db.commit()
        db.refresh(query_record)
        
        # è®°å½•Tokenä½¿ç”¨ç»Ÿè®¡
        try:
            from app.services.token_stats_service import get_token_stats_service
            token_stats_service = get_token_stats_service()
            
            # Embedding-3ä½¿ç”¨è®°å½•
            token_stats_service.record_token_usage(
                db=db,
                operation_type='query',
                operation_id=query_record.id,
                model_name='embedding-3',
                input_tokens=embedding_tokens,
                output_tokens=0
            )
            
            # LLMæ¨¡å‹ä½¿ç”¨è®°å½•
            token_stats_service.record_token_usage(
                db=db,
                operation_type='query',
                operation_id=query_record.id,
                model_name=request.model.value,
                input_tokens=prompt_tokens,
                output_tokens=completion_tokens
            )
        except Exception as e:
            logger.warning(f"âš ï¸ Tokenç»Ÿè®¡è®°å½•å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
        
        # æ„å»ºè¯¦ç»†çš„TokenStatså¯¹è±¡ï¼ˆåŒ…å«é˜¶æ®µç»Ÿè®¡ï¼‰
        by_stage = [
            {
                'stage': 'retrieving',
                'model': 'embedding-3',
                'inputTokens': embedding_tokens,
                'outputTokens': 0,
                'totalTokens': embedding_tokens
            },
            {
                'stage': 'generating',
                'model': request.model.value,
                'inputTokens': prompt_tokens,
                'outputTokens': completion_tokens,
                'totalTokens': prompt_tokens + completion_tokens
            }
        ]
        
        token_stats_obj = TokenStats(
            total_tokens=total_tokens,
            input_tokens=embedding_tokens + prompt_tokens,
            output_tokens=completion_tokens,
            embedding_tokens=embedding_tokens,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            by_model={
                'embedding-3': {
                    'inputTokens': embedding_tokens
                },
                request.model.value: {
                    'promptTokens': prompt_tokens,
                    'completionTokens': completion_tokens,
                    'totalTokens': prompt_tokens + completion_tokens
                }
            },
            by_stage=by_stage
        )
        
        # æ„å»ºå“åº”
        return QueryResponse(
            query_id=query_record.id,
            answer=answer,
            citations=citations,
            token_stats=token_stats_obj,
            response_time=response_time,
            confidence=Confidence.MEDIUM,  # TODO: è®¡ç®—ç½®ä¿¡åº¦
            model=request.model.value,
            timestamp=datetime.now().isoformat()
        )
        
    except NovelNotFoundError:
        raise
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.websocket("/stream")
async def query_stream(websocket: WebSocket):
    """
    æµå¼æ™ºèƒ½é—®ç­” WebSocket
    
    æ¥æ”¶: {"novel_id": 1, "query": "xxx", "model": "glm-4"}
    å‘é€: {"stage": "xxx", "content": "xxx", "progress": 0.5}
    """
    await websocket.accept()
    logger.info("ğŸ”Œ WebSocketè¿æ¥å·²å»ºç«‹")
    
    try:
        # æ¥æ”¶æŸ¥è¯¢è¯·æ±‚
        data = await websocket.receive_json()
        novel_id = data.get('novel_id')
        query = data.get('query')
        model = data.get('model', 'glm-4')
        
        if not novel_id or not query:
            await websocket.send_json({
                'error': 'ç¼ºå°‘å¿…è¦å‚æ•°: novel_id æˆ– query'
            })
            await websocket.close()
            return
        
        # è·å–æ•°æ®åº“ä¼šè¯
        from app.db.init_db import get_database_url
        from sqlalchemy import create_engine
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(get_database_url())
        SessionLocal = sessionmaker(bind=engine)
        db = SessionLocal()
        
        try:
            # éªŒè¯å°è¯´å­˜åœ¨
            novel = db.query(Novel).filter(Novel.id == novel_id).first()
            if not novel:
                await websocket.send_json({
                    'error': f'å°è¯´ ID={novel_id} ä¸å­˜åœ¨'
                })
                await websocket.close()
                return
            
            # é˜¶æ®µ1: æŸ¥è¯¢ç†è§£
            await websocket.send_json(StreamMessage(
                stage=QueryStage.UNDERSTANDING,
                content="æ­£åœ¨ç†è§£æ‚¨çš„é—®é¢˜...",
                progress=0.1
            ).model_dump())
            
            rag_engine = get_rag_engine()
            
            # é˜¶æ®µ2: æ£€ç´¢ä¸Šä¸‹æ–‡
            await websocket.send_json(StreamMessage(
                stage=QueryStage.RETRIEVING,
                content="æ­£åœ¨æ£€ç´¢ç›¸å…³å†…å®¹...",
                progress=0.3
            ).model_dump())
            
            # Tokenç»Ÿè®¡åˆå§‹åŒ–
            from app.services.token_stats_service import get_token_stats_service
            token_stats_service = get_token_stats_service()
            
            embedding_tokens = 0
            prompt_tokens = 0
            completion_tokens = 0
            
            # æŸ¥è¯¢å‘é‡åŒ–ï¼ˆç»Ÿè®¡Embedding tokensï¼‰
            from app.utils.token_counter import get_token_counter
            token_counter = get_token_counter()
            embedding_tokens += token_counter.count_tokens(query)
            
            query_embedding = rag_engine.query_embedding(query)
            
            # è¯­ä¹‰æ£€ç´¢
            vector_results = rag_engine.vector_search(novel_id, query_embedding)
            
            # Rerankï¼ˆå¸¦GraphRAGå¢å¼ºï¼‰
            reranked_chunks = rag_engine.rerank(
                query=query,
                vector_results=vector_results,
                novel_id=novel_id,
                db=db
            )
            
            if not reranked_chunks:
                await websocket.send_json({
                    'stage': 'finalizing',
                    'content': 'æŠ±æ­‰ï¼Œåœ¨å°è¯´ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚',
                    'progress': 1.0,
                    'done': True
                })
                await websocket.close()
                return
            
            # âœ¨ æ£€ç´¢å®Œæˆåç«‹å³æ„å»ºå¹¶å‘é€å¼•ç”¨åˆ—è¡¨
            logger.info("ğŸ“š æ£€ç´¢å®Œæˆï¼Œæ„å»ºå¼•ç”¨åˆ—è¡¨...")
            citations = []
            seen_chapters = set()
            
            for chunk in reranked_chunks[:5]:  # åªè¿”å›å‰5æ¡å¼•ç”¨
                metadata = chunk['metadata']
                chapter_num = metadata.get('chapter_num')
                
                if chapter_num in seen_chapters:
                    continue
                seen_chapters.add(chapter_num)
                
                # è·å–ç« èŠ‚æ ‡é¢˜ï¼Œå¦‚æœmetadataä¸­æ²¡æœ‰ï¼Œä»æ•°æ®åº“æŸ¥è¯¢
                chapter_title = metadata.get('chapter_title')
                if not chapter_title and chapter_num:
                    try:
                        from app.models.database import Chapter
                        chapter = db.query(Chapter).filter(
                            Chapter.novel_id == novel_id,
                            Chapter.num == chapter_num
                        ).first()
                        if chapter:
                            chapter_title = chapter.title
                    except Exception as e:
                        logger.warning(f"è·å–ç« èŠ‚æ ‡é¢˜å¤±è´¥: {e}")
                
                citations.append({
                    'chapter_num': chapter_num,
                    'chapter_title': chapter_title,
                    'text': chunk['content'][:200] + "...",
                    'score': chunk.get('score')
                })
            
            # å‘é€åŒ…å«å¼•ç”¨çš„æ£€ç´¢å®Œæˆæ¶ˆæ¯
            logger.info(f"ğŸ“¤ å‘é€å¼•ç”¨åˆ—è¡¨: {len(citations)} æ¡")
            await websocket.send_json({
                'stage': 'retrieving',
                'content': f"æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(citations)} ä¸ªç›¸å…³ç« èŠ‚",
                'progress': 0.4,
                'citations': citations
            })
            
            # é˜¶æ®µ3: ç”Ÿæˆç­”æ¡ˆ
            await websocket.send_json(StreamMessage(
                stage=QueryStage.GENERATING,
                content="",
                progress=0.5
            ).model_dump())
            
            # æ„å»ºPrompt
            prompt = rag_engine.build_prompt(db, novel_id, query, reranked_chunks)
            
            # æµå¼ç”Ÿæˆç­”æ¡ˆ
            full_answer = ""
            generation_usage = None
            finish_reason = None
            
            logger.info("ğŸ”„ å¼€å§‹æµå¼ç”Ÿæˆç­”æ¡ˆ...")
            
            for chunk_data in rag_engine.generate_answer_with_stats(prompt, model, stream=True):
                # chunk_dataå¯èƒ½åŒ…å«contentã€thinkingå’Œusage
                if isinstance(chunk_data, dict):
                    chunk = chunk_data.get('content', '')
                    thinking_chunk = chunk_data.get('reasoning_content')  # æå–thinkingå†…å®¹
                    usage = chunk_data.get('usage')
                    finish_reason_value = chunk_data.get('finish_reason')
                    
                    if usage:
                        # ä¿å­˜æœ€åçš„usageä¿¡æ¯
                        generation_usage = usage
                        logger.info(f"ğŸ’¡ [WebSocket] æ”¶åˆ°usage: {usage}")
                    
                    if finish_reason_value:
                        finish_reason = finish_reason_value
                        logger.info(f"ğŸ [WebSocket] æ”¶åˆ°finish_reason: {finish_reason}")
                else:
                    # å‘åå…¼å®¹ï¼šçº¯æ–‡æœ¬chunk
                    chunk = chunk_data if chunk_data else ''
                    thinking_chunk = None
                
                # å‘é€thinkingå†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if thinking_chunk:
                    await websocket.send_json({
                        'stage': 'generating',
                        'thinking': thinking_chunk,  # å‘é€thinkingå¢é‡å†…å®¹
                        'content': '',
                        'progress': 0.6,
                        'is_delta': True
                    })
                
                # å‘é€ç­”æ¡ˆå†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if chunk:
                    full_answer += chunk
                    await websocket.send_json({
                        'stage': 'generating',
                        'content': chunk,  # å‘é€å¢é‡å†…å®¹
                        'progress': 0.7,
                        'is_delta': True
                    })
            
            logger.info(f"âœ… æµå¼ç”Ÿæˆå®Œæˆï¼Œç­”æ¡ˆé•¿åº¦: {len(full_answer)}, æ˜¯å¦æœ‰usage: {generation_usage is not None}")
            
            # ä»generation_usageä¸­æå–Tokenç»Ÿè®¡
            if generation_usage:
                prompt_tokens = generation_usage.get('prompt_tokens', 0)
                completion_tokens = generation_usage.get('completion_tokens', 0)
                logger.info(f"âœ… ä½¿ç”¨APIè¿”å›çš„Tokenç»Ÿè®¡: prompt={prompt_tokens}, completion={completion_tokens}")
            else:
                # å¦‚æœæ²¡æœ‰ä»APIè·å–åˆ°usageï¼Œä½¿ç”¨ä¼°ç®—
                logger.warning("âš ï¸ APIæœªè¿”å›usageä¿¡æ¯ï¼Œä½¿ç”¨Tokenè®¡æ•°å™¨ä¼°ç®—")
                prompt_tokens = token_counter.count_tokens(prompt)
                completion_tokens = token_counter.count_tokens(full_answer)
                logger.info(f"ğŸ“Š ä¼°ç®—Tokenæ•°: prompt={prompt_tokens}, completion={completion_tokens}")
            
            # é˜¶æ®µ4: Self-RAGéªŒè¯
            # æ³¨æ„ï¼šä¸å‘é€ contentï¼Œé¿å…è¦†ç›–ä¹‹å‰çš„ç­”æ¡ˆ
            await websocket.send_json({
                'stage': 'validating',
                'progress': 0.8,
                'metadata': {'message': 'æ­£åœ¨éªŒè¯ç­”æ¡ˆå‡†ç¡®æ€§...'}
            })
            
            # Self-RAGéªŒè¯æµç¨‹
            from app.services.self_rag import (
                get_assertion_extractor,
                get_evidence_collector,
                get_evidence_scorer,
                get_consistency_checker,
                get_contradiction_detector,
                get_answer_corrector
            )
            
            contradictions_list = []
            confidence_level = "high"
            corrected_answer = full_answer
            
            try:
                # 1. æå–æ–­è¨€
                assertion_extractor = get_assertion_extractor()
                assertions = assertion_extractor.extract_assertions(full_answer)
                logger.info(f"âœ… æå–æ–­è¨€: {len(assertions)} ä¸ª")
                
                if assertions:
                    # 2. æ”¶é›†è¯æ®
                    evidence_collector = get_evidence_collector()
                    evidence_map = {}
                    
                    for idx, assertion in enumerate(assertions):
                        evidence_list = evidence_collector.collect_evidence_for_assertion(
                            db, novel_id, assertion, top_k=3
                        )
                        evidence_map[idx] = evidence_list
                    
                    logger.info(f"âœ… æ”¶é›†è¯æ®å®Œæˆ")
                    
                    # 3. è¯„åˆ†è¯æ®
                    evidence_scorer = get_evidence_scorer()
                    for idx, assertion in enumerate(assertions):
                        evidence_list = evidence_map.get(idx, [])
                        # å¯¹æ¯æ¡è¯æ®è¿›è¡Œè¯„åˆ†
                        scored_evidence_list = []
                        for evidence in evidence_list:
                            scored = evidence_scorer.score_evidence(
                                db=db,
                                novel_id=novel_id,
                                evidence=evidence,
                                query_context={'assertion': assertion}
                            )
                            # å°†è¯„åˆ†ä¿¡æ¯æ·»åŠ åˆ°è¯æ®ä¸­
                            evidence['score'] = scored
                            scored_evidence_list.append(evidence)
                        evidence_map[idx] = scored_evidence_list
                    
                    # 4. ä¸€è‡´æ€§æ£€æŸ¥
                    consistency_checker = get_consistency_checker()
                    
                    # 4.1 æ—¶åºä¸€è‡´æ€§æ£€æŸ¥
                    temporal_issues = consistency_checker.check_temporal_consistency(
                        assertions, evidence_map
                    )
                    
                    # 4.2 è§’è‰²ä¸€è‡´æ€§æ£€æŸ¥
                    character_issues = consistency_checker.check_character_consistency(
                        db, novel_id, assertions, evidence_map
                    )
                    
                    # åˆå¹¶ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ
                    consistency_report = {
                        'temporal_issues': temporal_issues,
                        'character_issues': character_issues,
                        'total_issues': len(temporal_issues) + len(character_issues)
                    }
                    
                    logger.info(f"âœ… ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆ: {consistency_report['total_issues']} ä¸ªé—®é¢˜")
                    
                    # 5. æ£€æµ‹çŸ›ç›¾
                    contradiction_detector = get_contradiction_detector()
                    contradictions = contradiction_detector.detect_contradictions(
                        db, novel_id, assertions, evidence_map, consistency_report
                    )
                    
                    # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸åˆ—è¡¨
                    contradictions_list = [
                        {
                            'type': c.type,
                            'earlyDescription': c.early_description,
                            'earlyChapter': c.early_chapter,
                            'lateDescription': c.late_description,
                            'lateChapter': c.late_chapter,
                            'analysis': c.analysis,
                            'confidence': c.confidence
                        }
                        for c in contradictions
                    ]
                    
                    logger.info(f"âœ… æ£€æµ‹åˆ°çŸ›ç›¾: {len(contradictions_list)} ä¸ª")
                    
                    # 6. ä¿®æ­£ç­”æ¡ˆ
                    if contradictions:
                        answer_corrector = get_answer_corrector()
                        correction_result = answer_corrector.correct_answer(
                            full_answer, contradictions, "high"
                        )
                        corrected_answer = correction_result.get('corrected_answer', full_answer)
                        confidence_level = correction_result.get('final_confidence', 'high')
                        
                        logger.info(f"âœ… ç­”æ¡ˆä¿®æ­£å®Œæˆï¼Œç½®ä¿¡åº¦: {confidence_level}")
                
            except Exception as e:
                logger.error(f"âš ï¸ Self-RAGéªŒè¯å¤±è´¥: {e}")
                # Self-RAGå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­è¿”å›åŸç­”æ¡ˆ
            
            # é˜¶æ®µ5: å®Œæˆæ±‡æ€»
            logger.info("ğŸ“‹ å¼€å§‹æ„å»ºæœ€ç»ˆç»“æœ...")
            # æ³¨æ„ï¼šä¸å‘é€ contentï¼Œé¿å…è¦†ç›–ä¹‹å‰çš„ç­”æ¡ˆ
            await websocket.send_json({
                'stage': 'finalizing',
                'progress': 0.9,
                'metadata': {'message': 'æ­£åœ¨æ•´ç†ç»“æœ...'}  # çŠ¶æ€ä¿¡æ¯æ”¾åœ¨ metadata ä¸­
            })
            
            # è®¡ç®—æ€»Tokenæ¶ˆè€—
            total_tokens = embedding_tokens + prompt_tokens + completion_tokens
            
            # æ„å»ºè¯¦ç»†çš„Tokenç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ…å«é˜¶æ®µçº§åˆ«ç»Ÿè®¡ï¼‰
            by_stage = [
                {
                    'stage': 'retrieving',
                    'model': 'embedding-3',
                    'inputTokens': embedding_tokens,
                    'outputTokens': 0,
                    'totalTokens': embedding_tokens
                },
                {
                    'stage': 'generating',
                    'model': model,
                    'inputTokens': prompt_tokens,
                    'outputTokens': completion_tokens,
                    'totalTokens': prompt_tokens + completion_tokens
                }
            ]
            
            token_stats = {
                'totalTokens': total_tokens,
                'inputTokens': embedding_tokens + prompt_tokens,
                'outputTokens': completion_tokens,
                'byModel': {
                    'embedding-3': {
                        'inputTokens': embedding_tokens,
                        'stage': 'retrieving'
                    },
                    model: {
                        'inputTokens': prompt_tokens,
                        'completionTokens': completion_tokens,
                        'totalTokens': prompt_tokens + completion_tokens,
                        'stage': 'generating'
                    }
                },
                'byStage': by_stage
            }
            
            logger.info(f"âœ… Tokenç»Ÿè®¡: æ€»è®¡ {total_tokens} tokens")
            logger.info(f"ğŸ’¾ ä¿å­˜æŸ¥è¯¢è®°å½•åˆ°æ•°æ®åº“...")
            
            # ä¿å­˜æŸ¥è¯¢å†å²ï¼ˆä½¿ç”¨ä¿®æ­£åçš„ç­”æ¡ˆï¼‰
            query_record = Query(
                novel_id=novel_id,
                query_text=query,
                answer_text=corrected_answer,
                model_used=model,
                response_time=0.0,  # WebSocketä¸ç»Ÿè®¡æ€»æ—¶é—´
                confidence=confidence_level,  # ä¿å­˜ç½®ä¿¡åº¦
                total_tokens=total_tokens  # ä¿å­˜Tokenæ¶ˆè€—
            )
            db.add(query_record)
            db.commit()
            db.refresh(query_record)
            logger.info(f"âœ… æŸ¥è¯¢è®°å½•å·²ä¿å­˜ï¼Œquery_id={query_record.id}")
            
            # è®°å½•Tokenä½¿ç”¨æƒ…å†µåˆ°ç»Ÿè®¡è¡¨
            try:
                # Embedding-3ä½¿ç”¨è®°å½•
                if embedding_tokens > 0:
                    token_stats_service.record_token_usage(
                        db=db,
                        operation_type='query',
                        operation_id=query_record.id,
                        model_name='embedding-3',
                        input_tokens=embedding_tokens,
                        output_tokens=0
                    )
                
                # GLMæ¨¡å‹ä½¿ç”¨è®°å½•
                if prompt_tokens > 0 or completion_tokens > 0:
                    token_stats_service.record_token_usage(
                        db=db,
                        operation_type='query',
                        operation_id=query_record.id,
                        model_name=model,
                        input_tokens=prompt_tokens,
                        output_tokens=completion_tokens
                    )
            except Exception as e:
                logger.warning(f"âš ï¸ Tokenç»Ÿè®¡è®°å½•å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # å‘é€æœ€ç»ˆç»“æœï¼ˆåŒ…å«query_idå’Œå®Œæ•´tokenç»Ÿè®¡ï¼‰
            # æ³¨æ„ï¼šcitations å·²åœ¨ retrieving é˜¶æ®µå‘é€ï¼Œè¿™é‡Œä¸å†é‡å¤å‘é€
            final_message = {
                'stage': 'finalizing',
                'content': corrected_answer,
                'progress': 1.0,
                'done': True,
                'contradictions': contradictions_list,
                'confidence': confidence_level,
                'query_id': query_record.id,
                'original_answer': full_answer if corrected_answer != full_answer else None,
                'metadata': {
                    'token_stats': token_stats  # ä½¿ç”¨å®Œæ•´çš„tokenç»Ÿè®¡ä¿¡æ¯
                }
            }
            
            logger.info(f"ğŸ“¤ å‡†å¤‡å‘é€æœ€ç»ˆæ¶ˆæ¯: query_id={query_record.id}, done=True, answer_length={len(corrected_answer)}")
            await websocket.send_json(final_message)
            logger.info(f"âœ… æµå¼æŸ¥è¯¢å®Œæˆï¼Œæœ€ç»ˆæ¶ˆæ¯å·²å‘é€")
            
        finally:
            db.close()
        
    except WebSocketDisconnect:
        logger.info("ğŸ”Œ WebSocketè¿æ¥å·²æ–­å¼€")
    except Exception as e:
        logger.error(f"âŒ æµå¼æŸ¥è¯¢å¤±è´¥: {e}")
        try:
            await websocket.send_json({
                'error': f'æŸ¥è¯¢å¤±è´¥: {str(e)}'
            })
        except:
            pass
    finally:
        try:
            await websocket.close()
        except:
            pass


@router.get("/{query_id}/token-stats", response_model=TokenStats, summary="è·å–æŸ¥è¯¢Tokenç»Ÿè®¡")
async def get_query_token_stats(
    query_id: int,
    db: Session = Depends(get_db_session)
):
    """
    è·å–æŒ‡å®šæŸ¥è¯¢çš„Tokenæ¶ˆè€—ç»Ÿè®¡
    
    - ä»token_statsè¡¨æŸ¥è¯¢å¹¶èšåˆ
    - æŒ‰æ¨¡å‹åˆ†ç»„ç»Ÿè®¡
    - è¿”å›è¯¦ç»†çš„Tokenæ¶ˆè€—ä¿¡æ¯
    """
    try:
        from app.models.database import TokenStat
        
        # æŸ¥è¯¢è¯¥queryçš„æ‰€æœ‰tokenç»Ÿè®¡è®°å½•
        stats_records = db.query(TokenStat).filter(
            TokenStat.operation_type == 'query',
            TokenStat.operation_id == query_id
        ).all()
        
        if not stats_records:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°Tokenç»Ÿè®¡è®°å½•")
        
        # æŒ‰æ¨¡å‹èšåˆ
        by_model = {}
        total_tokens = 0
        
        for record in stats_records:
            model_name = record.model_name
            
            if model_name not in by_model:
                by_model[model_name] = {}
            
            # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®ä¸åŒçš„å­—æ®µ
            if 'embedding' in model_name.lower():
                # Embeddingæ¨¡å‹åªæœ‰input_tokens
                by_model[model_name]['inputTokens'] = record.input_tokens or 0
            else:
                # LLMæ¨¡å‹æœ‰promptå’Œcompletion
                by_model[model_name]['promptTokens'] = record.prompt_tokens or 0
                by_model[model_name]['completionTokens'] = record.completion_tokens or 0
                by_model[model_name]['totalTokens'] = record.total_tokens or 0
            
            total_tokens += record.total_tokens or 0
        
        logger.info(f"âœ… è·å–æŸ¥è¯¢#{query_id}çš„Tokenç»Ÿè®¡: {total_tokens} tokens")
        
        return TokenStats(
            total_tokens=total_tokens,
            by_model=by_model
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–Tokenç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–Tokenç»Ÿè®¡å¤±è´¥: {str(e)}")


@router.get("/history", summary="è·å–æŸ¥è¯¢å†å²")
async def get_query_history(
    novel_id: Optional[int] = QueryParam(None, description="æŒ‰å°è¯´IDè¿‡æ»¤"),
    page: int = QueryParam(1, ge=1, description="é¡µç "),
    page_size: int = QueryParam(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    db: Session = Depends(get_db_session)
):
    """
    è·å–æŸ¥è¯¢å†å²
    
    - æ”¯æŒåˆ†é¡µ
    - æ”¯æŒæŒ‰å°è¯´IDè¿‡æ»¤
    - æŒ‰æ—¶é—´å€’åºæ’åˆ—
    """
    try:
        # æ„å»ºæŸ¥è¯¢
        query = db.query(Query)
        
        if novel_id:
            query = query.filter(Query.novel_id == novel_id)
        
        # è®¡ç®—æ€»æ•°
        total = query.count()
        
        # åˆ†é¡µæŸ¥è¯¢
        offset = (page - 1) * page_size
        queries = query.order_by(Query.created_at.desc()).offset(offset).limit(page_size).all()
        
        # æ„å»ºå“åº”
        items = []
        for q in queries:
            items.append({
                "id": q.id,
                "novel_id": q.novel_id,
                "query": q.query_text,
                "answer": q.answer_text[:200] + "..." if len(q.answer_text) > 200 else q.answer_text,
                "model": q.model_used,
                "total_tokens": q.total_tokens or 0,
                "confidence": q.confidence or "medium",
                "created_at": q.created_at if q.created_at else None,
                "feedback": "positive" if q.user_feedback == 1 else ("negative" if q.user_feedback == -1 else None)
            })
        
        logger.info(f"âœ… è·å–æŸ¥è¯¢å†å²æˆåŠŸ: {len(items)} æ¡")
        
        return {
            "items": items,
            "total": total,
            "page": page,
            "page_size": page_size,
            "total_pages": (total + page_size - 1) // page_size
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–æŸ¥è¯¢å†å²å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æŸ¥è¯¢å†å²å¤±è´¥: {str(e)}")


@router.post("/{query_id}/feedback", summary="æäº¤ç”¨æˆ·åé¦ˆ")
async def submit_feedback(
    query_id: int,
    feedback: str = QueryParam(..., regex="^(positive|negative)$", description="åé¦ˆç±»å‹"),
    note: Optional[str] = QueryParam(None, max_length=500, description="åé¦ˆå¤‡æ³¨"),
    db: Session = Depends(get_db_session)
):
    """
    æäº¤ç”¨æˆ·åé¦ˆ
    
    - positive: ç­”æ¡ˆå‡†ç¡®
    - negative: ç­”æ¡ˆä¸å‡†ç¡®
    """
    try:
        # æŸ¥è¯¢è®°å½•
        query_record = db.query(Query).filter(Query.id == query_id).first()
        
        if not query_record:
            raise HTTPException(status_code=404, detail=f"æŸ¥è¯¢è®°å½• ID={query_id} ä¸å­˜åœ¨")
        
        # æ›´æ–°åé¦ˆ
        query_record.user_feedback = 1 if feedback == "positive" else -1
        if note:
            query_record.feedback_note = note
        
        db.commit()
        
        logger.info(f"âœ… ç”¨æˆ·åé¦ˆå·²æäº¤: query_id={query_id}, feedback={feedback}")
        
        return {
            "success": True,
            "message": "æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼",
            "query_id": query_id,
            "feedback": feedback
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æäº¤åé¦ˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æäº¤åé¦ˆå¤±è´¥: {str(e)}")

