"""
å‘é‡åŒ–æœåŠ¡
è°ƒç”¨æ™ºè°±AI Embedding-3è¿›è¡Œæ–‡æœ¬å‘é‡åŒ–
"""

import logging
from typing import List, Dict, Optional, Tuple
import asyncio
from concurrent.futures import ThreadPoolExecutor

from app.services.zhipu_client import get_zhipu_client
from app.core.chromadb_client import get_chroma_client
from app.core.config import settings
from app.utils.token_counter import get_token_counter

logger = logging.getLogger(__name__)


class EmbeddingService:
    """å‘é‡åŒ–æœåŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–å‘é‡åŒ–æœåŠ¡"""
        self.zhipu_client = get_zhipu_client()
        self.chroma_client = get_chroma_client()
        self.token_counter = get_token_counter()
        self.batch_size = 10  # æ‰¹é‡å¤„ç†å¤§å°
        logger.info("âœ… å‘é‡åŒ–æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def embed_texts(
        self,
        texts: List[str],
        batch_size: Optional[int] = None
    ) -> Tuple[List[List[float]], int]:
        """
        æ‰¹é‡å‘é‡åŒ–æ–‡æœ¬
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
        
        Returns:
            Tuple[List[List[float]], int]: (å‘é‡åˆ—è¡¨, æ¶ˆè€—çš„tokenæ•°)
        """
        if not texts:
            return [], 0
        
        batch_size = batch_size or self.batch_size
        all_embeddings = []
        total_tokens = 0
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            logger.info(f"ğŸ”„ æ­£åœ¨å‘é‡åŒ–æ‰¹æ¬¡ {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}...")
            
            # è®¡ç®—æœ¬æ‰¹æ¬¡çš„tokenæ¶ˆè€—
            batch_tokens = sum(self.token_counter.count_tokens(text) for text in batch)
            total_tokens += batch_tokens
            
            try:
                # è°ƒç”¨æ™ºè°±AI
                embeddings = self.zhipu_client.embed_texts(batch)
                all_embeddings.extend(embeddings)
                
            except Exception as e:
                logger.error(f"âŒ æ‰¹æ¬¡ {i//batch_size + 1} å‘é‡åŒ–å¤±è´¥: {e}")
                # å¯¹å¤±è´¥çš„æ‰¹æ¬¡ä½¿ç”¨é›¶å‘é‡
                zero_embeddings = [[0.0] * settings.embedding_dimension for _ in batch]
                all_embeddings.extend(zero_embeddings)
        
        logger.info(f"âœ… å®Œæˆ {len(all_embeddings)} ä¸ªæ–‡æœ¬çš„å‘é‡åŒ–ï¼Œæ¶ˆè€— {total_tokens} tokens")
        return all_embeddings, total_tokens
    
    def create_collection(self, novel_id: int) -> str:
        """
        ä¸ºå°è¯´åˆ›å»ºå‘é‡é›†åˆ
        
        Args:
            novel_id: å°è¯´ID
        
        Returns:
            str: é›†åˆåç§°
        """
        collection_name = f"novel_{novel_id}"
        
        try:
            self.chroma_client.get_or_create_collection(
                name=collection_name,
                metadata={
                    "novel_id": str(novel_id),
                    "hnsw:space": "cosine",
                    "hnsw:construction_ef": 200,
                    "hnsw:M": 16
                }
            )
            logger.info(f"âœ… åˆ›å»º/è·å–Collection: {collection_name}")
            return collection_name
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºCollectionå¤±è´¥: {e}")
            raise
    
    def add_chapter_chunks(
        self,
        collection_name: str,
        chunks: List[str],
        embeddings: List[List[float]],
        metadata_list: List[Dict]
    ) -> bool:
        """
        æ·»åŠ ç« èŠ‚å—åˆ°å‘é‡åº“
        
        Args:
            collection_name: é›†åˆåç§°
            chunks: æ–‡æœ¬å—åˆ—è¡¨
            embeddings: å‘é‡åˆ—è¡¨
            metadata_list: å…ƒæ•°æ®åˆ—è¡¨
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not chunks or not embeddings:
            logger.warning("âš ï¸ æ²¡æœ‰å†…å®¹éœ€è¦æ·»åŠ ")
            return False
        
        try:
            # ç”ŸæˆID
            ids = [
                f"novel_{metadata['novel_id']}_ch{metadata['chapter_num']}_chunk{metadata['chunk_index']}"
                for metadata in metadata_list
            ]
            
            # æ·»åŠ åˆ°ChromaDB
            self.chroma_client.add_documents(
                collection_name=collection_name,
                documents=chunks,
                embeddings=embeddings,
                ids=ids,
                metadatas=metadata_list
            )
            
            logger.info(f"âœ… æˆåŠŸæ·»åŠ  {len(chunks)} ä¸ªå—åˆ° {collection_name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ åˆ°ChromaDBå¤±è´¥: {e}")
            return False
    
    def process_chapter(
        self,
        novel_id: int,
        chapter_num: int,
        chapter_title: str,
        chapter_chunks: List[Dict]
    ) -> Tuple[bool, int]:
        """
        å¤„ç†å•ä¸ªç« èŠ‚ï¼ˆå‘é‡åŒ–å¹¶å­˜å‚¨ï¼‰
        
        Args:
            novel_id: å°è¯´ID
            chapter_num: ç« èŠ‚ç¼–å·
            chapter_title: ç« èŠ‚æ ‡é¢˜
            chapter_chunks: ç« èŠ‚å—åˆ—è¡¨ï¼ˆåŒ…å«contentå’Œmetadataï¼‰
        
        Returns:
            Tuple[bool, int]: (æ˜¯å¦æˆåŠŸ, æ¶ˆè€—çš„tokenæ•°)
        """
        if not chapter_chunks:
            logger.warning(f"âš ï¸ ç« èŠ‚ {chapter_num} æ²¡æœ‰å†…å®¹")
            return False, 0
        
        try:
            # æå–æ–‡æœ¬
            texts = [chunk['content'] for chunk in chapter_chunks]
            
            # å‘é‡åŒ–ï¼ˆè·å–tokenæ¶ˆè€—ï¼‰
            embeddings, tokens_used = self.embed_texts(texts)
            
            # å‡†å¤‡å…ƒæ•°æ®
            metadata_list = []
            for i, chunk in enumerate(chapter_chunks):
                metadata = {
                    'novel_id': novel_id,
                    'chapter_num': chapter_num,
                    'chapter_title': chapter_title,
                    'chunk_index': i,
                    'char_count': len(chunk['content']),
                }
                # åˆå¹¶chunkè‡ªå¸¦çš„metadata
                if 'metadata' in chunk:
                    metadata.update(chunk['metadata'])
                metadata_list.append(metadata)
            
            # å­˜å‚¨åˆ°ChromaDB
            collection_name = f"novel_{novel_id}"
            success = self.add_chapter_chunks(
                collection_name=collection_name,
                chunks=texts,
                embeddings=embeddings,
                metadata_list=metadata_list
            )
            
            return success, tokens_used
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†ç« èŠ‚ {chapter_num} å¤±è´¥: {e}")
            return False, 0
    
    def query_similar_chunks(
        self,
        novel_id: int,
        query_text: str,
        top_k: int = 30,
        chapter_filter: Optional[Dict] = None
    ) -> Dict:
        """
        æŸ¥è¯¢ç›¸ä¼¼æ–‡æœ¬å—
        
        Args:
            novel_id: å°è¯´ID
            query_text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›Top-Kç»“æœ
            chapter_filter: ç« èŠ‚è¿‡æ»¤æ¡ä»¶
        
        Returns:
            Dict: æŸ¥è¯¢ç»“æœ
        """
        try:
            # å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬
            query_embedding = self.zhipu_client.embed_text(query_text)
            
            # ä»ChromaDBæ£€ç´¢
            collection_name = f"novel_{novel_id}"
            results = self.chroma_client.query_documents(
                collection_name=collection_name,
                query_embeddings=[query_embedding],
                n_results=top_k,
                where=chapter_filter
            )
            
            logger.info(f"âœ… æ£€ç´¢åˆ° {len(results.get('ids', [[]])[0])} ä¸ªç›¸ä¼¼å—")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ç›¸ä¼¼å—æŸ¥è¯¢å¤±è´¥: {e}")
            return {'ids': [[]], 'documents': [[]], 'metadatas': [[]], 'distances': [[]]}


# å…¨å±€å‘é‡åŒ–æœåŠ¡å®ä¾‹
_embedding_service: Optional[EmbeddingService] = None


def get_embedding_service() -> EmbeddingService:
    """è·å–å…¨å±€å‘é‡åŒ–æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _embedding_service
    if _embedding_service is None:
        _embedding_service = EmbeddingService()
    return _embedding_service

