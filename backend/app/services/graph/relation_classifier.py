"""
å…³ç³»ç±»å‹åˆ†ç±»å™¨ - ä½¿ç”¨LLMè¯†åˆ«å®ä½“é—´çš„å…·ä½“å…³ç³»ç±»å‹

åŠŸèƒ½:
- 8ç§å…³ç³»ç±»å‹è¯†åˆ«ï¼šå¸ˆå¾’ã€ç›Ÿå‹ã€æ•Œå¯¹ã€äº²å±ã€æ‹äººã€åŒé—¨ã€ä¸­ç«‹ã€å…±ç°
- Few-shotæç¤ºå·¥ç¨‹ä¼˜åŒ–
- æ™ºèƒ½ç« èŠ‚é‡‡æ ·
- å¢å¼ºå®ä½“è¯†åˆ«
- å¹¶å‘æ‰¹é‡å¤„ç†
"""

import json
import asyncio
import logging
from typing import List, Dict, Optional, Tuple
from sqlalchemy.orm import Session

from app.services.zhipu_client import get_zhipu_client
from app.services.batch_api_client import get_batch_client
from app.core.config import settings

logger = logging.getLogger(__name__)


class RelationshipClassifier:
    """ä½¿ç”¨LLMè¯†åˆ«è§’è‰²é—´çš„å…³ç³»ç±»å‹"""
    
    RELATION_TYPES = [
        'å¸ˆå¾’',      # æ˜ç¡®çš„å¸ˆå¾’å…³ç³»
        'ç›Ÿå‹',      # åˆä½œã€å‹å¥½å…³ç³»
        'æ•Œå¯¹',      # å¯¹ç«‹ã€æ•Œå¯¹å…³ç³»
        'äº²å±',      # å®¶æ—ã€è¡€ç¼˜å…³ç³»
        'æ‹äºº',      # æ‹çˆ±å…³ç³»
        'åŒé—¨',      # åŒä¸€ç»„ç»‡æˆ–é—¨æ´¾
        'ä¸­ç«‹',      # æ— æ˜æ˜¾å…³ç³»å€¾å‘
        'å…±ç°'       # ä»…å…±åŒå‡ºç°ï¼Œæ— æ˜ç¡®å…³ç³»
    ]
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†ç±»å™¨"""
        self.llm_client = get_zhipu_client()
    
    async def classify_relationship(
        self,
        entity1: str,
        entity2: str,
        contexts: List[str],
        cooccurrence_count: int = 0,
        chapter_range: str = ""
    ) -> Dict:
        """
        ä½¿ç”¨GLM-4.5-Flashè¿›è¡Œå…³ç³»åˆ†ç±»ï¼ˆå·²ä¼˜åŒ–ï¼‰
        
        ä¼˜åŒ–ç‚¹ï¼š
        1. Few-shotç¤ºä¾‹å¼•å¯¼
        2. è¯¦ç»†çš„å…³ç³»ç±»å‹å®šä¹‰å’Œå…³é”®è¯
        3. æ›´é•¿çš„ä¸Šä¸‹æ–‡ï¼ˆ300å­—ç¬¦ï¼‰
        4. æ›´å¤šç‰‡æ®µï¼ˆ5ä¸ªï¼‰
        5. ä¼ é€’å…±ç°ç»Ÿè®¡ä¿¡æ¯
        6. é™ä½temperatureæé«˜ç¨³å®šæ€§
        
        Args:
            entity1: å®ä½“1åç§°
            entity2: å®ä½“2åç§°
            contexts: 3-5ä¸ªå…¸å‹å…±ç°ç‰‡æ®µ
            cooccurrence_count: å…±ç°æ¬¡æ•°
            chapter_range: ç« èŠ‚èŒƒå›´
        
        Returns:
            {
                'relation_type': 'å¸ˆå¾’',
                'confidence': 0.9,
                'reasoning': '...'
            }
        """
        # æ„å»ºå¢å¼ºPromptï¼ˆæ›´é•¿ä¸Šä¸‹æ–‡ï¼‰
        context_text = ""
        for i, ctx in enumerate(contexts[:5], 1):
            context_text += f"\nã€ç‰‡æ®µ{i}ã€‘{ctx[:300]}\n"
        
        # Few-shotç¤ºä¾‹
        few_shot = """## ç¤ºä¾‹åˆ†æ

ç¤ºä¾‹1ï¼š
ã€ç‰‡æ®µã€‘è§ç‚æ­æ•¬åœ°å¯¹ç€æˆ’æŒ‡è¡Œç¤¼ï¼š"å¸ˆçˆ¶ï¼Œå¼Ÿå­æ˜ç™½äº†ã€‚"è¯è€å¾®ç¬‘é“ï¼š"å­©å­ï¼Œä¿®ç‚¼ä¸å¯æ€¥èºã€‚"ä¹‹åè¯è€ä¼ æˆè§ç‚ç‚¼è¯å¿ƒæ³•...
ã€åˆ¤æ–­ã€‘å¸ˆå¾’ï¼ˆç½®ä¿¡åº¦0.98ï¼‰- æ˜ç¡®çš„å¸ˆçˆ¶ç§°å‘¼å’Œä¼ æˆå…³ç³»

ç¤ºä¾‹2ï¼š
ã€ç‰‡æ®µã€‘è§ç‚å’Œè§è–°å„¿å¹¶è‚©è€Œç«‹ï¼Œä¸¤äººåæŒ‡ç›¸æ‰£ã€‚è–°å„¿æ¸©æŸ”åœ°çœ‹ç€è§ç‚ï¼Œçœ¼ä¸­æ»¡æ˜¯çˆ±æ„...
ã€åˆ¤æ–­ã€‘æ‹äººï¼ˆç½®ä¿¡åº¦0.95ï¼‰- æ˜æ˜¾çš„äº²å¯†äº’åŠ¨å’Œæ„Ÿæƒ…è¡¨è¾¾

ç¤ºä¾‹3ï¼š
ã€ç‰‡æ®µã€‘é­‚å¤©å¸å†·ç¬‘ï¼š"è§ç‚ï¼Œä»Šæ—¥å°±æ˜¯ä½ çš„æ­»æœŸï¼"è§ç‚æ€’å¼ï¼š"é­‚æ—å®³æˆ‘å®¶æ—ï¼Œä¸å…±æˆ´å¤©ï¼"ä¸¤äººå±•å¼€ç”Ÿæ­»ææ–—...
ã€åˆ¤æ–­ã€‘æ•Œå¯¹ï¼ˆç½®ä¿¡åº¦0.99ï¼‰- æ˜ç¡®çš„ä»‡æ¨å’Œç”Ÿæ­»å¯¹ç«‹

ç¤ºä¾‹4ï¼š
ã€ç‰‡æ®µã€‘è§ç‚èµ°è¿›æ‹å–ä¼šï¼Œçœ‹åˆ°ä¸»æŒäººç±³ç‰¹å°”é›…å¦ƒæ­£åœ¨å°ä¸Šä»‹ç»ç‰©å“ã€‚è§ç‚ååœ¨è§’è½é‡Œ...
ã€åˆ¤æ–­ã€‘å…±ç°ï¼ˆç½®ä¿¡åº¦0.70ï¼‰- ä»…åœ¨åŒä¸€åœºæ™¯ï¼Œæ— å®è´¨äº’åŠ¨

"""
        
        prompt = f"""{few_shot}

## ç°åœ¨è¯·åˆ†æä»¥ä¸‹å…³ç³»

ä½ æ˜¯ç½‘ç»œå°è¯´å…³ç³»åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æ"{entity1}"å’Œ"{entity2}"çš„å…³ç³»ç±»å‹ã€‚

**åˆ†æææ–™**
ä¸¤ä¸ªè§’è‰²å…±åŒå‡ºç° {cooccurrence_count} æ¬¡ï¼ˆ{chapter_range}ï¼‰ï¼Œä»¥ä¸‹æ˜¯å…¸å‹åœºæ™¯ï¼š
{context_text}

**å…³ç³»ç±»å‹å®šä¹‰ï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§å®šä¹‰é€‰æ‹©ï¼‰**

1. **å¸ˆå¾’**ï¼šæ˜ç¡®çš„å¸ˆæ‰¿å…³ç³»ï¼Œæœ‰ä¼ æˆçŸ¥è¯†/æŠ€èƒ½çš„æè¿°
   - å…³é”®è¯ï¼šå¸ˆçˆ¶ã€å¾’å¼Ÿã€ä¼ æˆã€æŒ‡å¯¼ã€æ•™å¯¼ã€æ‹œå¸ˆ
   - ç¤ºä¾‹ï¼šè¯è€ä¼ æˆè§ç‚ç‚¼è¯æœ¯

2. **ç›Ÿå‹**ï¼šåˆä½œã€äº’åŠ©ã€å…±åŒæˆ˜æ–—çš„å…³ç³»
   - å…³é”®è¯ï¼šè”æ‰‹ã€åˆä½œã€å¹¶è‚©ä½œæˆ˜ã€å¸®åŠ©ã€ç»“ç›Ÿ
   - ç¤ºä¾‹ï¼šä¸¤äººè”æ‰‹å¯¹æŠ—æ•Œäºº

3. **æ•Œå¯¹**ï¼šæ˜ç¡®çš„å¯¹ç«‹ã€ä»‡æ¨ã€æˆ˜æ–—å…³ç³»
   - å…³é”®è¯ï¼šæ•Œäººã€å¯¹æ‰‹ã€ä»‡æ¨ã€æˆ˜æ–—ã€å¯¹æŠ—ã€ä½ æ­»æˆ‘æ´»
   - ç¤ºä¾‹ï¼šä¸å…±æˆ´å¤©çš„æ­»æ•Œ

4. **äº²å±**ï¼šè¡€ç¼˜ã€å®¶æ—å…³ç³»
   - å…³é”®è¯ï¼šçˆ¶å­ã€å…„å¼Ÿã€å§å¦¹ã€äº²äººã€å®¶æ—
   - ç¤ºä¾‹ï¼šäº²ç”Ÿçˆ¶å­ã€äº²å…„å¼Ÿ

5. **æ‹äºº**ï¼šæ˜ç¡®çš„æ‹çˆ±ã€æƒ…ä¾£å…³ç³»
   - å…³é”®è¯ï¼šçˆ±æ…•ã€æ‹äººã€æƒ…ä¾£ã€å–œæ¬¢ã€ç›¸çˆ±ã€è¡¨ç™½
   - ç¤ºä¾‹ï¼šäº’ç›¸çˆ±æ…•çš„æƒ…ä¾£

6. **åŒé—¨**ï¼šåŒä¸€é—¨æ´¾ã€ç»„ç»‡ã€åŠ¿åŠ›
   - å…³é”®è¯ï¼šåŒé—¨ã€å¸ˆå…„å¼Ÿã€åŒæ´¾ã€åŒä¸€å®—é—¨
   - ç¤ºä¾‹ï¼šåŒä¸ºäº‘å²šå®—å¼Ÿå­

7. **ä¸­ç«‹**ï¼šè®¤è¯†ä½†æ— æ˜æ˜¾å…³ç³»å€¾å‘
   - ç‰¹å¾ï¼šå¶å°”äº¤é›†ï¼Œå…³ç³»ä¸æ˜ç¡®ï¼Œæ— æ˜æ˜¾æƒ…æ„Ÿå€¾å‘
   - ç¤ºä¾‹ï¼šè§è¿‡å‡ é¢çš„ç†Ÿäºº

8. **å…±ç°**ï¼šä»…åœ¨åŒä¸€åœºæ™¯å‡ºç°ï¼Œæ— å®è´¨äº’åŠ¨
   - ç‰¹å¾ï¼šåªæ˜¯åŒæ—¶åœ¨åœºï¼Œæ— å¯¹è¯æˆ–äº’åŠ¨ï¼Œçº¯ç²¹çš„èƒŒæ™¯è§’è‰²
   - ç¤ºä¾‹ï¼šåŒåœ¨ä¸€ä¸ªå®´ä¼šä¸Šä½†æ— äº¤æµ

**åˆ†ææ­¥éª¤**
1. ä»”ç»†é˜…è¯»æ‰€æœ‰ç‰‡æ®µ
2. è¯†åˆ«å…³é”®è¯å’Œäº’åŠ¨æ¨¡å¼
3. åˆ¤æ–­æœ€ä¸»è¦çš„å…³ç³»ç±»å‹ï¼ˆå¦‚æœæœ‰å¤šç§ï¼Œé€‰æ‹©æœ€æ ¸å¿ƒçš„ï¼‰
4. è¯„ä¼°åˆ¤æ–­çš„ç½®ä¿¡åº¦

**è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»æ˜¯çº¯JSONï¼‰**
{{"relation_type": "å¸ˆå¾’", "confidence": 0.95, "reasoning": "è¯è€å¤šæ¬¡æŒ‡å¯¼è§ç‚ä¿®ç‚¼ï¼Œæ˜ç¡®çš„å¸ˆå¾’ä¼ æ‰¿å…³ç³»"}}

è¯·åˆ†æï¼š"""
        
        content = ""  # åˆå§‹åŒ–ï¼Œé¿å…åœ¨å¼‚å¸¸å¤„ç†ä¸­æœªå®šä¹‰
        try:
            response = await asyncio.to_thread(
                self.llm_client.chat_completion,
                messages=[{"role": "user", "content": prompt}],
                model="GLM-4.5-Flash",  # å…è´¹é«˜é€Ÿæ¨¡å‹
                max_tokens=512,  # å¢åŠ tokené™åˆ¶ï¼Œé¿å…JSONè¢«æˆªæ–­
                temperature=0.1,  # é™ä½éšæœºæ€§ï¼Œæé«˜ç¨³å®šæ€§
                thinking={"type": "disabled"}  # ç¦ç”¨æ€è€ƒæ¨¡å¼ï¼Œç›´æ¥è¾“å‡ºJSON
            )
            
            content = response.get('content', '').strip()
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
            if not content:
                logger.warning(f"LLMè¿”å›ç©ºå†…å®¹ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                return {
                    'relation_type': 'å…±ç°',
                    'confidence': 0.5,
                    'reasoning': 'LLMè¿”å›ç©ºå†…å®¹'
                }
            
            # æå–JSONï¼ˆå¯èƒ½åŒ…å«åœ¨ä»£ç å—ä¸­ï¼‰
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()
            
            # å†æ¬¡æ£€æŸ¥æå–åçš„å†…å®¹
            if not content:
                logger.warning(f"æå–JSONåå†…å®¹ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼")
                return {
                    'relation_type': 'å…±ç°',
                    'confidence': 0.5,
                    'reasoning': 'æå–JSONå¤±è´¥'
                }
            
            result = json.loads(content)
            
            # éªŒè¯ç»“æœ
            if 'relation_type' not in result:
                logger.warning(f"LLMè¿”å›ç¼ºå°‘relation_typeï¼Œä½¿ç”¨é»˜è®¤å€¼")
                result['relation_type'] = 'å…±ç°'
            if 'confidence' not in result:
                result['confidence'] = 0.5
            if 'reasoning' not in result:
                result['reasoning'] = 'è‡ªåŠ¨åˆ†ç±»'
            
            return result
            
        except json.JSONDecodeError as e:
            # JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤è¢«æˆªæ–­çš„JSON
            logger.warning(f"JSONè§£æå¤±è´¥: {e}, å°è¯•ä¿®å¤...")
            
            # å°è¯•æå–éƒ¨åˆ†ä¿¡æ¯
            try:
                # ä½¿ç”¨æ­£åˆ™æå–relation_type
                import re
                relation_match = re.search(r'"relation_type"\s*:\s*"([^"]+)"', content)
                confidence_match = re.search(r'"confidence"\s*:\s*([0-9.]+)', content)
                
                if relation_match:
                    return {
                        'relation_type': relation_match.group(1),
                        'confidence': float(confidence_match.group(1)) if confidence_match else 0.5,
                        'reasoning': 'JSONè¢«æˆªæ–­ï¼Œéƒ¨åˆ†è§£æ'
                    }
            except:
                pass
            
            logger.error(f"æ— æ³•ä¿®å¤JSONï¼Œå†…å®¹: {content[:200]}")
            return {
                'relation_type': 'å…±ç°',
                'confidence': 0.5,
                'reasoning': 'JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼'
            }
        except Exception as e:
            logger.error(f"å…³ç³»åˆ†ç±»å¤±è´¥: {e}")
            return {
                'relation_type': 'å…±ç°',
                'confidence': 0.5,
                'reasoning': f'åˆ†ç±»å¤±è´¥: {str(e)}'
            }
    
    async def classify_batch(
        self,
        tasks: List[Tuple],
        max_concurrency: Optional[int] = None,
        use_batch_api: bool = False
    ) -> Tuple[List[Dict], Dict]:
        """
        æ‰¹é‡å¹¶å‘åˆ†ç±»å…³ç³»
        
        Args:
            tasks: [(entity1, entity2, contexts, count, chapters), ...]
            max_concurrency: æœ€å¤§å¹¶å‘æ•°ï¼ˆä»…åœ¨use_batch_api=Falseæ—¶ç”Ÿæ•ˆï¼‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼
            use_batch_api: æ˜¯å¦ä½¿ç”¨Batch API
        
        Returns:
            Tuple[List[Dict], Dict]: (åˆ†ç±»ç»“æœåˆ—è¡¨, tokenç»Ÿè®¡)
        """
        # ğŸ¯ æ™ºèƒ½åˆ¤æ–­ï¼šè¯·æ±‚æ•° < é˜ˆå€¼æ—¶ä½¿ç”¨å®æ—¶API
        if len(tasks) < settings.batch_api_threshold:
            logger.info(f"ğŸ“Š å…³ç³»åˆ†ç±»: è¯·æ±‚æ•°({len(tasks)}) < é˜ˆå€¼({settings.batch_api_threshold})ï¼Œä½¿ç”¨å®æ—¶API")
            use_batch_api = False
        elif use_batch_api:
            logger.info(f"ğŸ“Š å…³ç³»åˆ†ç±»: è¯·æ±‚æ•°({len(tasks)}) â‰¥ é˜ˆå€¼({settings.batch_api_threshold})ï¼Œä½¿ç”¨Batch API")
        
        if use_batch_api:
            return await self._classify_batch_with_batch_api(tasks)
        
        # ä½¿ç”¨é€Ÿç‡é™åˆ¶çš„å¹¶å‘æ§åˆ¶
        max_concurrency = max_concurrency or settings.graph_relation_concurrency
        
        logger.info(f"ğŸ“Š åˆ†æ‰¹å¤„ç† {len(tasks)} å¯¹å…³ç³»åˆ†ç±»ï¼ˆå¹¶å‘æ•°ï¼š{max_concurrency}ï¼Œæ¯æ‰¹é—´éš”1ç§’ï¼‰...")
        
        # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹max_concurrencyä¸ªä»»åŠ¡
        results = []
        for batch_idx in range(0, len(tasks), max_concurrency):
            batch = tasks[batch_idx:batch_idx + max_concurrency]
            batch_num = batch_idx // max_concurrency + 1
            total_batches = (len(tasks) + max_concurrency - 1) // max_concurrency
            
            logger.info(f"  å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ ({len(batch)} ä¸ªä»»åŠ¡)...")
            
            # æ‰¹å†…ä»»åŠ¡å¹¶å‘æ‰§è¡Œ
            batch_results = await asyncio.gather(
                *[self.classify_relationship(
                    entity1, entity2, contexts, count, 
                    f"ç¬¬{min(chapters)}ç« -ç¬¬{max(chapters)}ç« "
                  ) for entity1, entity2, contexts, count, chapters in batch],
                return_exceptions=True
            )
            
            results.extend(batch_results)
            
            # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…æŒç»­é«˜é¢‘è¯·æ±‚
            if batch_idx + max_concurrency < len(tasks):
                await asyncio.sleep(1.0)
        
        logger.info(f"âœ… æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆ")
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"åˆ†ç±»ä»»åŠ¡ {i} å¤±è´¥: {result}")
                valid_results.append({
                    'relation_type': 'å…±ç°',
                    'confidence': 0.5,
                    'reasoning': f'åˆ†ç±»å¤±è´¥: {str(result)}'
                })
            else:
                valid_results.append(result)
        
        # ç»Ÿè®¡åˆ†ç±»ç»“æœ
        type_counts = {}
        for result in valid_results:
            rel_type = result['relation_type']
            type_counts[rel_type] = type_counts.get(rel_type, 0) + 1
        
        logger.info(f"âœ… å…³ç³»åˆ†ç±»å®Œæˆï¼Œç±»å‹åˆ†å¸ƒ: {type_counts}")
        
        # å®æ—¶APIæ¨¡å¼ï¼šä¼°ç®—tokenæ¶ˆè€—
        from app.utils.token_counter import get_token_counter
        token_counter = get_token_counter()
        
        total_input_tokens = 0
        for entity1, entity2, contexts, count, chapters in tasks:
            # ä¼°ç®—prompt tokenï¼ˆåŒ…å«æŒ‡ä»¤+ä¸Šä¸‹æ–‡ï¼‰
            prompt = f"è§’è‰²1ï¼š{entity1}\nè§’è‰²2ï¼š{entity2}\nå…±ç°æ¬¡æ•°ï¼š{count}\nä¸Šä¸‹æ–‡ï¼š{''.join(contexts[:3])}"
            total_input_tokens += token_counter.count_tokens(prompt)
        
        # ä¼°ç®—è¾“å‡ºtokenï¼ˆå…³ç³»åˆ†ç±»ç»“æœè¾ƒçŸ­ï¼Œå¹³å‡80 tokensï¼‰
        total_output_tokens = len(valid_results) * 80
        
        token_stats = {
            'input_tokens': total_input_tokens,
            'output_tokens': total_output_tokens,
            'total_tokens': total_input_tokens + total_output_tokens
        }
        
        logger.info(f"ğŸ“Š ä¼°ç®—Tokenæ¶ˆè€—: input={total_input_tokens}, output={total_output_tokens}, total={token_stats['total_tokens']}")
        
        return valid_results, token_stats
    
    async def _classify_batch_with_batch_api(
        self,
        tasks: List[Tuple]
    ) -> Tuple[List[Dict], Dict]:
        """
        ä½¿ç”¨Batch APIæ‰¹é‡åˆ†ç±»å…³ç³»
        
        Args:
            tasks: [(entity1, entity2, contexts, count, chapters), ...]
        
        Returns:
            Tuple[List[Dict], Dict]: (åˆ†ç±»ç»“æœåˆ—è¡¨, tokenç»Ÿè®¡)
        """
        logger.info(f"ğŸš€ ä½¿ç”¨Batch APIåˆ†ç±» {len(tasks)} å¯¹å…³ç³»ï¼ˆæ— å¹¶å‘é™åˆ¶ï¼Œå…è´¹ï¼‰...")
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ™ºè°±AI Batch APIé™åˆ¶ï¼ˆChatæ¨¡å‹ï¼š50,000ä¸ªè¯·æ±‚/æ‰¹æ¬¡ï¼‰
        if len(tasks) > 50000:
            logger.error(f"âŒ å…³ç³»å¯¹æ•°({len(tasks)})è¶…è¿‡Batch APIé™åˆ¶(50,000)ï¼Œè¿™ç§æƒ…å†µæå…¶ç½•è§")
            # ç†è®ºä¸Šä¸ä¼šå‘ç”Ÿï¼ˆéœ€è¦æ•°åƒä¸ªå®ä½“æ‰å¯èƒ½ï¼‰ï¼Œä½†æ·»åŠ é˜²æŠ¤
            logger.error(f"   å»ºè®®ï¼šè”ç³»å¼€å‘è€…æˆ–æ‰‹åŠ¨å…³é—­Batch APIæ¨¡å¼")
            raise ValueError(f"å…³ç³»å¯¹æ•°è¶…è¿‡Batch APIé™åˆ¶: {len(tasks)} > 50,000")
        
        # 1. æ„å»ºBatch APIä»»åŠ¡
        batch_tasks = []
        task_mapping = {}  # custom_id -> task_index
        
        for i, (entity1, entity2, contexts, count, chapters) in enumerate(tasks):
            chapter_range = f"ç¬¬{min(chapters)}ç« -ç¬¬{max(chapters)}ç« "
            
            # æ„å»ºPrompt
            context_text = ""
            for j, ctx in enumerate(contexts[:5], 1):
                context_text += f"\nã€ç‰‡æ®µ{j}ã€‘{ctx[:300]}\n"
            
            few_shot = """## ç¤ºä¾‹åˆ†æ

ç¤ºä¾‹1ï¼š
ã€ç‰‡æ®µã€‘è§ç‚æ­æ•¬åœ°å¯¹ç€æˆ’æŒ‡è¡Œç¤¼ï¼š"å¸ˆçˆ¶ï¼Œå¼Ÿå­æ˜ç™½äº†ã€‚"è¯è€å¾®ç¬‘é“ï¼š"å­©å­ï¼Œä¿®ç‚¼ä¸å¯æ€¥èºã€‚"ä¹‹åè¯è€ä¼ æˆè§ç‚ç‚¼è¯å¿ƒæ³•...
ã€åˆ¤æ–­ã€‘å¸ˆå¾’ï¼ˆç½®ä¿¡åº¦0.98ï¼‰- æ˜ç¡®çš„å¸ˆçˆ¶ç§°å‘¼å’Œä¼ æˆå…³ç³»

ç¤ºä¾‹2ï¼š
ã€ç‰‡æ®µã€‘è§ç‚å’Œè§è–°å„¿å¹¶è‚©è€Œç«‹ï¼Œä¸¤äººåæŒ‡ç›¸æ‰£ã€‚è–°å„¿æ¸©æŸ”åœ°çœ‹ç€è§ç‚ï¼Œçœ¼ä¸­æ»¡æ˜¯çˆ±æ„...
ã€åˆ¤æ–­ã€‘æ‹äººï¼ˆç½®ä¿¡åº¦0.95ï¼‰- æ˜æ˜¾çš„äº²å¯†äº’åŠ¨å’Œæ„Ÿæƒ…è¡¨è¾¾

ç¤ºä¾‹3ï¼š
ã€ç‰‡æ®µã€‘é­‚å¤©å¸å†·ç¬‘ï¼š"è§ç‚ï¼Œä»Šæ—¥å°±æ˜¯ä½ çš„æ­»æœŸï¼"è§ç‚æ€’å¼ï¼š"é­‚æ—å®³æˆ‘å®¶æ—ï¼Œä¸å…±æˆ´å¤©ï¼"ä¸¤äººå±•å¼€ç”Ÿæ­»ææ–—...
ã€åˆ¤æ–­ã€‘æ•Œå¯¹ï¼ˆç½®ä¿¡åº¦0.99ï¼‰- æ˜ç¡®çš„ä»‡æ¨å’Œç”Ÿæ­»å¯¹ç«‹

ç¤ºä¾‹4ï¼š
ã€ç‰‡æ®µã€‘è§ç‚èµ°è¿›æ‹å–ä¼šï¼Œçœ‹åˆ°ä¸»æŒäººç±³ç‰¹å°”é›…å¦ƒæ­£åœ¨å°ä¸Šä»‹ç»ç‰©å“ã€‚è§ç‚ååœ¨è§’è½é‡Œ...
ã€åˆ¤æ–­ã€‘å…±ç°ï¼ˆç½®ä¿¡åº¦0.70ï¼‰- ä»…åœ¨åŒä¸€åœºæ™¯ï¼Œæ— å®è´¨äº’åŠ¨

"""
            
            prompt = f"""{few_shot}

## ç°åœ¨è¯·åˆ†æä»¥ä¸‹å…³ç³»

ä½ æ˜¯ç½‘ç»œå°è¯´å…³ç³»åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æ"{entity1}"å’Œ"{entity2}"çš„å…³ç³»ç±»å‹ã€‚

**åˆ†æææ–™**
ä¸¤ä¸ªè§’è‰²å…±åŒå‡ºç° {count} æ¬¡ï¼ˆ{chapter_range}ï¼‰ï¼Œä»¥ä¸‹æ˜¯å…¸å‹åœºæ™¯ï¼š
{context_text}

**å…³ç³»ç±»å‹å®šä¹‰ï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§å®šä¹‰é€‰æ‹©ï¼‰**

1. **å¸ˆå¾’**ï¼šæ˜ç¡®çš„å¸ˆæ‰¿å…³ç³»ï¼Œæœ‰ä¼ æˆçŸ¥è¯†/æŠ€èƒ½çš„æè¿°
   - å…³é”®è¯ï¼šå¸ˆçˆ¶ã€å¾’å¼Ÿã€ä¼ æˆã€æŒ‡å¯¼ã€æ•™å¯¼ã€æ‹œå¸ˆ

2. **ç›Ÿå‹**ï¼šåˆä½œã€äº’åŠ©ã€å…±åŒæˆ˜æ–—çš„å…³ç³»
   - å…³é”®è¯ï¼šè”æ‰‹ã€åˆä½œã€å¹¶è‚©ä½œæˆ˜ã€å¸®åŠ©ã€ç»“ç›Ÿ

3. **æ•Œå¯¹**ï¼šæ˜ç¡®çš„å¯¹ç«‹ã€ä»‡æ¨ã€æˆ˜æ–—å…³ç³»
   - å…³é”®è¯ï¼šæ•Œäººã€å¯¹æ‰‹ã€ä»‡æ¨ã€æˆ˜æ–—ã€å¯¹æŠ—ã€ä½ æ­»æˆ‘æ´»

4. **äº²å±**ï¼šè¡€ç¼˜ã€å®¶æ—å…³ç³»
   - å…³é”®è¯ï¼šçˆ¶å­ã€å…„å¼Ÿã€å§å¦¹ã€äº²äººã€å®¶æ—

5. **æ‹äºº**ï¼šæ˜ç¡®çš„æ‹çˆ±ã€æƒ…ä¾£å…³ç³»
   - å…³é”®è¯ï¼šçˆ±æ…•ã€æ‹äººã€æƒ…ä¾£ã€å–œæ¬¢ã€ç›¸çˆ±ã€è¡¨ç™½

6. **åŒé—¨**ï¼šåŒä¸€é—¨æ´¾ã€ç»„ç»‡ã€åŠ¿åŠ›
   - å…³é”®è¯ï¼šåŒé—¨ã€å¸ˆå…„å¼Ÿã€åŒæ´¾ã€åŒä¸€å®—é—¨

7. **ä¸­ç«‹**ï¼šè®¤è¯†ä½†æ— æ˜æ˜¾å…³ç³»å€¾å‘
   - ç‰¹å¾ï¼šå¶å°”äº¤é›†ï¼Œå…³ç³»ä¸æ˜ç¡®ï¼Œæ— æ˜æ˜¾æƒ…æ„Ÿå€¾å‘

8. **å…±ç°**ï¼šä»…åœ¨åŒä¸€åœºæ™¯å‡ºç°ï¼Œæ— å®è´¨äº’åŠ¨
   - ç‰¹å¾ï¼šåªæ˜¯åŒæ—¶åœ¨åœºï¼Œæ— å¯¹è¯æˆ–äº’åŠ¨ï¼Œçº¯ç²¹çš„èƒŒæ™¯è§’è‰²

**è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»æ˜¯çº¯JSONï¼‰**
{{"relation_type": "å¸ˆå¾’", "confidence": 0.95, "reasoning": "è¯è€å¤šæ¬¡æŒ‡å¯¼è§ç‚ä¿®ç‚¼ï¼Œæ˜ç¡®çš„å¸ˆå¾’ä¼ æ‰¿å…³ç³»"}}

è¯·åˆ†æï¼š"""
            
            custom_id = f"relation-{i}-{entity1}-{entity2}"
            task_mapping[custom_id] = i
            
            batch_tasks.append({
                "custom_id": custom_id,
                "method": "POST",
                "url": "/v4/chat/completions",
                "body": {
                    "model": "glm-4-flash",  # ä½¿ç”¨å…è´¹çš„Flashæ¨¡å‹
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.1,
                    "max_tokens": 200
                }
            })
        
        # 2. æäº¤Batch API
        batch_client = get_batch_client()
        
        def progress_callback(batch_id, status, progress, completed, total, failed):
            logger.info(f"ğŸ“Š Batch APIè¿›åº¦: {status} | {completed}/{total} ({progress*100:.1f}%) | å¤±è´¥: {failed}")
        
        try:
            results_map, token_stats = await asyncio.to_thread(
                batch_client.submit_and_wait,
                batch_tasks,
                check_interval=30,  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                progress_callback=progress_callback
            )
        except Exception as e:
            logger.error(f"âŒ Batch APIè°ƒç”¨å¤±è´¥: {e}")
            # é™çº§åˆ°é»˜è®¤å€¼
            empty_stats = {'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0}
            default_results = [{'relation_type': 'å…±ç°', 'confidence': 0.5, 'reasoning': f'Batch APIå¤±è´¥: {str(e)}'} for _ in tasks]
            return default_results, empty_stats
        
        # 3. è§£æç»“æœå¹¶æŒ‰åŸé¡ºåºè¿”å›
        valid_results = []
        for i in range(len(tasks)):
            custom_id = f"relation-{i}-{tasks[i][0]}-{tasks[i][1]}"
            
            if custom_id in results_map:
                result = results_map[custom_id]
                
                if result['status'] == 'success':
                    try:
                        content = result['content'].strip()
                        
                        # æå–JSON
                        if '```json' in content:
                            content = content.split('```json')[1].split('```')[0].strip()
                        elif '```' in content:
                            content = content.split('```')[1].split('```')[0].strip()
                        
                        parsed = json.loads(content)
                        
                        # éªŒè¯ç»“æœ
                        if 'relation_type' not in parsed:
                            parsed['relation_type'] = 'å…±ç°'
                        if 'confidence' not in parsed:
                            parsed['confidence'] = 0.5
                        if 'reasoning' not in parsed:
                            parsed['reasoning'] = 'è‡ªåŠ¨åˆ†ç±»'
                        
                        valid_results.append(parsed)
                    except Exception as e:
                        logger.warning(f"è§£æç»“æœå¤±è´¥: {e}, å†…å®¹: {result['content'][:100]}")
                        valid_results.append({
                            'relation_type': 'å…±ç°',
                            'confidence': 0.5,
                            'reasoning': f'è§£æå¤±è´¥: {str(e)}'
                        })
                else:
                    logger.warning(f"ä»»åŠ¡å¤±è´¥: {custom_id}, é”™è¯¯: {result.get('error')}")
                    valid_results.append({
                        'relation_type': 'å…±ç°',
                        'confidence': 0.5,
                        'reasoning': f'APIé”™è¯¯: {result.get("error")}'
                    })
            else:
                logger.warning(f"ç¼ºå°‘ç»“æœ: {custom_id}")
                valid_results.append({
                    'relation_type': 'å…±ç°',
                    'confidence': 0.5,
                    'reasoning': 'ç¼ºå°‘ç»“æœ'
                })
        
        # ç»Ÿè®¡åˆ†ç±»ç»“æœ
        type_counts = {}
        for result in valid_results:
            rel_type = result['relation_type']
            type_counts[rel_type] = type_counts.get(rel_type, 0) + 1
        
        logger.info(f"âœ… Batch APIå…³ç³»åˆ†ç±»å®Œæˆï¼Œç±»å‹åˆ†å¸ƒ: {type_counts}")
        logger.info(f"ğŸ“Š å…³ç³»åˆ†ç±»Tokenç»Ÿè®¡: {token_stats}")
        
        return valid_results, token_stats
    
    def _smart_chapter_sampling(
        self,
        chapter_nums: List[int],
        max_samples: int = 5
    ) -> List[int]:
        """
        æ™ºèƒ½ç« èŠ‚é‡‡æ ·ï¼šæ—©æœŸ+ä¸­æœŸ+åæœŸ+å‡åŒ€åˆ†å¸ƒ
        
        ä¼˜åŒ–ç‚¹ï¼š
        - è¦†ç›–å…³ç³»çš„æ•´ä¸ªæ—¶é—´è·¨åº¦
        - ä¼˜å…ˆé‡‡æ ·é¦–æ¬¡å‡ºç°ã€ä¸­æœŸã€æœ«æ¬¡å‡ºç°
        - é¿å…å‡åŒ€é‡‡æ ·é”™è¿‡å…³é”®ç« èŠ‚
        
        Args:
            chapter_nums: ç« èŠ‚åˆ—è¡¨
            max_samples: æœ€å¤§é‡‡æ ·æ•°
        
        Returns:
            é‡‡æ ·åçš„ç« èŠ‚åˆ—è¡¨
        """
        if len(chapter_nums) <= max_samples:
            return chapter_nums
        
        # å–é¦–ã€ä¸­ã€å°¾å„1ä¸ª
        result = [
            chapter_nums[0],  # é¦–æ¬¡å‡ºç°
            chapter_nums[len(chapter_nums)//2],  # ä¸­æœŸ
            chapter_nums[-1],  # æœ€åå‡ºç°
        ]
        
        # å‰©ä½™ä½ç½®å‡åŒ€é‡‡æ ·
        remaining = max_samples - 3
        if remaining > 0:
            step = (len(chapter_nums) - 1) // (remaining + 1)
            for i in range(1, remaining + 1):
                idx = i * step
                if idx < len(chapter_nums) and chapter_nums[idx] not in result:
                    result.append(chapter_nums[idx])
        
        return sorted(set(result))
    
    def _extract_paragraph_with_entities(
        self,
        content: str,
        entity1: str,
        entity2: str,
        chapter_num: int
    ) -> Optional[str]:
        """
        æå–åŒ…å«ä¸¤ä¸ªå®ä½“çš„æ®µè½ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        ä¼˜åŒ–ç‚¹ï¼š
        - æ”¯æŒåˆ«ååŒ¹é…ï¼ˆå¦‚"è§ç‚"â†’"è§"ï¼‰
        - æ›´é•¿çš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆ400å­—ç¬¦ï¼‰
        - æ›´å¤§çš„æœç´¢èŒƒå›´ï¼ˆ800å­—ç¬¦å†…ï¼‰
        
        Args:
            content: ç« èŠ‚å†…å®¹
            entity1: å®ä½“1
            entity2: å®ä½“2
            chapter_num: ç« èŠ‚å·
        
        Returns:
            æå–çš„æ®µè½ï¼Œæ ¼å¼ï¼š"[ç¬¬Xç« ] ..."
        """
        # è€ƒè™‘å®ä½“åˆ«åæ¨¡å¼
        entity1_patterns = [
            entity1,
            entity1[:2] if len(entity1) >= 2 else entity1,  # å§“æ°
        ]
        
        entity2_patterns = [
            entity2,
            entity2[:2] if len(entity2) >= 2 else entity2,  # å§“æ°
        ]
        
        # æŸ¥æ‰¾åŒæ—¶åŒ…å«ä¸¤ä¸ªå®ä½“çš„ä½ç½®
        lines = content.split('\n')
        best_match = None
        max_score = 0
        
        for line in lines:
            score = 0
            has_entity1 = any(p in line for p in entity1_patterns)
            has_entity2 = any(p in line for p in entity2_patterns)
            
            if has_entity1:
                score += 1
            if has_entity2:
                score += 1
            
            if score == 2 and score >= max_score:
                # æ‰¾åˆ°åŒ…å«ä¸¤ä¸ªå®ä½“çš„è¡Œ
                idx = content.find(line)
                if idx != -1:
                    # æå–å‰åå„150å­—ç¬¦
                    start = max(0, idx - 150)
                    end = min(len(content), idx + len(line) + 150)
                    context = content[start:end].strip()
                    
                    # é™åˆ¶é•¿åº¦ä¸º400å­—ç¬¦
                    if len(context) > 400:
                        context = context[:400] + "..."
                    
                    best_match = f"[ç¬¬{chapter_num}ç« ] {context}"
                    max_score = score
        
        if best_match:
            return best_match
        
        # å¦‚æœæ²¡æ‰¾åˆ°åŒæ—¶åŒ…å«çš„è¡Œï¼Œå°è¯•æŸ¥æ‰¾é™„è¿‘çš„ï¼ˆèŒƒå›´æ‰©å¤§åˆ°800ï¼‰
        idx1 = -1
        idx2 = -1
        
        for pattern in entity1_patterns:
            idx1 = content.find(pattern)
            if idx1 != -1:
                break
        
        for pattern in entity2_patterns:
            idx2 = content.find(pattern)
            if idx2 != -1:
                break
        
        if idx1 != -1 and idx2 != -1 and abs(idx1 - idx2) < 800:
            start = max(0, min(idx1, idx2) - 100)
            end = min(len(content), max(idx1, idx2) + 200)
            context = content[start:end].strip()
            
            if len(context) > 400:
                context = context[:400] + "..."
            
            return f"[ç¬¬{chapter_num}ç« ] {context}"
        
        return None


# å…¨å±€å®ä¾‹
_relation_classifier = None

def get_relation_classifier() -> RelationshipClassifier:
    """è·å–å…³ç³»åˆ†ç±»å™¨å•ä¾‹"""
    global _relation_classifier
    if _relation_classifier is None:
        _relation_classifier = RelationshipClassifier()
    return _relation_classifier

