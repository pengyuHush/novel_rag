"""
æŸ¥è¯¢ç¼“å­˜æœåŠ¡
å®ç°å†…å­˜ç¼“å­˜ä»¥æå‡é«˜é¢‘æŸ¥è¯¢çš„å“åº”é€Ÿåº¦
"""

import hashlib
import logging
import time
from typing import Optional, Any, Dict
from cachetools import TTLCache

logger = logging.getLogger(__name__)


class QueryCacheService:
    """æŸ¥è¯¢ç¼“å­˜æœåŠ¡"""
    
    def __init__(self, maxsize: int = 1000, ttl: int = 3600):
        """
        åˆå§‹åŒ–ç¼“å­˜æœåŠ¡
        
        Args:
            maxsize: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
            ttl: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 1 å°æ—¶
        """
        self.cache = TTLCache(maxsize=maxsize, ttl=ttl)
        self.hit_count = 0
        self.miss_count = 0
        logger.info(f"âœ… æŸ¥è¯¢ç¼“å­˜æœåŠ¡åˆå§‹åŒ– (maxsize={maxsize}, ttl={ttl}s)")
    
    def _generate_key(
        self, 
        novel_id: int, 
        query: str, 
        model: str,
        enable_query_rewrite: bool = True,
        enable_query_decomposition: bool = True
    ) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®
        
        Args:
            novel_id: å°è¯´ID
            query: æŸ¥è¯¢æ–‡æœ¬
            model: æ¨¡å‹åç§°
            enable_query_rewrite: æ˜¯å¦å¯ç”¨æŸ¥è¯¢æ”¹å†™
            enable_query_decomposition: æ˜¯å¦å¯ç”¨æŸ¥è¯¢åˆ†è§£
        
        Returns:
            str: ç¼“å­˜é”®ï¼ˆå“ˆå¸Œå€¼ï¼‰
        """
        # å°†é…ç½®å‚æ•°ä¹ŸåŒ…å«åœ¨keyä¸­ï¼Œç¡®ä¿ä¸åŒé…ç½®ä¸ä¼šä½¿ç”¨ç›¸åŒç¼“å­˜
        key_string = f"{novel_id}:{query}:{model}:{enable_query_rewrite}:{enable_query_decomposition}"
        return hashlib.md5(key_string.encode('utf-8')).hexdigest()
    
    def get(
        self, 
        novel_id: int, 
        query: str, 
        model: str,
        enable_query_rewrite: bool = True,
        enable_query_decomposition: bool = True
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–ç¼“å­˜ç»“æœ
        
        Args:
            novel_id: å°è¯´ID
            query: æŸ¥è¯¢æ–‡æœ¬
            model: æ¨¡å‹åç§°
            enable_query_rewrite: æ˜¯å¦å¯ç”¨æŸ¥è¯¢æ”¹å†™
            enable_query_decomposition: æ˜¯å¦å¯ç”¨æŸ¥è¯¢åˆ†è§£
        
        Returns:
            Optional[Dict]: ç¼“å­˜çš„ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        key = self._generate_key(novel_id, query, model, enable_query_rewrite, enable_query_decomposition)
        
        if key in self.cache:
            self.hit_count += 1
            logger.info(f"ğŸ¯ ç¼“å­˜å‘½ä¸­ (å‘½ä¸­ç‡: {self.get_hit_rate():.1%})")
            logger.debug(f"ğŸ”§ [DEBUG] ç¼“å­˜keyå‚æ•°: rewrite={enable_query_rewrite}, decomposition={enable_query_decomposition}")
            return self.cache[key]
        else:
            self.miss_count += 1
            logger.debug(f"âšª ç¼“å­˜æœªå‘½ä¸­")
            logger.debug(f"ğŸ”§ [DEBUG] ç¼“å­˜keyå‚æ•°: rewrite={enable_query_rewrite}, decomposition={enable_query_decomposition}")
            return None
    
    def set(
        self, 
        novel_id: int, 
        query: str, 
        model: str, 
        result: Dict[str, Any],
        enable_query_rewrite: bool = True,
        enable_query_decomposition: bool = True
    ):
        """
        è®¾ç½®ç¼“å­˜
        
        Args:
            novel_id: å°è¯´ID
            query: æŸ¥è¯¢æ–‡æœ¬
            model: æ¨¡å‹åç§°
            result: æŸ¥è¯¢ç»“æœ
            enable_query_rewrite: æ˜¯å¦å¯ç”¨æŸ¥è¯¢æ”¹å†™
            enable_query_decomposition: æ˜¯å¦å¯ç”¨æŸ¥è¯¢åˆ†è§£
        """
        key = self._generate_key(novel_id, query, model, enable_query_rewrite, enable_query_decomposition)
        self.cache[key] = {
            'result': result,
            'cached_at': time.time()
        }
        logger.debug(f"ğŸ’¾ ç»“æœå·²ç¼“å­˜ (å½“å‰ç¼“å­˜æ•°: {len(self.cache)})")
    
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.cache.clear()
        self.hit_count = 0
        self.miss_count = 0
        logger.info("ğŸ—‘ï¸ ç¼“å­˜å·²æ¸…ç©º")
    
    def clear_novel(self, novel_id: int):
        """
        æ¸…ç©ºæŒ‡å®šå°è¯´çš„ç¼“å­˜
        
        Args:
            novel_id: å°è¯´ID
        """
        # ç”±äºæˆ‘ä»¬ä½¿ç”¨å“ˆå¸Œé”®ï¼Œæ— æ³•ç›´æ¥æŒ‰ novel_id è¿‡æ»¤
        # ç®€å•å®ç°ï¼šæ¸…ç©ºæ‰€æœ‰ç¼“å­˜ï¼ˆå®é™…ä½¿ç”¨ä¸­å¯ä»¥æ”¹è¿›ä¸ºå¸¦å‰ç¼€çš„é”®ï¼‰
        logger.warning(f"âš ï¸ æ¸…ç©ºæ‰€æœ‰ç¼“å­˜ï¼ˆåŒ…å« novel_id={novel_id}ï¼‰")
        self.clear()
    
    def get_hit_rate(self) -> float:
        """
        è·å–ç¼“å­˜å‘½ä¸­ç‡
        
        Returns:
            float: å‘½ä¸­ç‡ (0.0-1.0)
        """
        total = self.hit_count + self.miss_count
        if total == 0:
            return 0.0
        return self.hit_count / total
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            'size': len(self.cache),
            'maxsize': self.cache.maxsize,
            'hit_count': self.hit_count,
            'miss_count': self.miss_count,
            'hit_rate': self.get_hit_rate()
        }


# å…¨å±€ç¼“å­˜æœåŠ¡å®ä¾‹
_query_cache: Optional[QueryCacheService] = None


def get_query_cache() -> QueryCacheService:
    """è·å–å…¨å±€æŸ¥è¯¢ç¼“å­˜å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _query_cache
    if _query_cache is None:
        _query_cache = QueryCacheService()
    return _query_cache

