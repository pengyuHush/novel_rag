"""
RAGå¼•æ“ - æ£€ç´¢å¢å¼ºç”Ÿæˆ
å®ç°åŸºç¡€RAGæµç¨‹
"""

import logging
from typing import List, Dict, Optional, Tuple
from sqlalchemy.orm import Session

from app.services.embedding_service import get_embedding_service
from app.services.zhipu_client import get_zhipu_client
from app.models.database import Novel, Chapter
from app.models.schemas import Citation, Confidence

logger = logging.getLogger(__name__)


class RAGEngine:
    """RAGå¼•æ“"""
    
    def __init__(self):
        """åˆå§‹åŒ–RAGå¼•æ“"""
        self.embedding_service = get_embedding_service()
        self.zhipu_client = get_zhipu_client()
        self.top_k_retrieval = 30  # æ£€ç´¢Top-30
        self.top_k_rerank = 10     # RerankåTop-10
        
        logger.info("âœ… RAGå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def query_embedding(self, query: str) -> List[float]:
        """
        æŸ¥è¯¢å‘é‡åŒ–
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
        
        Returns:
            List[float]: æŸ¥è¯¢å‘é‡
        """
        return self.zhipu_client.embed_text(query)
    
    def vector_search(
        self,
        novel_id: int,
        query_embedding: List[float],
        top_k: int = None
    ) -> Dict:
        """
        è¯­ä¹‰æ£€ç´¢
        
        Args:
            novel_id: å°è¯´ID
            query_embedding: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›Top-Kç»“æœ
        
        Returns:
            Dict: æ£€ç´¢ç»“æœ
        """
        top_k = top_k or self.top_k_retrieval
        
        from app.core.chromadb_client import get_chroma_client
        chroma_client = get_chroma_client()
        
        collection_name = f"novel_{novel_id}"
        
        try:
            results = chroma_client.query_documents(
                collection_name=collection_name,
                query_embeddings=[query_embedding],
                n_results=top_k
            )
            
            logger.info(f"âœ… è¯­ä¹‰æ£€ç´¢å®Œæˆ: {len(results.get('ids', [[]])[0])} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ è¯­ä¹‰æ£€ç´¢å¤±è´¥: {e}")
            return {'ids': [[]], 'documents': [[]], 'metadatas': [[]], 'distances': [[]]}
    
    def keyword_search(
        self,
        db: Session,
        novel_id: int,
        query: str,
        top_k: int = 10
    ) -> List[Dict]:
        """
        å…³é”®è¯æ£€ç´¢ï¼ˆç®€å•å®ç°ï¼‰
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            novel_id: å°è¯´ID
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›Top-Kç»“æœ
        
        Returns:
            List[Dict]: æ£€ç´¢ç»“æœ
        """
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼ˆå®é™…åº”è¯¥ç”¨å…¨æ–‡ç´¢å¼•ï¼‰
        # è¿™é‡Œåªæ˜¯æ¼”ç¤ºï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥ä½¿ç”¨Elasticsearchç­‰
        logger.info(f"ğŸ” å…³é”®è¯æ£€ç´¢: {query}")
        
        # TODO: å®ç°åŸºäºæ•°æ®åº“çš„å…³é”®è¯æ£€ç´¢
        # æš‚æ—¶è¿”å›ç©ºç»“æœ
        return []
    
    def rerank(
        self,
        query: str,
        vector_results: Dict,
        keyword_results: List[Dict] = None,
        top_k: int = None
    ) -> List[Dict]:
        """
        æ··åˆRerank
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            vector_results: å‘é‡æ£€ç´¢ç»“æœ
            keyword_results: å…³é”®è¯æ£€ç´¢ç»“æœ
            top_k: è¿”å›Top-Kç»“æœ
        
        Returns:
            List[Dict]: Rerankåçš„ç»“æœ
        """
        top_k = top_k or self.top_k_rerank
        
        # æå–å‘é‡æ£€ç´¢ç»“æœ
        documents = vector_results.get('documents', [[]])[0]
        metadatas = vector_results.get('metadatas', [[]])[0]
        distances = vector_results.get('distances', [[]])[0]
        
        # æ„å»ºå€™é€‰æ–‡æ¡£
        candidates = []
        for i, (doc, metadata, distance) in enumerate(zip(documents, metadatas, distances)):
            candidates.append({
                'content': doc,
                'metadata': metadata,
                'score': 1 - distance,  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
                'rank': i + 1
            })
        
        # ç®€å•æ’åºï¼ˆå®é™…å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„Rerankç®—æ³•ï¼‰
        # æŒ‰ç« èŠ‚å·å’Œåˆ†æ•°æ’åº
        candidates.sort(
            key=lambda x: (
                -x['score'],  # åˆ†æ•°é™åº
                x['metadata'].get('chapter_num', 999)  # ç« èŠ‚å·å‡åº
            )
        )
        
        # è¿”å›Top-K
        reranked = candidates[:top_k]
        logger.info(f"âœ… Rerankå®Œæˆ: è¿”å› {len(reranked)} ä¸ªç»“æœ")
        
        return reranked
    
    def build_prompt(
        self,
        db: Session,
        novel_id: int,
        query: str,
        context_chunks: List[Dict]
    ) -> str:
        """
        æ„å»ºRAG Prompt
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            novel_id: å°è¯´ID
            query: æŸ¥è¯¢æ–‡æœ¬
            context_chunks: ä¸Šä¸‹æ–‡å—åˆ—è¡¨
        
        Returns:
            str: æ„å»ºå¥½çš„Prompt
        """
        # è·å–å°è¯´ä¿¡æ¯
        novel = db.query(Novel).filter(Novel.id == novel_id).first()
        novel_title = novel.title if novel else "æœªçŸ¥"
        novel_author = novel.author if novel and novel.author else "æœªçŸ¥"
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for i, chunk in enumerate(context_chunks, 1):
            metadata = chunk['metadata']
            chapter_num = metadata.get('chapter_num', '?')
            chapter_title = metadata.get('chapter_title', '')
            content = chunk['content']
            
            context_parts.append(
                f"[ç‰‡æ®µ{i} - ç¬¬{chapter_num}ç«  {chapter_title}]\n{content}"
            )
        
        context_text = "\n\n".join(context_parts)
        
        # æ„å»ºå®Œæ•´Prompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´é˜…è¯»åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹å°è¯´å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

**å°è¯´ä¿¡æ¯**
- æ ‡é¢˜: {novel_title}
- ä½œè€…: {novel_author}

**ç›¸å…³å†…å®¹**
{context_text}

**ç”¨æˆ·é—®é¢˜**
{query}

**å›ç­”è¦æ±‚**
1. åŸºäºæä¾›çš„å°è¯´å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ 
2. å¦‚æœå†…å®¹ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. å¼•ç”¨æ—¶è¯·æ ‡æ³¨ç« èŠ‚å·
4. å›ç­”è¦å‡†ç¡®ã€å®Œæ•´ã€æœ‰æ¡ç†

**ä½ çš„å›ç­”**:"""
        
        return prompt
    
    def generate_answer(
        self,
        prompt: str,
        model: str = "glm-4",
        stream: bool = False
    ):
        """
        ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            prompt: å®Œæ•´çš„Prompt
            model: ä½¿ç”¨çš„æ¨¡å‹
            stream: æ˜¯å¦æµå¼è¾“å‡º
        
        Returns:
            str | Generator: ç­”æ¡ˆæ–‡æœ¬æˆ–ç”Ÿæˆå™¨
        """
        try:
            messages = [{"role": "user", "content": prompt}]
            
            if stream:
                # æµå¼ç”Ÿæˆ
                for chunk in self.zhipu_client.chat_completion_stream(
                    messages=messages,
                    model=model
                ):
                    if chunk.get("content"):
                        yield chunk["content"]
            else:
                # éæµå¼ç”Ÿæˆ
                response = self.zhipu_client.chat_completion(
                    messages=messages,
                    model=model
                )
                
                logger.info(f"âœ… ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
                return response.get("content", "")
                
        except Exception as e:
            logger.error(f"âŒ ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            if stream:
                yield "æŠ±æ­‰ï¼Œç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯ã€‚"
            else:
                return "æŠ±æ­‰ï¼Œç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯ã€‚"
    
    def query(
        self,
        db: Session,
        novel_id: int,
        query: str,
        model: str = "glm-4"
    ) -> Tuple[str, List[Citation], Dict]:
        """
        å®Œæ•´RAGæŸ¥è¯¢æµç¨‹
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            novel_id: å°è¯´ID
            query: æŸ¥è¯¢æ–‡æœ¬
            model: ä½¿ç”¨çš„æ¨¡å‹
        
        Returns:
            Tuple[str, List[Citation], Dict]: (ç­”æ¡ˆ, å¼•ç”¨åˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯)
        """
        logger.info(f"ğŸ“ å¼€å§‹RAGæŸ¥è¯¢: {query}")
        
        # 1. æŸ¥è¯¢å‘é‡åŒ–
        query_embedding = self.query_embedding(query)
        
        # 2. è¯­ä¹‰æ£€ç´¢
        vector_results = self.vector_search(novel_id, query_embedding)
        
        # 3. å…³é”®è¯æ£€ç´¢ï¼ˆå¯é€‰ï¼‰
        keyword_results = self.keyword_search(db, novel_id, query)
        
        # 4. æ··åˆRerank
        reranked_chunks = self.rerank(query, vector_results, keyword_results)
        
        if not reranked_chunks:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
            return "æŠ±æ­‰ï¼Œåœ¨å°è¯´ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚", [], {}
        
        # 5. æ„å»ºPrompt
        prompt = self.build_prompt(db, novel_id, query, reranked_chunks)
        
        # 6. ç”Ÿæˆç­”æ¡ˆ
        answer = self.generate_answer(prompt, model, stream=False)
        
        # 7. æ„å»ºå¼•ç”¨åˆ—è¡¨
        citations = []
        seen_chapters = set()
        
        for chunk in reranked_chunks:
            metadata = chunk['metadata']
            chapter_num = metadata.get('chapter_num')
            
            # å»é‡ï¼ˆæ¯ç« æœ€å¤šä¸€æ¡å¼•ç”¨ï¼‰
            if chapter_num in seen_chapters:
                continue
            seen_chapters.add(chapter_num)
            
            citations.append(Citation(
                chapter_num=chapter_num,
                chapter_title=metadata.get('chapter_title'),
                text=chunk['content'][:200] + "...",  # æˆªæ–­æ˜¾ç¤º
                score=chunk.get('score')
            ))
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'retrieved_chunks': len(vector_results.get('ids', [[]])[0]),
            'reranked_chunks': len(reranked_chunks),
            'citations': len(citations)
        }
        
        logger.info(f"âœ… RAGæŸ¥è¯¢å®Œæˆ: {len(citations)} æ¡å¼•ç”¨")
        
        return answer, citations, stats


# å…¨å±€RAGå¼•æ“å®ä¾‹
_rag_engine: Optional[RAGEngine] = None


def get_rag_engine() -> RAGEngine:
    """è·å–å…¨å±€RAGå¼•æ“å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _rag_engine
    if _rag_engine is None:
        _rag_engine = RAGEngine()
    return _rag_engine

