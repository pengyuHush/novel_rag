# RAG系统提示词文档

本文档整理了小说RAG系统中所有检索和查询阶段使用的提示词，方便进行统一的优化和调整。

---

## 目录

1. [查询改写阶段](#1-查询改写阶段)
   - 1.1 对话类查询改写
   - 1.2 分析类查询改写
   - 1.3 事实类查询改写
2. [答案生成阶段](#2-答案生成阶段)
   - 2.1 对话类查询提示词
   - 2.2 分析类查询提示词
   - 2.3 事实类查询提示词
3. [Self-RAG验证阶段](#3-self-rag验证阶段)
   - 3.1 断言提取（暂无LLM提示词）
   - 3.2 证据收集（暂无LLM提示词）
   - 3.3 答案修正（暂无LLM提示词）

---

## 1. 查询改写阶段

**文件位置**: `backend/app/services/query_rewriter.py`

**使用模型**: GLM-4-Flash-250414

**目的**: 将用户的原始查询改写为更利于检索的形式，提升召回率和精度。

---

### 1.1 对话类查询改写

**触发条件**: 查询包含"说"、"讲"、"提到"、"回答"等对话关键词

**策略**: 添加"说""道""台词"等关键词，明确对话场景和说话者

**提示词**:

```
你是查询优化专家。请将用户的对话类查询改写为更利于检索小说对话内容的形式。

查询类型：对话类（询问角色的对话、台词）

原始查询：{query}

改写要求：
1. 保留核心语义和关键信息（人物、场景）
2. 添加对话相关的关键词，如："说"、"道"、"回答"、"讲"、"台词"、"对话"等
3. 明确对话的上下文（如果原查询有提及）
4. 改写后的查询应该更容易匹配小说中的对话场景
5. 保持查询简洁，不要过度扩展

示例1：
原始："张无忌和赵敏怎么认识的"
改写："张无忌和赵敏初次见面时说了什么 两人的对话"

示例2：
原始："令狐冲在思过崖学到了什么武功"
改写："令狐冲在思过崖提到学了什么武功 说过的话"

请直接输出改写后的查询，不要有其他解释：
```

**温度参数**: 0.3（较低温度保证稳定性）

**最大Token数**: 200

---

### 1.2 分析类查询改写

**触发条件**: 查询包含"为什么"、"怎么"、"如何"、"原因"、"演变"等分析关键词

**策略**: 添加"原因""过程""影响"等关键词，明确时间、因果关系

**提示词**:

```
你是查询优化专家。请将用户的分析类查询改写为更利于检索小说情节和因果关系的形式。

查询类型：分析类（需要综合分析、推理的问题）

原始查询：{query}

改写要求：
1. 保留核心语义和关键信息（人物、事件）
2. 添加分析相关的关键词，如："原因"、"过程"、"结果"、"影响"、"变化"、"发展"等
3. 明确因果关系和时间顺序（如果原查询有提及）
4. 可以适当添加同义词或相关概念
5. 改写后的查询应该更容易匹配小说中的情节分析和因果描述
6. 保持查询相对简洁

示例1：
原始："为什么张无忌成为明教教主"
改写："张无忌成为明教教主的原因和过程 如何当上教主的经过"

示例2：
原始："令狐冲和岳灵珊的感情"
改写："令狐冲和岳灵珊感情发展变化过程 从相爱到分离的原因"

请直接输出改写后的查询，不要有其他解释：
```

**温度参数**: 0.3

**最大Token数**: 200

---

### 1.3 事实类查询改写

**触发条件**: 默认类型（不属于对话类或分析类）

**策略**: 添加同义词，明确查询意图

**提示词**:

```
你是查询优化专家。请将用户的事实类查询改写为更利于检索小说具体信息的形式。

查询类型：事实类（询问具体事实、情节细节）

原始查询：{query}

改写要求：
1. 保留核心语义和关键信息
2. 添加同义词或相关表达方式
3. 明确查询对象（人物、地点、事件等）
4. 改写后的查询应该更容易匹配小说中的具体描述
5. 保持查询简洁明确

示例1：
原始："张三丰的武功"
改写："张三丰的武功实力 会什么武学招式"

示例2：
原始："华山派在哪里"
改写："华山派的地点位置 山门所在"

请直接输出改写后的查询，不要有其他解释：
```

**温度参数**: 0.3

**最大Token数**: 200

---

## 2. 答案生成阶段

**文件位置**: `backend/app/services/adaptive_prompt_builder.py`

**使用模型**: GLM-4-Plus（或配置的主模型）

**目的**: 根据查询类型和检索到的上下文生成高质量答案。

**上下文格式**:
```
[片段X - 《小说标题》 - 第Y章 章节标题]
片段内容...
```

**注意**: 多小说查询时，会在上下文中标注来源小说，并在提示词中添加多小说提示。

---

### 2.1 对话类查询提示词

**查询特征**: 询问角色的对话、台词

**Few-shot示例**:

```
示例问答：
问题：萧峰在聚贤庄说了什么？
回答：萧峰在聚贤庄大声说道："我萧峰大好男儿，何惧于死？今日既然来到聚贤庄，便是来赴死的！"（第42章）他还说："诸位英雄，萧峰平生不敢做之事，便是对不起朋友。"（第42章）这些话表达了他宁死不屈的决心和重情重义的品格。
```

**主提示词模板**:

```
你是小说对话分析专家。请从以下片段中提取与问题相关的对话内容。

**小说信息**
- 标题: {novel_title}
- 作者: {novel_author}
[多小说时] **注意**: 以下片段来自多本小说，请在回答时明确标注每段对话来自哪本小说和哪一章。

**相关片段**
{context_text}

**用户问题**
{query}

**回答要求**
1. **直接引用原文对话**，使用引号标注（如："张无忌说道：'……'"）
2. 标注说话者和对话所在的章节号[多小说时] 以及小说名称（多本小说时）
3. 如有必要，简要说明对话发生的背景或场景
4. 如果片段中没有相关对话，请明确说明
5. 保持对话的完整性，不要断章取义
6. [多小说时] 综合多本小说的内容，给出全面完整的回答 / [单小说时] 基于小说内容给出完整的回答

{few_shot_examples}

**你的回答**:
```

**特点**:
- 强调直接引用原文对话
- 要求使用引号标注
- 标注说话者和章节
- 多小说时要求标注来源

---

### 2.2 分析类查询提示词

**查询特征**: 需要综合分析、推理的问题（为什么、如何、演变）

**Few-shot示例**:

```
示例问答：
问题：令狐冲为何被逐出华山派？
回答：令狐冲被逐出华山派主要有三个原因：

第一，在思过崖学习了"吸星大法"等魔教武功（第13章）。令狐冲因伤被困思过崖时，无意中发现了魔教长老留下的武功秘籍，出于好奇和求生本能学习了这些武功。

第二，与魔教长老向问天结交，被怀疑投靠魔教（第18章）。令狐冲救了向问天一命，两人结为好友，这让岳不群更加怀疑他与魔教有染。

第三，与小师妹岳灵珊的感情破裂，失去了师门庇护（第21章）。岳灵珊移情别恋林平之后，岳不群借机清理门户，以"行为不端、私学魔功"为由将令狐冲逐出师门。

综合以上因素，岳不群的野心和猜忌是令狐冲被逐的根本原因。
```

**主提示词模板**:

```
你是小说情节分析专家。请基于以下片段进行深度分析。

**小说信息**
- 标题: {novel_title}
- 作者: {novel_author}
[多小说时] **注意**: 以下片段来自多本小说，请综合分析不同小说中的相关内容，并在回答时标注来源。

**相关片段**
{context_text}

**用户问题**
{query}

**回答要求**
1. 首先梳理关键情节和时间线
2. 分析因果关系和人物动机
3. 综合多个片段，形成连贯的解释
4. 标注引用的章节范围[多小说时] 和小说名称（多本小说时）
5. 如果信息不足以完整回答，请说明缺失的信息
6. [多小说时] 对比分析不同小说中的相关内容，给出全面深入的分析 / [单小说时] 基于小说内容给出深入的分析

**思考步骤**（请按此步骤组织回答）：
第1步：识别问题中的关键要素（人物、事件、时间）
第2步：从提供的片段中定位相关信息
第3步：建立信息之间的因果关系或时序关系
第4步：形成连贯的解释和结论

{few_shot_examples}

**你的回答**:
```

**特点**:
- 引导逐步推理
- 添加Chain of Thought（思考步骤）
- 要求综合多个片段
- 多小说时要求对比分析

---

### 2.3 事实类查询提示词

**查询特征**: 询问具体事实、情节细节

**Few-shot示例**:

```
示例问答：
问题：张三丰活了多少岁？
回答：张三丰活了至少200岁以上。在《倚天屠龙记》中，张三丰创立武当派时已是百岁高龄，到张无忌时代仍然健在（第1章、第24章），是武林中德高望重的宗师级人物。
```

**主提示词模板**:

```
你是小说内容助手。请准确回答用户的事实性问题。

**小说信息**
- 标题: {novel_title}
- 作者: {novel_author}
[多小说时] **注意**: 以下片段来自多本小说，请在回答时明确标注信息来自哪本小说。

**相关片段**
{context_text}

**用户问题**
{query}

**回答要求**
1. 回答必须基于提供的片段内容
2. 如片段内容不足以回答，明确说明缺少哪些信息
3. 标注信息来源章节[多小说时] 和小说名称（多本小说时）
4. 回答要简洁明确，直击要点
5. 不要添加推测或编造信息
6. [多小说时] 综合多本小说的信息，给出完整准确的回答 / [单小说时] 基于小说内容给出准确的回答

{few_shot_examples}

**你的回答**:
```

**特点**:
- 强调准确性
- 要求简洁明确
- 明确信息来源
- 多小说时要求综合信息

---

## 3. Self-RAG验证阶段

**文件位置**: 
- `backend/app/services/self_rag/assertion_extractor.py`
- `backend/app/services/self_rag/evidence_collector.py`
- `backend/app/services/self_rag/answer_corrector.py`

**目的**: 对生成的答案进行自我验证和修正，确保答案的准确性和一致性。

**注意**: 当前Self-RAG阶段主要使用规则和检索方法，暂无LLM提示词。

---

### 3.1 断言提取

**方法**: 基于规则的句子分析

**流程**:
1. 将答案按句子分割
2. 检测断言类型（fact/relation/event）
3. 提取实体和章节引用
4. 计算置信度

**断言类型关键词**:
- **事件类**: 发生、出现、开始、结束、离开、到达、战斗、死亡
- **关系类**: 关系、认识、朋友、敌人、师傅、徒弟、父子、母女
- **事实类**: 是、为、在、有、没有、属于、来自

**暂无LLM提示词**

---

### 3.2 证据收集

**方法**: 多源检索（向量检索 + 关键词检索 + 图谱检索）

**流程**:
1. 向量检索：使用断言文本进行语义搜索
2. 关键词检索：基于实体和章节引用进行精确搜索
3. 图谱检索：查询实体之间的关系演变

**证据来源**:
- `vector`: 向量数据库检索
- `keyword`: BM25关键词检索
- `graph`: 知识图谱查询

**暂无LLM提示词**

---

### 3.3 答案修正

**方法**: 基于矛盾检测的规则修正

**流程**:
1. 对每个断言收集多源证据
2. 检测证据之间的矛盾
3. 根据矛盾严重程度修正答案

**修正策略**:
- **高置信度矛盾**: 在答案末尾添加矛盾说明和不确定性标注
- **中等置信度矛盾**: 添加轻量级提示
- **低置信度矛盾**: 仅添加警告

**输出格式**:
```
⚠️ **注意**：以上答案存在以下矛盾，请结合原文仔细判断：

**矛盾提示 1**：{矛盾分析}
- 第X章：{早期描述}
- 第Y章：{后期描述}
```

**暂无LLM提示词**

---

## 4. 查询类型检测

**文件位置**: `backend/app/services/query_router.py`

**方法**: 基于关键词和正则匹配的规则分类

**查询类型**:

### 4.1 对话类 (DIALOGUE)

**关键词**: 说、讲、提到、回答、问、告诉、谈、说话、对话、聊天、交流、沟通、说道、问道、答道、喊道、叫道、笑道、哭着说

**正则模式**:
- `对.{0,5}说`
- `跟.{0,5}讲`
- `向.{0,5}提`
- `告诉.{0,5}`

**检索策略**:
- top_k: 15（对话块较短，增加检索数量）
- chunk_merge: False（不合并，保留对话完整性）
- quote_weight: 1.5（引号内容权重×1.5）
- prefer_dialogue: True（优先对话块）

---

### 4.2 分析类 (ANALYSIS)

**关键词**: 为什么、怎么、如何、原因、动机、目的、演变、变化、发展、转变、改变、成长、分析、解释、理解、探讨、研究、关系、影响、意义、作用、价值

**正则模式**:
- `为何`
- `缘何`
- `因何`
- `凭什么`

**演变分析子类型关键词**: 演变、变化、发展、转变、改变、成长、从...到、前期、中期、后期、早期、晚期、最初、最后、开始、结束、经历、历程

**检索策略**:
- top_k: 20（分析需要更多上下文）
- chunk_merge: True（合并相邻块获取完整语境）
- quote_weight: 1.0（无特殊权重）
- prefer_dialogue: False

---

### 4.3 事实类 (FACT)

**特征**: 默认类型（不属于对话类或分析类）

**典型问题**: "XX是谁"、"XX在哪"、"XX的武功"

**检索策略**:
- top_k: 10（标准检索数量）
- chunk_merge: False（标准块大小）
- quote_weight: 1.0
- prefer_dialogue: False

---

## 5. 提示词优化建议区域

### 5.1 查询改写优化方向

**当前问题**:
- [ ] 改写示例较少，可能不够全面
- [ ] 温度参数固定为0.3，可能需要根据查询复杂度动态调整
- [ ] 缺少对多小说查询的特殊处理

**优化方向**:
- [ ] 增加更多改写示例，覆盖更多场景
- [ ] 添加改写质量评估机制
- [ ] 针对多小说查询添加特殊改写策略

---

### 5.2 答案生成优化方向

**当前问题**:
- [ ] Few-shot示例固定，可能不适配所有小说类型（武侠、玄幻、现代等）
- [ ] 多小说查询的提示较弱，可能导致答案过于简洁
- [ ] 缺少对长答案的结构化指导

**优化方向**:
- [ ] 根据小说类型动态选择Few-shot示例
- [ ] 加强多小说查询的提示，明确要求综合和对比
- [ ] 添加答案结构化模板（如：总-分-总结构）
- [ ] 添加答案长度控制机制

---

### 5.3 Self-RAG优化方向

**当前问题**:
- [ ] 断言提取完全基于规则，可能不够准确
- [ ] 缺少矛盾检测的LLM判断环节
- [ ] 答案修正过于机械，缺少智能重写

**优化方向**:
- [ ] 引入LLM进行断言提取和验证
- [ ] 使用LLM判断证据之间是否真正矛盾
- [ ] 实现基于LLM的智能答案重写（而非简单追加警告）

---

## 6. 参数配置

### 6.1 查询改写参数

| 参数 | 值 | 说明 |
|------|-----|------|
| model | GLM-4-Flash-250414 | 使用免费快速模型 |
| temperature | 0.3 | 较低温度保证稳定性 |
| max_tokens | 200 | 改写查询不需要太长 |

---

### 6.2 答案生成参数

| 参数 | 值 | 说明 |
|------|-----|------|
| model | GLM-4-Plus | 主力模型（可配置） |
| temperature | 根据配置 | 一般0.7-0.9 |
| max_tokens | 根据配置 | 一般2000-4000 |
| max_chunks | 10 | 最大使用的上下文块数量 |
| include_few_shot | True | 是否包含Few-shot示例 |

---

### 6.3 检索参数

| 查询类型 | top_k | chunk_merge | quote_weight | prefer_dialogue |
|----------|-------|-------------|--------------|-----------------|
| DIALOGUE | 15 | False | 1.5 | True |
| ANALYSIS | 20 | True | 1.0 | False |
| FACT | 10 | False | 1.0 | False |

---

## 7. 查询改写的应用范围

### 7.1 查询改写在不同阶段的使用

### 8.1 查询改写在不同阶段的使用

查询改写功能有两个配置选项：

1. **`enable_query_rewrite`** (启用查询改写)
   - 控制是否启用查询改写功能
   - 默认值：`true`（推荐开启）
   - 影响：是否调用LLM对用户查询进行优化改写

2. **`use_rewritten_in_prompt`** (Prompt中使用改写查询)
   - 控制在生成答案时是否使用改写后的查询
   - 默认值：`false`（推荐保持关闭）
   - 影响：Prompt中使用原始查询还是改写后的查询

### 8.2 推荐配置

#### 配置方案一：标准模式（推荐）✅

```
enable_query_rewrite: true
use_rewritten_in_prompt: false
```

**工作流程**:
1. 用户输入："令狐冲在思过崖学到了什么武功"
2. 查询改写：优化为 "令狐冲在思过崖提到学了什么武功 说过的话"
3. **检索阶段**：使用改写后的查询进行向量化、检索、重排序
4. **生成阶段**：Prompt中使用原始查询 "令狐冲在思过崖学到了什么武功"

**优点**:
- ✅ 检索召回率高（改写添加了关键词）
- ✅ 答案贴合用户意图（针对原始问题回答）
- ✅ 用户体验好（不会答非所问）

---

#### 配置方案二：全程改写模式

```
enable_query_rewrite: true
use_rewritten_in_prompt: true
```

**工作流程**:
1. 用户输入："令狐冲在思过崖学到了什么武功"
2. 查询改写：优化为 "令狐冲在思过崖提到学了什么武功 说过的话"
3. **检索阶段**：使用改写后的查询
4. **生成阶段**：Prompt中也使用改写后的查询

**优点**:
- ✅ 语义一致性更强（检索和生成使用同一查询）

**缺点**:
- ❌ 可能导致答非所问（LLM回答改写后的问题，而非用户原始问题）
- ❌ 用户体验较差

---

#### 配置方案三：禁用改写模式

```
enable_query_rewrite: false
use_rewritten_in_prompt: false（此时无效）
```

**工作流程**:
1. 用户输入："令狐冲在思过崖学到了什么武功"
2. **检索阶段**：直接使用原始查询
3. **生成阶段**：Prompt中使用原始查询

**优点**:
- ✅ 速度快（省去改写步骤）
- ✅ Token消耗少

**缺点**:
- ❌ 检索召回率可能较低
- ❌ 答案可能不够全面

---

### 8.3 前端配置入口

用户可以在查询配置弹窗中调整这两个选项：

1. **"启用查询改写（检索阶段）"** → `enable_query_rewrite`
2. **"Prompt中使用改写查询"** → `use_rewritten_in_prompt`

注意：只有启用了"查询改写"，"Prompt中使用改写查询"选项才可用。

---

## 8. 版本历史

### v1.1 (2024-11-21)
- 新增配置项：`use_rewritten_in_prompt`
- 支持用户控制是否在Prompt中使用改写后的查询
- 更新文档，说明查询改写的应用范围和推荐配置

### v1.0 (2024-11-21)
- 初始版本
- 整理了所有现有提示词
- 添加了优化建议区域

---

## 9. 使用说明

1. **修改提示词**: 直接在本文档中编辑提示词模板
2. **同步到代码**: 将修改后的提示词复制到对应的Python文件中
3. **测试验证**: 在测试环境中验证提示词效果
4. **记录变更**: 在版本历史中记录重要修改

**注意**: 修改提示词时，请保持占位符格式不变（如 `{query}`, `{context_text}` 等）

---

## 10. 相关文件路径

- 查询改写: `backend/app/services/query_rewriter.py`
- 答案生成: `backend/app/services/adaptive_prompt_builder.py`
- 查询路由: `backend/app/services/query_router.py`
- 断言提取: `backend/app/services/self_rag/assertion_extractor.py`
- 证据收集: `backend/app/services/self_rag/evidence_collector.py`
- 答案修正: `backend/app/services/self_rag/answer_corrector.py`

