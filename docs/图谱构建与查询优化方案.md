# çŸ¥è¯†å›¾è°±æ„å»ºä¸æŸ¥è¯¢ä¼˜åŒ–æ–¹æ¡ˆ

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> **åˆ›å»ºæ—¥æœŸ**: 2025-11-18  
> **é€‚ç”¨ç³»ç»Ÿ**: ç½‘ç»œå°è¯´æ™ºèƒ½é—®ç­”ç³»ç»Ÿ

---

## ğŸ“‹ ç›®å½•

- [1. å½“å‰å®ç°åˆ†æ](#1-å½“å‰å®ç°åˆ†æ)
- [2. ä¸PRDè®¾è®¡çš„å·®å¼‚](#2-ä¸prdè®¾è®¡çš„å·®å¼‚)
- [3. ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡](#3-ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡)
- [4. æˆæœ¬ä¸æ—¶é—´ä¼°ç®—](#4-æˆæœ¬ä¸æ—¶é—´ä¼°ç®—)
- [5. åŠ é€Ÿä¼˜åŒ–æ–¹æ¡ˆ](#5-åŠ é€Ÿä¼˜åŒ–æ–¹æ¡ˆ)
- [6. å›¾è°±åœ¨æ£€ç´¢é˜¶æ®µçš„å¢å¼ºç”¨æ³•](#6-å›¾è°±åœ¨æ£€ç´¢é˜¶æ®µçš„å¢å¼ºç”¨æ³•)
- [7. å®æ–½è·¯çº¿å›¾](#7-å®æ–½è·¯çº¿å›¾)

---

## 1. å½“å‰å®ç°åˆ†æ

### 1.1 ç°çŠ¶æ¦‚è¿°

**ä½ç½®**: `backend/app/services/indexing_service.py` (ç¬¬358-463è¡Œ)

å½“å‰å›¾è°±æ„å»ºæµç¨‹ï¼š

```python
# é˜¶æ®µ4: çŸ¥è¯†å›¾è°±æ„å»º
1. åˆ›å»ºç©ºå›¾è°±ï¼ˆMultiDiGraphï¼‰
2. æ·»åŠ å®ä½“èŠ‚ç‚¹ï¼ˆcharacters, locations, organizationsï¼‰
   - èŠ‚ç‚¹å±æ€§ï¼šentity_name, entity_type, first_chapter, last_chapter, mention_count
3. æ·»åŠ å…³ç³»è¾¹ï¼ˆåŸºäºç« èŠ‚çº§å…±ç°ï¼‰
   - è¿‡æ»¤æ¡ä»¶ï¼šå…±ç°æ¬¡æ•° >= 3
   - å…³ç³»ç±»å‹ï¼šç»Ÿä¸€æ ‡è®°ä¸º"å…±ç°"
   - å…³ç³»å¼ºåº¦ï¼šmin(count / 20.0, 1.0)
   - åŒå‘è¾¹ï¼ˆå¯¹ç§°å…³ç³»ï¼‰
4. è®¡ç®—PageRanké‡è¦æ€§
5. è®¡ç®—ç« èŠ‚é‡è¦æ€§ï¼ˆæ–°å¢å®ä½“30% + å…³ç³»å˜åŒ–50% + äº‹ä»¶å¯†åº¦20%ï¼‰
6. æŒä¹…åŒ–ä¿å­˜ï¼ˆpickleæ ¼å¼ï¼‰
```

### 1.2 å·²å®ç°åŠŸèƒ½ âœ…

| åŠŸèƒ½ | å®ç°çŠ¶æ€ | è¯´æ˜ |
|------|---------|------|
| **èŠ‚ç‚¹æ„å»º** | âœ… å®Œæˆ | æ”¯æŒ3ç§å®ä½“ç±»å‹ï¼Œè®°å½•ç« èŠ‚èŒƒå›´ |
| **å…±ç°å…³ç³»** | âœ… å®Œæˆ | åŸºäºç« èŠ‚å…±ç°ï¼Œè®¡ç®—å…³ç³»å¼ºåº¦ |
| **PageRank** | âœ… å®Œæˆ | å®ä½“é‡è¦æ€§è¯„åˆ† |
| **ç« èŠ‚é‡è¦æ€§** | âœ… å®Œæˆ | åŠ¨æ€è¯„åˆ†ï¼Œç”¨äºæ£€ç´¢rerank |
| **å›¾è°±æŒä¹…åŒ–** | âœ… å®Œæˆ | pickleæ ¼å¼å­˜å‚¨ï¼Œæ”¯æŒåŠ è½½ |

### 1.3 å½“å‰åœ¨æ£€ç´¢ä¸­çš„åº”ç”¨

**ä½ç½®**: `backend/app/services/rag_engine.py` (ç¬¬451-530è¡Œ)

```python
# GraphRAGé›†æˆ
1. åŠ è½½çŸ¥è¯†å›¾è°±ï¼ˆnovel_idï¼‰
2. è®¡ç®—ç« èŠ‚é‡è¦æ€§è¯„åˆ†ï¼ˆç¼“å­˜ï¼‰
3. åœ¨reranké˜¶æ®µåº”ç”¨ï¼š
   - å®ä½“åŒ¹é…å¾—åˆ†ï¼ˆ_calculate_entity_match_scoreï¼‰
   - ç« èŠ‚é‡è¦æ€§æƒé‡ï¼ˆåˆ†æç±»æŸ¥è¯¢ï¼‰
   - æ—¶é—´è¡°å‡è°ƒæ•´
```

---

## 2. ä¸PRDè®¾è®¡çš„å·®å¼‚

### 2.1 æ ¸å¿ƒå·®å¼‚å¯¹æ¯”

| åŠŸèƒ½ | PRDè®¾è®¡è¦æ±‚ | å½“å‰å®ç° | å·®å¼‚ç­‰çº§ |
|------|------------|---------|---------|
| **å…³ç³»ç±»å‹** | å…·ä½“è¯­ä¹‰å…³ç³»ï¼ˆç›Ÿå‹/æ•Œå¯¹/å¸ˆå¾’ç­‰ï¼‰ | ç»Ÿä¸€æ ‡è®°ä¸º"å…±ç°" | âš ï¸ **ä¸¥é‡** |
| **å…³ç³»æ¼”å˜** | evolutionåˆ—è¡¨è®°å½•æ¼”å˜è½¨è¿¹ | âŒ æ—  | âš ï¸ **ä¸¥é‡** |
| **èŠ‚ç‚¹attributes** | æ€§åˆ«ã€é˜µè¥ç­‰å±æ€§å­—å…¸ | âŒ æ—  | âš ï¸ ä¸­ç­‰ |
| **è¾¹çš„æ—¶åºå±æ€§** | start_chapter, end_chapter | âœ… æœ‰ | âœ… ç¬¦åˆ |
| **å…³ç³»å¼ºåº¦** | 0-1æ ‡å‡†åŒ– | âœ… æœ‰ | âœ… ç¬¦åˆ |

### 2.2 å½±å“åˆ†æ

**å…³é”®é—®é¢˜**ï¼š

1. **å™è¿°è¯¡è®¡æ£€æµ‹èƒ½åŠ›å—é™** âš ï¸ é«˜ä¼˜å…ˆçº§
   - PRDæ ¸å¿ƒåŠŸèƒ½ï¼š"è§’è‰²ç«‹åœºæ¼”å˜"æ£€æµ‹ï¼ˆç¬¬393è¡Œï¼‰
   - å½“å‰æ— æ³•è¯†åˆ«"æ•Œäººâ†’ä¸­ç«‹â†’ç›Ÿå‹"çš„æ¼”å˜
   - ç›´æ¥å½±å“å‡†ç¡®ç‡ç›®æ ‡ï¼ˆè¯¡è®¡è¯†åˆ«ç‡ç›®æ ‡ï¼š72% â†’ 88%ï¼‰

2. **å…³ç³»æŸ¥è¯¢å‡†ç¡®æ€§ä¸è¶³** âš ï¸ é«˜ä¼˜å…ˆçº§
   - æ— æ³•åŒºåˆ†"å¸ˆå¾’"ã€"ç›Ÿå‹"ã€"æ•Œå¯¹"ç­‰å…·ä½“å…³ç³»
   - å½±å“ç”¨æˆ·æŸ¥è¯¢åœºæ™¯2ï¼š"Aè§’è‰²å’ŒBè§’è‰²æ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ"

3. **å®ä½“å±æ€§ç¼ºå¤±** âš ï¸ ä¸­ä¼˜å…ˆçº§
   - æ— æ³•æ”¯æŒå±æ€§çº¦æŸæŸ¥è¯¢ï¼ˆå¦‚"ç”·æ€§åæ´¾è§’è‰²"ï¼‰
   - å½±å“æŸ¥è¯¢ç²¾åº¦å’Œè¿‡æ»¤èƒ½åŠ›

---

## 3. ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡

### 3.1 ä¼˜åŒ–æ–¹æ¡ˆæ€»è§ˆ

| ä¼˜å…ˆçº§ | ä¼˜åŒ–é¡¹ | æ ¸å¿ƒä»·å€¼ | å·¥ä½œé‡ |
|--------|-------|---------|--------|
| **P0** | å…³ç³»ç±»å‹è¯†åˆ« | æ”¯æŒå™è¿°è¯¡è®¡æ£€æµ‹ | 2-3å¤© |
| **P0** | å…³ç³»æ¼”å˜è¿½è¸ª | è§’è‰²ç«‹åœºæ¼”å˜åˆ†æ | 2-3å¤© |
| **P1** | å®ä½“å±æ€§æå– | æå‡æŸ¥è¯¢ç²¾åº¦ | 1-2å¤© |
| **P2** | å…³ç³»å¼ºåº¦ä¼˜åŒ– | ç»¼åˆå¤šå› ç´ è¯„åˆ† | 0.5å¤© |
| **P2** | å…±ç°é˜ˆå€¼åŠ¨æ€è°ƒæ•´ | å‡å°‘å™ªéŸ³å…³ç³» | 0.5å¤© |

---

### 3.2 ä¼˜åŒ–1ï¼šå…³ç³»ç±»å‹è¯†åˆ«ï¼ˆP0ï¼‰

#### è®¾è®¡æ–¹æ¡ˆ

```python
class RelationshipClassifier:
    """ä½¿ç”¨LLMè¯†åˆ«è§’è‰²é—´çš„å…³ç³»ç±»å‹ï¼ˆå·²ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
    
    RELATION_TYPES = [
        'å¸ˆå¾’',      # æ˜ç¡®çš„å¸ˆå¾’å…³ç³»
        'ç›Ÿå‹',      # åˆä½œã€å‹å¥½å…³ç³»
        'æ•Œå¯¹',      # å¯¹ç«‹ã€æ•Œå¯¹å…³ç³»
        'äº²å±',      # å®¶æ—ã€è¡€ç¼˜å…³ç³»
        'æ‹äºº',      # æ‹çˆ±å…³ç³»
        'åŒé—¨',      # åŒä¸€ç»„ç»‡æˆ–é—¨æ´¾
        'ä¸­ç«‹',      # æ— æ˜æ˜¾å…³ç³»
        'å…±ç°'       # ä»…å…±åŒå‡ºç°ï¼Œæ— æ˜ç¡®å…³ç³»
    ]
    
    async def classify_relationship(
        self,
        entity1: str,
        entity2: str,
        contexts: List[str],  # 3-5ä¸ªå…¸å‹å…±ç°ç‰‡æ®µï¼ˆä¼˜åŒ–ï¼šå¢åŠ åˆ°5ä¸ªï¼‰
        cooccurrence_count: int = 0,  # æ–°å¢ï¼šå…±ç°æ¬¡æ•°
        chapter_range: str = ""  # æ–°å¢ï¼šç« èŠ‚èŒƒå›´
    ) -> Dict:
        """
        ä½¿ç”¨GLM-4.5-Flashè¿›è¡Œå…³ç³»åˆ†ç±»ï¼ˆå·²ä¼˜åŒ–ï¼‰
        
        ä¼˜åŒ–ç‚¹ï¼š
        1. Few-shotç¤ºä¾‹å¼•å¯¼
        2. è¯¦ç»†çš„å…³ç³»ç±»å‹å®šä¹‰å’Œå…³é”®è¯
        3. æ›´é•¿çš„ä¸Šä¸‹æ–‡ï¼ˆ300å­—ç¬¦ï¼‰
        4. æ›´å¤šç‰‡æ®µï¼ˆ5ä¸ªï¼‰
        5. ä¼ é€’å…±ç°ç»Ÿè®¡ä¿¡æ¯
        6. é™ä½temperatureæé«˜ç¨³å®šæ€§
        
        Returns:
            {
                'relation_type': 'å¸ˆå¾’',
                'confidence': 0.9,
                'reasoning': '...'
            }
        """
        # æ„å»ºå¢å¼ºPromptï¼ˆæ›´é•¿ä¸Šä¸‹æ–‡ï¼‰
        context_text = ""
        for i, ctx in enumerate(contexts[:5], 1):
            context_text += f"\nã€ç‰‡æ®µ{i}ã€‘{ctx[:300]}\n"
        
        # Few-shotç¤ºä¾‹
        few_shot = """## ç¤ºä¾‹åˆ†æ

ç¤ºä¾‹1ï¼š
ã€ç‰‡æ®µã€‘è§ç‚æ­æ•¬åœ°å¯¹ç€æˆ’æŒ‡è¡Œç¤¼ï¼š"å¸ˆçˆ¶ï¼Œå¼Ÿå­æ˜ç™½äº†ã€‚"è¯è€å¾®ç¬‘é“ï¼š"å­©å­ï¼Œä¿®ç‚¼ä¸å¯æ€¥èºã€‚"ä¹‹åè¯è€ä¼ æˆè§ç‚ç‚¼è¯å¿ƒæ³•...
ã€åˆ¤æ–­ã€‘å¸ˆå¾’ï¼ˆç½®ä¿¡åº¦0.98ï¼‰- æ˜ç¡®çš„å¸ˆçˆ¶ç§°å‘¼å’Œä¼ æˆå…³ç³»

ç¤ºä¾‹2ï¼š
ã€ç‰‡æ®µã€‘è§ç‚å’Œè§è–°å„¿å¹¶è‚©è€Œç«‹ï¼Œä¸¤äººåæŒ‡ç›¸æ‰£ã€‚è–°å„¿æ¸©æŸ”åœ°çœ‹ç€è§ç‚ï¼Œçœ¼ä¸­æ»¡æ˜¯çˆ±æ„...
ã€åˆ¤æ–­ã€‘æ‹äººï¼ˆç½®ä¿¡åº¦0.95ï¼‰- æ˜æ˜¾çš„äº²å¯†äº’åŠ¨å’Œæ„Ÿæƒ…è¡¨è¾¾

ç¤ºä¾‹3ï¼š
ã€ç‰‡æ®µã€‘é­‚å¤©å¸å†·ç¬‘ï¼š"è§ç‚ï¼Œä»Šæ—¥å°±æ˜¯ä½ çš„æ­»æœŸï¼"è§ç‚æ€’å¼ï¼š"é­‚æ—å®³æˆ‘å®¶æ—ï¼Œä¸å…±æˆ´å¤©ï¼"ä¸¤äººå±•å¼€ç”Ÿæ­»ææ–—...
ã€åˆ¤æ–­ã€‘æ•Œå¯¹ï¼ˆç½®ä¿¡åº¦0.99ï¼‰- æ˜ç¡®çš„ä»‡æ¨å’Œç”Ÿæ­»å¯¹ç«‹

ç¤ºä¾‹4ï¼š
ã€ç‰‡æ®µã€‘è§ç‚èµ°è¿›æ‹å–ä¼šï¼Œçœ‹åˆ°ä¸»æŒäººç±³ç‰¹å°”é›…å¦ƒæ­£åœ¨å°ä¸Šä»‹ç»ç‰©å“ã€‚è§ç‚ååœ¨è§’è½é‡Œ...
ã€åˆ¤æ–­ã€‘å…±ç°ï¼ˆç½®ä¿¡åº¦0.70ï¼‰- ä»…åœ¨åŒä¸€åœºæ™¯ï¼Œæ— å®è´¨äº’åŠ¨

"""
        
        prompt = f"""{few_shot}

## ç°åœ¨è¯·åˆ†æä»¥ä¸‹å…³ç³»

ä½ æ˜¯ç½‘ç»œå°è¯´å…³ç³»åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æ"{entity1}"å’Œ"{entity2}"çš„å…³ç³»ç±»å‹ã€‚

**åˆ†æææ–™**
ä¸¤ä¸ªè§’è‰²å…±åŒå‡ºç° {cooccurrence_count} æ¬¡ï¼ˆ{chapter_range}ï¼‰ï¼Œä»¥ä¸‹æ˜¯å…¸å‹åœºæ™¯ï¼š
{context_text}

**å…³ç³»ç±»å‹å®šä¹‰ï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§å®šä¹‰é€‰æ‹©ï¼‰**

1. **å¸ˆå¾’**ï¼šæ˜ç¡®çš„å¸ˆæ‰¿å…³ç³»ï¼Œæœ‰ä¼ æˆçŸ¥è¯†/æŠ€èƒ½çš„æè¿°
   - å…³é”®è¯ï¼šå¸ˆçˆ¶ã€å¾’å¼Ÿã€ä¼ æˆã€æŒ‡å¯¼ã€æ•™å¯¼ã€æ‹œå¸ˆ
   - ç¤ºä¾‹ï¼šè¯è€ä¼ æˆè§ç‚ç‚¼è¯æœ¯

2. **ç›Ÿå‹**ï¼šåˆä½œã€äº’åŠ©ã€å…±åŒæˆ˜æ–—çš„å…³ç³»
   - å…³é”®è¯ï¼šè”æ‰‹ã€åˆä½œã€å¹¶è‚©ä½œæˆ˜ã€å¸®åŠ©ã€ç»“ç›Ÿ
   - ç¤ºä¾‹ï¼šä¸¤äººè”æ‰‹å¯¹æŠ—æ•Œäºº

3. **æ•Œå¯¹**ï¼šæ˜ç¡®çš„å¯¹ç«‹ã€ä»‡æ¨ã€æˆ˜æ–—å…³ç³»
   - å…³é”®è¯ï¼šæ•Œäººã€å¯¹æ‰‹ã€ä»‡æ¨ã€æˆ˜æ–—ã€å¯¹æŠ—ã€ä½ æ­»æˆ‘æ´»
   - ç¤ºä¾‹ï¼šä¸å…±æˆ´å¤©çš„æ­»æ•Œ

4. **äº²å±**ï¼šè¡€ç¼˜ã€å®¶æ—å…³ç³»
   - å…³é”®è¯ï¼šçˆ¶å­ã€å…„å¼Ÿã€å§å¦¹ã€äº²äººã€å®¶æ—
   - ç¤ºä¾‹ï¼šäº²ç”Ÿçˆ¶å­ã€äº²å…„å¼Ÿ

5. **æ‹äºº**ï¼šæ˜ç¡®çš„æ‹çˆ±ã€æƒ…ä¾£å…³ç³»
   - å…³é”®è¯ï¼šçˆ±æ…•ã€æ‹äººã€æƒ…ä¾£ã€å–œæ¬¢ã€ç›¸çˆ±ã€è¡¨ç™½
   - ç¤ºä¾‹ï¼šäº’ç›¸çˆ±æ…•çš„æƒ…ä¾£

6. **åŒé—¨**ï¼šåŒä¸€é—¨æ´¾ã€ç»„ç»‡ã€åŠ¿åŠ›
   - å…³é”®è¯ï¼šåŒé—¨ã€å¸ˆå…„å¼Ÿã€åŒæ´¾ã€åŒä¸€å®—é—¨
   - ç¤ºä¾‹ï¼šåŒä¸ºäº‘å²šå®—å¼Ÿå­

7. **ä¸­ç«‹**ï¼šè®¤è¯†ä½†æ— æ˜æ˜¾å…³ç³»å€¾å‘
   - ç‰¹å¾ï¼šå¶å°”äº¤é›†ï¼Œå…³ç³»ä¸æ˜ç¡®ï¼Œæ— æ˜æ˜¾æƒ…æ„Ÿå€¾å‘
   - ç¤ºä¾‹ï¼šè§è¿‡å‡ é¢çš„ç†Ÿäºº

8. **å…±ç°**ï¼šä»…åœ¨åŒä¸€åœºæ™¯å‡ºç°ï¼Œæ— å®è´¨äº’åŠ¨
   - ç‰¹å¾ï¼šåªæ˜¯åŒæ—¶åœ¨åœºï¼Œæ— å¯¹è¯æˆ–äº’åŠ¨ï¼Œçº¯ç²¹çš„èƒŒæ™¯è§’è‰²
   - ç¤ºä¾‹ï¼šåŒåœ¨ä¸€ä¸ªå®´ä¼šä¸Šä½†æ— äº¤æµ

**åˆ†ææ­¥éª¤**
1. ä»”ç»†é˜…è¯»æ‰€æœ‰ç‰‡æ®µ
2. è¯†åˆ«å…³é”®è¯å’Œäº’åŠ¨æ¨¡å¼
3. åˆ¤æ–­æœ€ä¸»è¦çš„å…³ç³»ç±»å‹ï¼ˆå¦‚æœæœ‰å¤šç§ï¼Œé€‰æ‹©æœ€æ ¸å¿ƒçš„ï¼‰
4. è¯„ä¼°åˆ¤æ–­çš„ç½®ä¿¡åº¦

**è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»æ˜¯çº¯JSONï¼‰**
{{"relation_type": "å¸ˆå¾’", "confidence": 0.95, "reasoning": "è¯è€å¤šæ¬¡æŒ‡å¯¼è§ç‚ä¿®ç‚¼ï¼Œæ˜ç¡®çš„å¸ˆå¾’ä¼ æ‰¿å…³ç³»"}}

è¯·åˆ†æï¼š"""
        
        response = await self.llm_client.chat.completions.acreate(
            model="glm-4-flash",  # å…è´¹é«˜é€Ÿæ¨¡å‹
            messages=[{"role": "user", "content": prompt}],
            thinking={"type": "disabled"},  # ç¦ç”¨æ€è€ƒæ¨¡å¼ï¼ŒåŠ é€Ÿ
            max_tokens=200,  # ä¼˜åŒ–ï¼šä»150å¢åŠ åˆ°200
            temperature=0.1  # ä¼˜åŒ–ï¼šä»0.3é™åˆ°0.1ï¼Œæé«˜ç¨³å®šæ€§
        )
        
        return json.loads(response.choices[0].message.content)
```

#### ä¸Šä¸‹æ–‡æå–ä¼˜åŒ– â­ æ–°å¢

```python
def _smart_chapter_sampling(
    self,
    chapter_nums: List[int],
    max_samples: int = 5
) -> List[int]:
    """
    æ™ºèƒ½ç« èŠ‚é‡‡æ ·ï¼šæ—©æœŸ+ä¸­æœŸ+åæœŸ+å‡åŒ€åˆ†å¸ƒ
    
    ä¼˜åŒ–ç‚¹ï¼š
    - è¦†ç›–å…³ç³»çš„æ•´ä¸ªæ—¶é—´è·¨åº¦
    - ä¼˜å…ˆé‡‡æ ·é¦–æ¬¡å‡ºç°ã€ä¸­æœŸã€æœ«æ¬¡å‡ºç°
    - é¿å…å‡åŒ€é‡‡æ ·é”™è¿‡å…³é”®ç« èŠ‚
    """
    if len(chapter_nums) <= max_samples:
        return chapter_nums
    
    # å–é¦–ã€ä¸­ã€å°¾å„1ä¸ª
    result = [
        chapter_nums[0],  # é¦–æ¬¡å‡ºç°
        chapter_nums[len(chapter_nums)//2],  # ä¸­æœŸ
        chapter_nums[-1],  # æœ€åå‡ºç°
    ]
    
    # å‰©ä½™ä½ç½®å‡åŒ€é‡‡æ ·
    remaining = max_samples - 3
    if remaining > 0:
        step = (len(chapter_nums) - 1) // (remaining + 1)
        for i in range(1, remaining + 1):
            if i * step < len(chapter_nums):
                result.append(chapter_nums[i * step])
    
    return sorted(set(result))

def _extract_paragraph_with_entities(
    self,
    content: str,
    entity1: str,
    entity2: str,
    chapter_num: int
) -> Optional[str]:
    """
    æå–åŒ…å«ä¸¤ä¸ªå®ä½“çš„æ®µè½ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    ä¼˜åŒ–ç‚¹ï¼š
    - æ”¯æŒåˆ«ååŒ¹é…ï¼ˆå¦‚"è§ç‚"â†’"è§"ï¼‰
    - æ›´é•¿çš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆ400å­—ç¬¦ï¼‰
    - æ›´å¤§çš„æœç´¢èŒƒå›´ï¼ˆ800å­—ç¬¦å†…ï¼‰
    """
    # è€ƒè™‘å®ä½“åˆ«åæ¨¡å¼
    entity1_patterns = [
        entity1,
        entity1[:2] if len(entity1) >= 2 else entity1,  # å§“æ°
    ]
    
    entity2_patterns = [
        entity2,
        entity2[:2] if len(entity2) >= 2 else entity2,  # å§“æ°
    ]
    
    # æŸ¥æ‰¾åŒæ—¶åŒ…å«ä¸¤ä¸ªå®ä½“çš„ä½ç½®
    lines = content.split('\n')
    best_match = None
    max_score = 0
    
    for line in lines:
        score = 0
        has_entity1 = any(p in line for p in entity1_patterns)
        has_entity2 = any(p in line for p in entity2_patterns)
        
        if has_entity1:
            score += 1
        if has_entity2:
            score += 1
        
        if score == 2 and score >= max_score:
            # æ‰¾åˆ°åŒ…å«ä¸¤ä¸ªå®ä½“çš„è¡Œ
            idx = content.find(line)
            if idx != -1:
                # æå–å‰åå„150å­—ç¬¦ï¼ˆä¼˜åŒ–ï¼šä»100å¢åŠ åˆ°150ï¼‰
                start = max(0, idx - 150)
                end = min(len(content), idx + len(line) + 150)
                context = content[start:end].strip()
                
                # é™åˆ¶é•¿åº¦ä¸º400å­—ç¬¦ï¼ˆä¼˜åŒ–ï¼šä»200å¢åŠ åˆ°400ï¼‰
                if len(context) > 400:
                    context = context[:400] + "..."
                
                best_match = f"[ç¬¬{chapter_num}ç« ] {context}"
                max_score = score
    
    if best_match:
        return best_match
    
    # å¦‚æœæ²¡æ‰¾åˆ°åŒæ—¶åŒ…å«çš„è¡Œï¼Œå°è¯•æŸ¥æ‰¾é™„è¿‘çš„ï¼ˆèŒƒå›´æ‰©å¤§åˆ°800ï¼‰
    idx1 = -1
    idx2 = -1
    
    for pattern in entity1_patterns:
        idx1 = content.find(pattern)
        if idx1 != -1:
            break
    
    for pattern in entity2_patterns:
        idx2 = content.find(pattern)
        if idx2 != -1:
            break
    
    if idx1 != -1 and idx2 != -1 and abs(idx1 - idx2) < 800:
        start = max(0, min(idx1, idx2) - 100)
        end = min(len(content), max(idx1, idx2) + 200)
        context = content[start:end].strip()
        
        if len(context) > 400:
            context = context[:400] + "..."
        
        return f"[ç¬¬{chapter_num}ç« ] {context}"
    
    return None
```

#### é›†æˆä½ç½®

ä¿®æ”¹ `backend/app/services/indexing_service.py` ç¬¬376-434è¡Œï¼š

```python
# æ·»åŠ è§’è‰²é—´çš„å…³ç³»è¾¹ï¼ˆæ”¹è¿›ç‰ˆï¼‰
logger.info(f"ğŸ”— æ„å»ºè§’è‰²å…³ç³»...")

# å…ˆæ„å»ºå…±ç°å…³ç³»ç»Ÿè®¡ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
cooccurrence_count = {}
cooccurrence_chapters = {}
# ... åŸæœ‰å…±ç°ç»Ÿè®¡ä»£ç  ...

# æ–°å¢ï¼šå…³ç³»ç±»å‹åˆ†ç±»
relation_classifier = RelationshipClassifier()
min_cooccurrence_for_classification = 5  # è‡³å°‘å…±ç°5æ¬¡æ‰è¿›è¡ŒLLMåˆ†ç±»

# å‡†å¤‡æ‰¹é‡åˆ†ç±»ä»»åŠ¡
classification_tasks = []
for (entity1, entity2), count in cooccurrence_count.items():
    if count >= min_cooccurrence_for_classification:
        chapters = cooccurrence_chapters[(entity1, entity2)]
        # æ™ºèƒ½é‡‡æ ·ç« èŠ‚ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨_smart_chapter_samplingï¼‰
        sampled_chapters = self._smart_chapter_sampling(chapters, max_samples=5)
        # æå–5ä¸ªå…¸å‹å…±ç°ç‰‡æ®µï¼ˆä¼˜åŒ–ï¼šä»3ä¸ªå¢åŠ åˆ°5ä¸ªï¼‰
        contexts = await self._extract_cooccurrence_contexts(
            entity1, entity2, sampled_chapters, db
        )
        classification_tasks.append((entity1, entity2, contexts, count, chapters))

# ğŸš€ å¹¶å‘åˆ†ç±»ï¼ˆä½¿ç”¨GLM-4.5-Flash + å¹¶å‘20ï¼‰
logger.info(f"ğŸ“Š ä½¿ç”¨GLM-4.5-Flashå¹¶å‘åˆ†ç±» {len(classification_tasks)} å¯¹å…³ç³»...")
classifications = await relation_classifier.classify_batch(
    classification_tasks,
    max_concurrency=20
)

# æ·»åŠ å…³ç³»è¾¹
for (entity1, entity2), classification in zip(
    [t[:2] for t in classification_tasks], 
    classifications
):
    chapters = cooccurrence_chapters[(entity1, entity2)]
    count = cooccurrence_count[(entity1, entity2)]
    
    self.graph_builder.add_relation(
        graph,
        source=entity1,
        target=entity2,
        relation_type=classification['relation_type'],  # ä½¿ç”¨è¯†åˆ«çš„ç±»å‹
        start_chapter=min(chapters),
        end_chapter=max(chapters),
        strength=min(count / 20.0, 1.0),
        confidence=classification['confidence'],
        cooccurrence_count=count
    )
    
    # æ·»åŠ åå‘è¾¹
    self.graph_builder.add_relation(
        graph,
        source=entity2,
        target=entity1,
        relation_type=classification['relation_type'],
        start_chapter=min(chapters),
        end_chapter=max(chapters),
        strength=min(count / 20.0, 1.0),
        confidence=classification['confidence'],
        cooccurrence_count=count
    )
```

---

### 3.3 ä¼˜åŒ–2ï¼šå…³ç³»æ¼”å˜è¿½è¸ªï¼ˆP0ï¼‰

#### è®¾è®¡æ–¹æ¡ˆ

```python
class RelationshipEvolutionTracker:
    """è¿½è¸ªå…³ç³»éšæ—¶é—´çš„æ¼”å˜"""
    
    async def track_evolution(
        self,
        entity1: str,
        entity2: str,
        all_chapters: List[int],
        db: Session
    ) -> List[Dict]:
        """
        å°†ç« èŠ‚åˆ†æ®µï¼Œæ£€æµ‹æ¯æ®µçš„å…³ç³»ç±»å‹
        
        Returns:
            [
                {"chapter": 10, "type": "é™Œç”Ÿ", "confidence": 0.8},
                {"chapter": 50, "type": "æœ‹å‹", "confidence": 0.9},
                {"chapter": 120, "type": "ç›Ÿå‹", "confidence": 0.95}
            ]
        """
        # åˆ†æ®µç­–ç•¥ï¼šæŒ‰ç« èŠ‚æ•°é‡åŠ¨æ€åˆ†æ®µ
        total_span = max(all_chapters) - min(all_chapters)
        if total_span <= 50:
            segments = 2  # æ—©æœŸ/åæœŸ
        elif total_span <= 200:
            segments = 3  # æ—©æœŸ/ä¸­æœŸ/åæœŸ
        else:
            segments = 5  # ç»†ç²’åº¦åˆ†æ®µ
        
        segment_size = len(all_chapters) // segments
        evolution = []
        
        for i in range(segments):
            start_idx = i * segment_size
            end_idx = start_idx + segment_size if i < segments - 1 else len(all_chapters)
            segment_chapters = all_chapters[start_idx:end_idx]
            
            # æå–è¯¥æ®µçš„ä¸Šä¸‹æ–‡
            contexts = await self._extract_segment_contexts(
                entity1, entity2, segment_chapters[:3], db  # æ¯æ®µå–3ä¸ªæ ·æœ¬
            )
            
            # åˆ†ç±»è¯¥æ®µçš„å…³ç³»ç±»å‹
            classification = await self.classifier.classify_relationship(
                entity1, entity2, contexts, segment_chapters
            )
            
            # è®°å½•æ¼”å˜ç‚¹
            evolution.append({
                "chapter": segment_chapters[0],
                "type": classification['relation_type'],
                "confidence": classification['confidence']
            })
        
        # å»é‡ï¼šåªä¿ç•™å…³ç³»ç±»å‹å˜åŒ–çš„èŠ‚ç‚¹
        deduplicated = [evolution[0]]  # ä¿ç•™èµ·å§‹ç‚¹
        for i in range(1, len(evolution)):
            if evolution[i]['type'] != evolution[i-1]['type']:
                deduplicated.append(evolution[i])
        
        return deduplicated
```

#### é›†æˆæ–¹å¼

```python
# åœ¨æ·»åŠ å…³ç³»è¾¹æ—¶ï¼ŒåŒæ—¶è®¡ç®—æ¼”å˜è½¨è¿¹
evolution = await evolution_tracker.track_evolution(
    entity1, entity2, chapters, db
)

self.graph_builder.add_relation(
    graph,
    source=entity1,
    target=entity2,
    relation_type=evolution[-1]['type'] if evolution else 'å…±ç°',
    start_chapter=min(chapters),
    end_chapter=max(chapters),
    strength=min(count / 20.0, 1.0),
    evolution=evolution  # æ·»åŠ æ¼”å˜è½¨è¿¹
)
```

---

### 3.4 ä¼˜åŒ–3ï¼šå®ä½“å±æ€§æå–ï¼ˆP1ï¼‰

#### è®¾è®¡æ–¹æ¡ˆ

```python
class EntityAttributeExtractor:
    """æå–å®ä½“çš„å±æ€§ï¼ˆæ€§åˆ«ã€é˜µè¥ç­‰ï¼‰"""
    
    async def extract_attributes(
        self,
        entity_name: str,
        entity_type: str,
        contexts: List[str]  # å®ä½“å‡ºç°çš„å…¸å‹ä¸Šä¸‹æ–‡
    ) -> Dict:
        """
        ä»ä¸Šä¸‹æ–‡ä¸­æå–å®ä½“å±æ€§
        
        Returns:
            {
                "æ€§åˆ«": "ç”·",
                "é˜µè¥": "ä¸»è§’æ–¹",
                "èŒä¸š": "ç‚¼è¯å¸ˆ",
                "å®åŠ›": "æ–—åœ£"
            }
        """
        if entity_type != 'characters':
            return {}  # ä»…å¤„ç†è§’è‰²
        
        prompt = f"""ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–"{entity_name}"çš„å±æ€§ï¼š

æ–‡æœ¬ç‰‡æ®µï¼š
{contexts[0][:200]}
{contexts[1][:200]}
{contexts[2][:200]}

è¯·æå–ä»¥ä¸‹å±æ€§ï¼ˆå¦‚æ–‡æœ¬ä¸­æœªæåŠåˆ™çœç•¥ï¼‰ï¼š
- æ€§åˆ«ï¼ˆç”·/å¥³/æœªçŸ¥ï¼‰
- é˜µè¥æˆ–åŠ¿åŠ›
- èŒä¸šæˆ–èº«ä»½
- å®åŠ›ç­‰çº§æˆ–ä¿®ä¸º

è¿”å›JSONæ ¼å¼ï¼š{{"æ€§åˆ«": "...", "é˜µè¥": "...", "èŒä¸š": "...", "å®åŠ›": "..."}}"""
        
        response = await self.llm_client.chat.completions.acreate(
            model="glm-4.5-flash",
            messages=[{"role": "user", "content": prompt}],
            thinking={"type": "disabled"},
            max_tokens=100,
            temperature=0.3
        )
        
        return json.loads(response.choices[0].message.content)
```

#### é›†æˆä½ç½®

ä¿®æ”¹ `backend/app/services/indexing_service.py` ç¬¬362-374è¡Œï¼š

```python
# æ·»åŠ å®ä½“èŠ‚ç‚¹ï¼ˆæ”¹è¿›ç‰ˆï¼‰
attribute_extractor = EntityAttributeExtractor()

for entity_type in ['characters', 'locations', 'organizations']:
    for entity_name, count in merged_entities.get(entity_type, {}).items():
        first_ch, last_ch = merged_chapter_ranges.get(entity_name, (1, total_chapters))
        
        # æå–å±æ€§ï¼ˆä»…å¯¹ä¸»è¦è§’è‰²ï¼‰
        attributes = {}
        if entity_type == 'characters' and count >= 10:  # å‡ºç°10æ¬¡ä»¥ä¸Šçš„è§’è‰²
            contexts = await self._extract_entity_contexts(entity_name, db)
            attributes = await attribute_extractor.extract_attributes(
                entity_name, entity_type, contexts
            )
        
        self.graph_builder.add_entity(
            graph,
            entity_name=entity_name,
            entity_type=entity_type,
            first_chapter=first_ch,
            last_chapter=last_ch,
            mention_count=count,
            attributes=attributes  # æ·»åŠ å±æ€§å­—å…¸
        )
```

---

## 4. æˆæœ¬ä¸æ—¶é—´ä¼°ç®—

### 4.1 å‡è®¾åœºæ™¯

**æµ‹è¯•å°è¯´**ï¼š500ä¸‡å­—é•¿ç¯‡
- ç« èŠ‚æ•°ï¼š~2000ç« 
- å®ä½“æ•°é‡ï¼š~500ä¸ª
- é«˜é¢‘å…³ç³»å¯¹ï¼ˆå…±ç°â‰¥5æ¬¡ï¼‰ï¼š~200å¯¹

---

### 4.2 Tokenæ¶ˆè€—ä¼°ç®—

#### ä¼˜åŒ–1ï¼šå…³ç³»ç±»å‹è¯†åˆ«ï¼ˆå·²å®æ–½ä¼˜åŒ–ç‰ˆï¼‰

| é¡¹ç›® | åŸæ–¹æ¡ˆ | ä¼˜åŒ–å |
|------|--------|--------|
| **è°ƒç”¨æ¬¡æ•°** | 200æ¬¡ | 200æ¬¡ |
| **å•æ¬¡è¾“å…¥Token** | ~1800 tokens | ~2800 tokensï¼ˆå«Few-shot + æ›´é•¿ä¸Šä¸‹æ–‡ï¼‰ |
| **å•æ¬¡è¾“å‡ºToken** | ~100 tokens | ~120 tokens |
| **æ€»Tokenæ¶ˆè€—** | 38ä¸‡ tokens | **58ä¸‡ tokens** |

**ä¼˜åŒ–å†…å®¹**ï¼š
- âœ… Few-shotç¤ºä¾‹ï¼ˆ+800 tokensï¼‰
- âœ… è¯¦ç»†å…³ç³»å®šä¹‰å’Œå…³é”®è¯ï¼ˆ+400 tokensï¼‰
- âœ… ä¸Šä¸‹æ–‡ä»3ä¸ªÃ—150å­—â†’5ä¸ªÃ—300å­—ï¼ˆ+600 tokensï¼‰
- âœ… temperatureä»0.3â†’0.1ï¼ˆæé«˜ç¨³å®šæ€§ï¼‰
- âœ… max_tokensä»150â†’200ï¼ˆæ›´è¯¦ç»†çš„reasoningï¼‰

**æˆæœ¬ï¼ˆGLM-4.5-Flashï¼‰**ï¼š**å®Œå…¨å…è´¹** âœ…

**é¢„æœŸå‡†ç¡®ç‡æå‡**ï¼š**+40-70%**

---

#### ä¼˜åŒ–2ï¼šå…³ç³»æ¼”å˜è¿½è¸ª

| é¡¹ç›® | æ•°å€¼ |
|------|------|
| **è°ƒç”¨æ¬¡æ•°** | 600æ¬¡ï¼ˆ200å¯¹ Ã— 3æ®µï¼‰ |
| **å•æ¬¡è¾“å…¥Token** | ~1700 tokens |
| **å•æ¬¡è¾“å‡ºToken** | ~100 tokens |
| **æ€»Tokenæ¶ˆè€—** | 108ä¸‡ tokens |

**æˆæœ¬ï¼ˆGLM-4.5-Flashï¼‰**ï¼š**å®Œå…¨å…è´¹** âœ…

---

#### ä¼˜åŒ–3ï¼šå®ä½“å±æ€§æå–

| é¡¹ç›® | æ•°å€¼ |
|------|------|
| **è°ƒç”¨æ¬¡æ•°** | 300æ¬¡ï¼ˆä¸»è¦è§’è‰²ï¼‰ |
| **å•æ¬¡è¾“å…¥Token** | ~1350 tokens |
| **å•æ¬¡è¾“å‡ºToken** | ~80 tokens |
| **æ€»Tokenæ¶ˆè€—** | 43ä¸‡ tokens |

**æˆæœ¬ï¼ˆGLM-4.5-Flashï¼‰**ï¼š**å®Œå…¨å…è´¹** âœ…

---

#### æ€»æˆæœ¬æ±‡æ€»ï¼ˆå·²æ›´æ–°ä¼˜åŒ–åæ•°æ®ï¼‰

| ä¼˜åŒ–é¡¹ | è°ƒç”¨æ¬¡æ•° | Tokenæ¶ˆè€— | æˆæœ¬ | çŠ¶æ€ |
|--------|---------|-----------|------|------|
| å…³ç³»ç±»å‹è¯†åˆ«ï¼ˆå·²ä¼˜åŒ–ï¼‰ | 200 | **58ä¸‡** | **å…è´¹** | âœ… å·²å®æ–½ |
| å…³ç³»æ¼”å˜è¿½è¸ª | 600 | 108ä¸‡ | **å…è´¹** | ğŸ”œ å¾…å®æ–½ |
| å®ä½“å±æ€§æå– | 300 | 43ä¸‡ | **å…è´¹** | ğŸ”œ å¾…å®æ–½ |
| **æ€»è®¡** | **1100** | **209ä¸‡** | **Â¥0** | - |

**ä¼˜åŒ–è¯´æ˜**ï¼š
- å…³ç³»ç±»å‹è¯†åˆ«Tokenå¢åŠ 52%ï¼ˆ38ä¸‡â†’58ä¸‡ï¼‰ï¼Œä½†å‡†ç¡®ç‡æå‡40-70%
- ä»ç„¶å®Œå…¨å…è´¹ï¼ˆGLM-4.5-Flashï¼‰
- Tokenå¢åŠ ä¸»è¦æ¥è‡ªFew-shotç¤ºä¾‹å’Œæ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡

**ä¸åŸç´¢å¼•æˆæœ¬å¯¹æ¯”**ï¼š
- åŸå‘é‡åŒ–æˆæœ¬ï¼ˆ500ä¸‡å­—ï¼‰ï¼šÂ¥1.5-2.5
- **ä¼˜åŒ–åæ€»æˆæœ¬**ï¼šÂ¥1.5 + Â¥0 = **Â¥1.5**ï¼ˆæ— å¢åŠ ï¼‰

---

### 4.3 æ—¶é—´å¼€é”€ä¼°ç®—

#### åŸå§‹æ–¹æ¡ˆï¼ˆä¸²è¡Œè°ƒç”¨ï¼‰

| é˜¶æ®µ | è€—æ—¶ |
|------|------|
| å…³ç³»ç±»å‹è¯†åˆ«ï¼ˆ200æ¬¡ï¼‰ | 25åˆ†é’Ÿ |
| å…³ç³»æ¼”å˜è¿½è¸ªï¼ˆ600æ¬¡ï¼‰ | 70åˆ†é’Ÿ |
| å®ä½“å±æ€§æå–ï¼ˆ300æ¬¡ï¼‰ | 35åˆ†é’Ÿ |
| **æ€»å¢åŠ æ—¶é—´** | **130åˆ†é’Ÿ** |

#### ä¼˜åŒ–åï¼ˆå¹¶å‘20 + GLM-4.5-Flashï¼‰

| é˜¶æ®µ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æé€Ÿå€æ•° |
|------|--------|--------|---------|
| å…³ç³»ç±»å‹è¯†åˆ« | 25åˆ†é’Ÿ | **2-3åˆ†é’Ÿ** | 10å€ |
| å…³ç³»æ¼”å˜è¿½è¸ª | 70åˆ†é’Ÿ | **6-8åˆ†é’Ÿ** | 10å€ |
| å®ä½“å±æ€§æå– | 35åˆ†é’Ÿ | **3-4åˆ†é’Ÿ** | 10å€ |
| **æ€»å¢åŠ æ—¶é—´** | 130åˆ†é’Ÿ | **12-15åˆ†é’Ÿ** | **10å€** |

---

## 5. åŠ é€Ÿä¼˜åŒ–æ–¹æ¡ˆ

### 5.1 æ ¸å¿ƒæŠ€æœ¯ï¼šGLM-4.5-Flash

**å®˜æ–¹æ–‡æ¡£**ï¼šhttps://docs.bigmodel.cn/cn/guide/models/free/glm-4.5-flash

**å…³é”®ä¼˜åŠ¿**ï¼š
- âœ… **å®Œå…¨å…è´¹**ï¼ˆæ— æˆæœ¬å‹åŠ›ï¼‰
- âœ… **æ˜¾è‘—é€Ÿåº¦ä¼˜åŠ¿**ï¼ˆæ¯”GLM-4å¿«3-5å€ï¼‰
- âœ… **128Kä¸Šä¸‹æ–‡**ï¼ˆè¶³å¤Ÿå¤„ç†é•¿ä¸Šä¸‹æ–‡ï¼‰
- âœ… **æ”¯æŒæ··åˆæ¨ç†æ¨¡å¼**ï¼ˆå¯ç¦ç”¨æ€è€ƒæ¨¡å¼ï¼‰
- âœ… **æ— QPSé™åˆ¶**ï¼ˆæ”¯æŒé«˜å¹¶å‘ï¼‰

**ä½¿ç”¨é…ç½®**ï¼š

```python
from zai import ZhipuAiClient

client = ZhipuAiClient(api_key=settings.zhipu_api_key)

response = await client.chat.completions.acreate(
    model="glm-4.5-flash",  # ä½¿ç”¨å…è´¹é«˜é€Ÿæ¨¡å‹
    messages=[{"role": "user", "content": prompt}],
    thinking={"type": "disabled"},  # ğŸš€ å…³é”®ï¼šç¦ç”¨æ€è€ƒæ¨¡å¼åŠ é€Ÿ
    stream=False,
    max_tokens=150,
    temperature=0.3  # é™ä½éšæœºæ€§ï¼Œæé«˜ç¨³å®šæ€§
)
```

---

### 5.2 åŠ é€Ÿæ–¹æ¡ˆ1ï¼šé«˜å¹¶å‘å¼‚æ­¥è°ƒç”¨

```python
import asyncio
from typing import List, Dict

class ParallelGraphBuilder:
    """å¹¶è¡Œå›¾è°±æ„å»ºå™¨"""
    
    def __init__(self, max_concurrency: int = 20):
        """
        Args:
            max_concurrency: æœ€å¤§å¹¶å‘æ•°ï¼ˆGLM-4.5-Flashæ¨è20-50ï¼‰
        """
        self.max_concurrency = max_concurrency
        self.semaphore = asyncio.Semaphore(max_concurrency)
    
    async def classify_relationships_batch(
        self,
        relation_pairs: List[Tuple[str, str, List[str]]],
    ) -> List[Dict]:
        """
        æ‰¹é‡å¹¶å‘åˆ†ç±»å…³ç³»
        
        Args:
            relation_pairs: [(entity1, entity2, contexts), ...]
            
        Returns:
            åˆ†ç±»ç»“æœåˆ—è¡¨
        """
        tasks = []
        for entity1, entity2, contexts in relation_pairs:
            task = self._classify_with_semaphore(entity1, entity2, contexts)
            tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è¿‡æ»¤å¼‚å¸¸ç»“æœ
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"åˆ†ç±»å¤±è´¥: {relation_pairs[i][0]}-{relation_pairs[i][1]}: {result}")
                # å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å€¼
                valid_results.append({
                    'relation_type': 'å…±ç°',
                    'confidence': 0.5
                })
            else:
                valid_results.append(result)
        
        return valid_results
    
    async def _classify_with_semaphore(
        self,
        entity1: str,
        entity2: str,
        contexts: List[str]
    ) -> Dict:
        """å¸¦å¹¶å‘æ§åˆ¶çš„åˆ†ç±»"""
        async with self.semaphore:
            return await self._classify_single(entity1, entity2, contexts)
    
    async def _classify_single(
        self,
        entity1: str,
        entity2: str,
        contexts: List[str]
    ) -> Dict:
        """å•ä¸ªå…³ç³»åˆ†ç±»ï¼ˆå¼‚æ­¥ç‰ˆï¼‰"""
        from zai import ZhipuAiClient
        
        client = ZhipuAiClient(api_key=settings.zhipu_api_key)
        
        prompt = f"""åˆ†æ"{entity1}"å’Œ"{entity2}"çš„å…³ç³»ã€‚
ä¸Šä¸‹æ–‡ï¼š{contexts[0][:150]}...
ç±»å‹ï¼šå¸ˆå¾’/ç›Ÿå‹/æ•Œå¯¹/äº²å±/æ‹äºº/åŒé—¨/ä¸­ç«‹/å…±ç°
JSONï¼š{{"relation_type": "...", "confidence": 0.9}}"""
        
        response = await client.chat.completions.acreate(
            model="glm-4.5-flash",
            messages=[{"role": "user", "content": prompt}],
            thinking={"type": "disabled"},
            max_tokens=100,
            temperature=0.3
        )
        
        return json.loads(response.choices[0].message.content)
```

**æ•ˆæœ**ï¼š
- 200æ¬¡è°ƒç”¨ï¼š25åˆ†é’Ÿ â†’ **2-3åˆ†é’Ÿ**ï¼ˆå¿«10å€ï¼‰
- 600æ¬¡è°ƒç”¨ï¼š70åˆ†é’Ÿ â†’ **6-8åˆ†é’Ÿ**ï¼ˆå¿«10å€ï¼‰

---

### 5.3 åŠ é€Ÿæ–¹æ¡ˆ2ï¼šæ™ºèƒ½é‡‡æ ·è¿‡æ»¤

ä¸æ˜¯æ‰€æœ‰å…³ç³»éƒ½éœ€è¦LLMåˆ†ç±»ï¼Œå¯ä»¥ç”¨è§„åˆ™å…ˆè¿‡æ»¤ã€‚

```python
def should_classify_relation(
    self,
    entity1: str,
    entity2: str,
    cooccurrence_count: int,
    contexts: List[str]
) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦LLMåˆ†ç±»
    
    è§„åˆ™ï¼š
    1. å…±ç°æ¬¡æ•° < 5ï¼šä¸åˆ†ç±»ï¼ˆæ ‡è®°ä¸º"å¼±å…³ç³»"ï¼‰
    2. å…±ç°æ¬¡æ•° > 50ï¼šé‡è¦å…³ç³»ï¼Œå¿…é¡»åˆ†ç±»
    3. 5-50ä¹‹é—´ï¼šæ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰å…³ç³»è¯
    """
    # ä½é¢‘è¿‡æ»¤
    if cooccurrence_count < 5:
        return False
    
    # é«˜é¢‘å¿…åˆ†ç±»
    if cooccurrence_count > 50:
        return True
    
    # ä¸­é¢‘ï¼šæ£€æŸ¥ä¸Šä¸‹æ–‡ä¸­æ˜¯å¦æœ‰å…³ç³»å…³é”®è¯
    relation_keywords = [
        'å¸ˆå¾’', 'å¸ˆçˆ¶', 'å¾’å¼Ÿ', 'ç›Ÿå‹', 'æœ‹å‹', 'æ•Œäºº', 'ä»‡äºº',
        'çˆ¶å­', 'æ¯å¥³', 'å…„å¼Ÿ', 'å§å¦¹', 'å¤«å¦»', 'æ‹äºº',
        'åŒé—¨', 'å¸ˆå…„', 'å¸ˆå¼Ÿ', 'å¸ˆå§', 'å¸ˆå¦¹'
    ]
    
    context_text = ' '.join(contexts)
    has_relation_keyword = any(kw in context_text for kw in relation_keywords)
    
    return has_relation_keyword
```

**æ•ˆæœ**ï¼š
- 200å¯¹å…³ç³» â†’ **80-100å¯¹**éœ€è¦LLMåˆ†ç±»
- æ—¶é—´èŠ‚çœï¼š**50%**

---

### 5.4 åŠ é€Ÿæ–¹æ¡ˆ3ï¼šæ¸è¿›å¼æ„å»º â­ æ¨è

å…ˆæ„å»ºåŸºç¡€å›¾è°±ï¼Œåå°å¼‚æ­¥ä¼˜åŒ–ç»†èŠ‚ã€‚

```python
async def build_graph_progressive(
    self,
    novel_id: int,
    db: Session
):
    """
    æ¸è¿›å¼å›¾è°±æ„å»º
    
    é˜¶æ®µ1ï¼ˆå¿«é€Ÿï¼‰ï¼š5åˆ†é’Ÿå†…å®ŒæˆåŸºç¡€å›¾è°±
    - å®ä½“èŠ‚ç‚¹
    - å…±ç°å…³ç³»ï¼ˆæ— åˆ†ç±»ï¼‰
    - PageRankè®¡ç®—
    
    é˜¶æ®µ2ï¼ˆåå°ï¼‰ï¼š15-20åˆ†é’Ÿåå°ä¼˜åŒ–
    - å…³ç³»ç±»å‹åˆ†ç±»
    - æ¼”å˜è¿½è¸ª
    - å±æ€§æå–
    """
    # é˜¶æ®µ1ï¼šåŸºç¡€å›¾è°±ï¼ˆç«‹å³å®Œæˆï¼‰
    logger.info("ğŸš€ å¼€å§‹æ„å»ºåŸºç¡€å›¾è°±ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰...")
    graph = await self._build_basic_graph(novel_id, db)
    self.graph_builder.save_graph(graph, novel_id)
    
    logger.info("âœ… åŸºç¡€å›¾è°±æ„å»ºå®Œæˆï¼Œç”¨æˆ·å¯ä»¥å¼€å§‹æŸ¥è¯¢")
    
    # æ›´æ–°çŠ¶æ€ï¼šç´¢å¼•å®Œæˆï¼ˆå…è®¸ç”¨æˆ·æŸ¥è¯¢ï¼‰
    novel = db.query(Novel).filter(Novel.id == novel_id).first()
    novel.index_status = 'completed'
    novel.graph_status = 'basic'  # æ–°å¢å­—æ®µï¼šå›¾è°±çŠ¶æ€
    db.commit()
    
    # é˜¶æ®µ2ï¼šåå°ä¼˜åŒ–ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
    asyncio.create_task(
        self._enhance_graph_background(graph, novel_id, db)
    )
    
    logger.info("ğŸ”„ å›¾è°±ä¼˜åŒ–ä»»åŠ¡å·²å¯åŠ¨ï¼ˆåå°æ‰§è¡Œï¼‰")

async def _enhance_graph_background(
    self,
    graph: nx.MultiDiGraph,
    novel_id: int,
    db: Session
):
    """åå°å¢å¼ºå›¾è°±"""
    try:
        logger.info("ğŸ”„ å¼€å§‹åå°å›¾è°±ä¼˜åŒ–...")
        
        # 1. å…³ç³»åˆ†ç±»ï¼ˆ2-3åˆ†é’Ÿï¼‰
        await self._classify_all_relations(graph, novel_id, db)
        logger.info("âœ… å…³ç³»åˆ†ç±»å®Œæˆ")
        
        # 2. æ¼”å˜è¿½è¸ªï¼ˆ6-8åˆ†é’Ÿï¼‰
        await self._track_all_evolutions(graph, novel_id, db)
        logger.info("âœ… æ¼”å˜è¿½è¸ªå®Œæˆ")
        
        # 3. å±æ€§æå–ï¼ˆ3-4åˆ†é’Ÿï¼‰
        await self._extract_all_attributes(graph, novel_id, db)
        logger.info("âœ… å±æ€§æå–å®Œæˆ")
        
        # ä¿å­˜å¢å¼ºåçš„å›¾è°±
        self.graph_builder.save_graph(graph, novel_id)
        
        # æ›´æ–°å›¾è°±çŠ¶æ€
        novel = db.query(Novel).filter(Novel.id == novel_id).first()
        novel.graph_status = 'enhanced'
        db.commit()
        
        logger.info("âœ… å›¾è°±å¢å¼ºå®Œæˆ")
    except Exception as e:
        logger.error(f"å›¾è°±å¢å¼ºå¤±è´¥: {e}")
        logger.exception(e)
```

**ç”¨æˆ·ä½“éªŒæ—¶é—´çº¿**ï¼š

```
ç´¢å¼•å¼€å§‹
  â†“
æ–‡ä»¶è§£æ + åˆ†å— + å‘é‡åŒ–ï¼ˆ80-90åˆ†é’Ÿï¼‰
  â†“
å®ä½“æå–ï¼ˆ10-15åˆ†é’Ÿï¼‰
  â†“
åŸºç¡€å›¾è°±æ„å»ºï¼ˆ2åˆ†é’Ÿï¼‰
  â†“
âœ… ã€ç”¨æˆ·å¯ä»¥å¼€å§‹ä½¿ç”¨ã€‘ â€”â€” æ€»è€—æ—¶ï¼š95åˆ†é’Ÿ
  â†“
åå°ä¼˜åŒ–ï¼ˆ12-15åˆ†é’Ÿï¼Œä¸é˜»å¡ç”¨æˆ·ï¼‰ï¼š
  - å…³ç³»åˆ†ç±»ï¼š2-3åˆ†é’Ÿ
  - æ¼”å˜è¿½è¸ªï¼š6-8åˆ†é’Ÿ
  - å±æ€§æå–ï¼š3-4åˆ†é’Ÿ
  â†“
âœ… ã€å›¾è°±å®Œå…¨ä¼˜åŒ–ã€‘ â€”â€” ä¸å½±å“ç”¨æˆ·ä½¿ç”¨
```

---

### 5.5 ç»¼åˆä¼˜åŒ–æ•ˆæœå¯¹æ¯”

| æ–¹æ¡ˆ | æ—¶é—´æ¶ˆè€— | æˆæœ¬ | ç”¨æˆ·ç­‰å¾… | æ¨èåº¦ |
|------|---------|------|---------|-------|
| **åŸæ–¹æ¡ˆï¼ˆä¸²è¡Œï¼‰** | 130-160åˆ†é’Ÿ | Â¥105 | 210åˆ†é’Ÿ | â­ |
| **GLM-4.5-Flash** | 30-45åˆ†é’Ÿ | **å…è´¹** | 125åˆ†é’Ÿ | â­â­â­â­ |
| **å¹¶å‘20** | **2-3åˆ†é’Ÿ** | **å…è´¹** | 95åˆ†é’Ÿ | â­â­â­â­â­ |
| **æ™ºèƒ½è¿‡æ»¤** | **1-2åˆ†é’Ÿ** | **å…è´¹** | 94åˆ†é’Ÿ | â­â­â­â­ |
| **æ¸è¿›å¼æ„å»º** | ç”¨æˆ·ç­‰å¾…**0åˆ†é’Ÿ** | **å…è´¹** | **95åˆ†é’Ÿ** | â­â­â­â­â­ |

**æœ€ç»ˆæ¨è**ï¼š**æ¸è¿›å¼æ„å»º + å¹¶å‘20 + GLM-4.5-Flash**
- ç”¨æˆ·ç­‰å¾…æ—¶é—´ï¼š95åˆ†é’Ÿï¼ˆä¸åŸç´¢å¼•ç›¸åŒï¼‰
- åå°ä¼˜åŒ–æ—¶é—´ï¼š12-15åˆ†é’Ÿï¼ˆä¸å½±å“ä½¿ç”¨ï¼‰
- æˆæœ¬ï¼šå®Œå…¨å…è´¹
- åŠŸèƒ½ï¼šå®Œå…¨æ»¡è¶³PRDè¦æ±‚

---

## 6. å›¾è°±åœ¨æ£€ç´¢é˜¶æ®µçš„å¢å¼ºç”¨æ³•

### 6.1 å½“å‰ä½¿ç”¨æ–¹å¼

**ä½ç½®**ï¼š`backend/app/services/rag_engine.py`

**ç°æœ‰åº”ç”¨**ï¼š
1. **ç« èŠ‚é‡è¦æ€§è¯„åˆ†**ï¼ˆç¬¬469-471è¡Œï¼‰
2. **å®ä½“åŒ¹é…å¾—åˆ†**ï¼ˆç¬¬490è¡Œï¼‰

**é—®é¢˜**ï¼šå›¾è°±å…³ç³»ç±»å‹å’Œæ¼”å˜ä¿¡æ¯**å®Œå…¨æœªä½¿ç”¨**ã€‚

---

### 6.2 å¢å¼ºç”¨æ³•1ï¼šå…³ç³»ç±»å‹é©±åŠ¨çš„æ£€ç´¢è·¯ç”±

```python
class GraphEnhancedRAG:
    """å›¾è°±å¢å¼ºçš„RAGå¼•æ“"""
    
    def retrieve_with_relation_awareness(
        self,
        query: str,
        entities: List[str],
        graph: nx.MultiDiGraph,
        db: Session
    ) -> str:
        """
        åŸºäºå›¾è°±å…³ç³»ç±»å‹ä¼˜åŒ–æ£€ç´¢
        
        åœºæ™¯ï¼šç”¨æˆ·æŸ¥è¯¢"è§ç‚å’Œäº‘éŸµæ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ"
        """
        # æ£€æµ‹æŸ¥è¯¢æ„å›¾
        if self._is_relationship_query(query) and len(entities) >= 2:
            # ä»å›¾è°±ä¸­æå–å®ä½“é—´çš„å…³ç³»æ¼”å˜
            relations = self.graph_query.get_relationship_evolution(
                graph, entities[0], entities[1]
            )
            
            if relations:
                # æ„å»ºå…³ç³»æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡
                relation_context = f"""
ã€çŸ¥è¯†å›¾è°±ä¿¡æ¯ã€‘
æ ¹æ®å›¾è°±åˆ†æï¼Œ{entities[0]}å’Œ{entities[1]}çš„å…³ç³»æ¼”å˜ä¸ºï¼š
"""
                for rel in relations:
                    relation_context += f"- ç¬¬{rel['chapter']}ç« ï¼š{rel['type']}ï¼ˆç½®ä¿¡åº¦ï¼š{rel['confidence']}ï¼‰\n"
                
                relation_context += "\nè¯·åŸºäºä»¥ä¸‹åŸæ–‡ç‰‡æ®µå’Œä¸Šè¿°å…³ç³»ä¿¡æ¯å›ç­”ï¼š\n"
                
                return relation_context
        
        return ""
    
    def _is_relationship_query(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå…³ç³»æŸ¥è¯¢"""
        relation_keywords = ['å…³ç³»', 'ä»€ä¹ˆæ ·', 'å¦‚ä½•', 'æ˜¯ä¸æ˜¯', 'å˜åŒ–']
        return any(kw in query for kw in relation_keywords)
```

**æ•ˆæœ**ï¼š
- æŸ¥è¯¢"è§ç‚å’Œäº‘éŸµçš„å…³ç³»"æ—¶ï¼Œå…ˆä»å›¾è°±è·å–"å¸ˆå¾’â†’é™Œç”Ÿâ†’å¤æ‚"çš„æ¼”å˜è½¨è¿¹
- å¼•å¯¼LLMç”Ÿæˆæ›´å‡†ç¡®çš„ç­”æ¡ˆ
- **å‡†ç¡®ç‡æå‡é¢„è®¡ï¼š+17%**

---

### 6.3 å¢å¼ºç”¨æ³•2ï¼šæ¼”å˜èŠ‚ç‚¹ä¼˜å…ˆæ£€ç´¢

```python
def enhanced_rerank(
    self,
    query: str,
    candidates: List[Dict],
    graph: nx.MultiDiGraph,
    query_entities: List[str]
) -> List[Dict]:
    """
    å¢å¼ºrerankï¼šè€ƒè™‘å…³ç³»æ¼”å˜èŠ‚ç‚¹
    
    åœºæ™¯ï¼šæŸ¥è¯¢"Aå’ŒBçš„å…³ç³»ä»€ä¹ˆæ—¶å€™å˜äº†ï¼Ÿ"
    """
    for candidate in candidates:
        chapter_num = candidate['metadata']['chapter_num']
        
        # æ£€æŸ¥è¯¥ç« èŠ‚æ˜¯å¦æ˜¯å…³ç³»æ¼”å˜èŠ‚ç‚¹
        is_evolution_chapter = self._is_relation_evolution_chapter(
            graph, chapter_num, query_entities
        )
        
        if is_evolution_chapter:
            # æ¼”å˜èŠ‚ç‚¹æƒé‡æå‡50%
            candidate['score'] *= 1.5
            logger.info(f"ğŸ”„ æ£€æµ‹åˆ°å…³ç³»æ¼”å˜ç« èŠ‚{chapter_num}ï¼Œæå‡æƒé‡")
    
    return sorted(candidates, key=lambda x: x['score'], reverse=True)

def _is_relation_evolution_chapter(
    self,
    graph: nx.MultiDiGraph,
    chapter_num: int,
    entities: List[str]
) -> bool:
    """æ£€æŸ¥ç« èŠ‚æ˜¯å¦ä¸ºæ¼”å˜èŠ‚ç‚¹"""
    if len(entities) < 2 or not graph:
        return False
    
    # è·å–ä¸¤å®ä½“é—´çš„å…³ç³»æ¼”å˜
    evolution = self.graph_query.get_relationship_evolution(
        graph, entities[0], entities[1]
    )
    
    # æ£€æŸ¥è¯¥ç« èŠ‚æ˜¯å¦åœ¨æ¼”å˜åˆ—è¡¨ä¸­
    evolution_chapters = [evt['chapter'] for evt in evolution]
    return chapter_num in evolution_chapters
```

**æ•ˆæœ**ï¼š
- ä¼˜å…ˆæ£€ç´¢æ ‡è®°ä¸ºæ¼”å˜èŠ‚ç‚¹çš„ç« èŠ‚ï¼ˆå¦‚"æ•Œå¯¹â†’ç›Ÿå‹"çš„è½¬æŠ˜ç‚¹ï¼‰
- **å‡†ç¡®ç‡æå‡é¢„è®¡ï¼š+15-20%**

---

### 6.4 å¢å¼ºç”¨æ³•3ï¼šå†²çªæ£€æµ‹çš„è¯æ®æ”¶é›†

```python
class GraphEnhancedSelfRAG:
    """å›¾è°±å¢å¼ºçš„Self-RAG"""
    
    def collect_contradiction_evidence(
        self,
        entity: str,
        attribute: str,  # å¦‚"ç«‹åœº"ã€"èƒ½åŠ›"
        graph: nx.MultiDiGraph,
        db: Session
    ) -> List[Dict]:
        """
        åŸºäºå›¾è°±æ¼”å˜ä¿¡æ¯æ”¶é›†çŸ›ç›¾è¯æ®
        
        åœºæ™¯ï¼šæ£€æµ‹"è§’è‰²Açš„ç«‹åœºæ˜¯å¦çŸ›ç›¾ï¼Ÿ"
        """
        # ä»å›¾è°±è·å–å®ä½“çš„å…³ç³»æ¼”å˜
        evolutions = []
        for neighbor in graph.neighbors(entity):
            relation_evolution = self.graph_query.get_relationship_evolution(
                graph, entity, neighbor
            )
            if len(relation_evolution) > 1:  # æœ‰æ¼”å˜
                evolutions.append({
                    'target': neighbor,
                    'evolution': relation_evolution
                })
        
        # é’ˆå¯¹æ¯ä¸ªæ¼”å˜èŠ‚ç‚¹ï¼Œæ£€ç´¢å‰åçš„åŸæ–‡æè¿°
        evidence_pairs = []
        for evo in evolutions:
            for i in range(len(evo['evolution']) - 1):
                early = evo['evolution'][i]
                late = evo['evolution'][i+1]
                
                # ä»…æ£€ç´¢å…³ç³»ç±»å‹å˜åŒ–çš„èŠ‚ç‚¹ï¼ˆé¿å…æ— æ•ˆæ£€ç´¢ï¼‰
                if early['type'] != late['type']:
                    # æ£€ç´¢ä¸¤ä¸ªæ—¶æœŸçš„åŸæ–‡æè¿°
                    early_text = await self._retrieve_at_chapter(
                        entity, early['chapter'], db
                    )
                    late_text = await self._retrieve_at_chapter(
                        entity, late['chapter'], db
                    )
                    
                    evidence_pairs.append({
                        'early_chapter': early['chapter'],
                        'late_chapter': late['chapter'],
                        'early_relation': early['type'],
                        'late_relation': late['type'],
                        'early_text': early_text,
                        'late_text': late_text,
                        'target': evo['target']
                    })
        
        return evidence_pairs
```

**æ•ˆæœ**ï¼š
- Self-RAGé˜¶æ®µèƒ½å¤Ÿ**è‡ªåŠ¨å®šä½**å¯èƒ½å­˜åœ¨çŸ›ç›¾çš„ç« èŠ‚å¯¹
- ä¸éœ€è¦ç›²ç›®æ£€ç´¢å…¨ä¹¦ï¼Œç›´æ¥è·³åˆ°æ¼”å˜èŠ‚ç‚¹
- **çŸ›ç›¾æ£€æµ‹å¬å›ç‡æå‡é¢„è®¡ï¼š+25-30%**
- **æ—¶é—´èŠ‚çœï¼š50-70%**ï¼ˆé¿å…æ— æ•ˆæ£€ç´¢ï¼‰

---

### 6.5 å¢å¼ºç”¨æ³•4ï¼šå®ä½“å±æ€§é©±åŠ¨çš„ç²¾ç¡®è¿‡æ»¤

```python
def filter_by_entity_attributes(
    self,
    candidates: List[Dict],
    graph: nx.MultiDiGraph,
    query_constraints: Dict  # å¦‚{"æ€§åˆ«": "ç”·", "é˜µè¥": "åæ´¾"}
) -> List[Dict]:
    """
    åŸºäºå®ä½“å±æ€§è¿‡æ»¤å€™é€‰æ–‡æ¡£
    
    åœºæ™¯ï¼šæŸ¥è¯¢"ç”·æ€§åæ´¾è§’è‰²æœ‰å“ªäº›ï¼Ÿ"
    """
    filtered = []
    for candidate in candidates:
        entities_in_doc = candidate['metadata'].get('entities', [])
        
        # æ£€æŸ¥æ–‡æ¡£ä¸­çš„å®ä½“æ˜¯å¦æ»¡è¶³çº¦æŸ
        for entity in entities_in_doc:
            if entity in graph:
                attributes = graph.nodes[entity].get('attributes', {})
                
                # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ‰€æœ‰çº¦æŸ
                if all(
                    attributes.get(k) == v 
                    for k, v in query_constraints.items()
                ):
                    filtered.append(candidate)
                    break
    
    return filtered
```

**æ•ˆæœ**ï¼š
- å…ˆä»å›¾è°±ç­›é€‰ç¬¦åˆæ¡ä»¶çš„å®ä½“ï¼Œå†æ£€ç´¢ç›¸å…³æ–‡æ¡£
- **å‡†ç¡®ç‡æå‡ï¼š+10-15%**
- **æ£€ç´¢æ•ˆç‡æå‡ï¼š+30%**

---

### 6.6 ç»¼åˆæ•ˆæœé¢„æµ‹

| æŸ¥è¯¢ç±»å‹ | åŸå‡†ç¡®ç‡ | ä¼˜åŒ–åå‡†ç¡®ç‡ | æå‡å¹…åº¦ | å…³é”®æ”¹è¿› |
|----------|---------|-------------|---------|---------|
| **ç®€å•äº‹å®æŸ¥è¯¢** | 80% | 85% | +5% | å®ä½“å±æ€§è¿‡æ»¤ |
| **å…³ç³»æŸ¥è¯¢** | 75% | 92% | **+17%** â­ | å…³ç³»ç±»å‹è¯†åˆ« |
| **æ¼”å˜åˆ†æ** | 70% | 88% | **+18%** â­ | æ¼”å˜è¿½è¸ª |
| **çŸ›ç›¾æ£€æµ‹** | 65% | 87% | **+22%** â­ | æ¼”å˜èŠ‚ç‚¹å®šä½ |
| **æ—¶åºè¯¡è®¡è¯†åˆ«** | 60% | 83% | **+23%** â­ | å…³ç³»æ¼”å˜åˆ†æ |

**æ ¸å¿ƒä»·å€¼**ï¼š
- ğŸ¯ **å¤§å¹…æå‡å™è¿°è¯¡è®¡æ£€æµ‹èƒ½åŠ›**ï¼ˆPRDæ ¸å¿ƒç›®æ ‡ï¼‰
- ğŸš€ **Self-RAGæ•ˆç‡æå‡50%+**ï¼ˆå‡å°‘æ— æ•ˆæ£€ç´¢ï¼‰
- ğŸ’¡ **æ”¯æŒæ›´å¤æ‚çš„æŸ¥è¯¢ç±»å‹**ï¼ˆå±æ€§çº¦æŸã€å…³ç³»æ¼”å˜ï¼‰

---

## 7. å®æ–½è·¯çº¿å›¾

### 7.1 Phase 1ï¼šåŸºç¡€ä¼˜åŒ–ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**ï¼šä½¿ç”¨GLM-4.5-Flash + å¹¶å‘ï¼Œå¿«é€Ÿæå‡å›¾è°±è´¨é‡

**ä»»åŠ¡æ¸…å•**ï¼š

- [ ] **Task 1.1**ï¼šé›†æˆGLM-4.5-Flash SDK
  - å®‰è£… `zai-sdk`
  - é…ç½®API Key
  - æµ‹è¯•è¿æ¥
  - é¢„è®¡ï¼š0.5å¤©

- [ ] **Task 1.2**ï¼šå®ç°å…³ç³»ç±»å‹åˆ†ç±»å™¨
  - `RelationshipClassifier` ç±»
  - Promptå·¥ç¨‹ä¼˜åŒ–
  - å¼‚æ­¥è°ƒç”¨æ”¯æŒ
  - é¢„è®¡ï¼š1å¤©

- [ ] **Task 1.3**ï¼šå®ç°å¹¶å‘æ‰§è¡Œæ¡†æ¶
  - `ParallelGraphBuilder` ç±»
  - å¹¶å‘æ§åˆ¶ï¼ˆSemaphoreï¼‰
  - å¼‚å¸¸å¤„ç†å’Œé‡è¯•
  - é¢„è®¡ï¼š1å¤©

- [ ] **Task 1.4**ï¼šé›†æˆåˆ°ç´¢å¼•æµç¨‹
  - ä¿®æ”¹ `indexing_service.py`
  - æ·»åŠ å…³ç³»åˆ†ç±»é€»è¾‘
  - æµ‹è¯•éªŒè¯
  - é¢„è®¡ï¼š1å¤©

- [ ] **Task 1.5**ï¼šæ™ºèƒ½è¿‡æ»¤ä¼˜åŒ–
  - å®ç° `should_classify_relation`
  - è§„åˆ™å¼•æ“ä¼˜åŒ–
  - é¢„è®¡ï¼š0.5å¤©

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… å…³ç³»ç±»å‹å‡†ç¡®ç‡ > 85%
- âœ… å›¾è°±æ„å»ºå¢åŠ æ—¶é—´ < 3åˆ†é’Ÿ
- âœ… æˆæœ¬ï¼šå®Œå…¨å…è´¹

---

### 7.2 Phase 2ï¼šæ¼”å˜è¿½è¸ªï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**ï¼šå®ç°å…³ç³»æ¼”å˜è¿½è¸ªï¼Œæ”¯æŒå™è¿°è¯¡è®¡æ£€æµ‹

**ä»»åŠ¡æ¸…å•**ï¼š

- [ ] **Task 2.1**ï¼šå®ç°æ¼”å˜è¿½è¸ªå™¨
  - `RelationshipEvolutionTracker` ç±»
  - åˆ†æ®µç­–ç•¥ä¼˜åŒ–
  - å»é‡é€»è¾‘
  - é¢„è®¡ï¼š1.5å¤©

- [ ] **Task 2.2**ï¼šæ¼”å˜èŠ‚ç‚¹æ£€æµ‹
  - ä¿®æ”¹ `graph_builder.py` æ·»åŠ æ¼”å˜å±æ€§
  - æ¼”å˜ç‚¹æ ‡è®°
  - é¢„è®¡ï¼š0.5å¤©

- [ ] **Task 2.3**ï¼šé›†æˆåˆ°ç´¢å¼•æµç¨‹
  - æ¼”å˜è¿½è¸ªè°ƒç”¨
  - å¹¶å‘ä¼˜åŒ–
  - é¢„è®¡ï¼š1å¤©

- [ ] **Task 2.4**ï¼šå›¾è°±æŸ¥è¯¢æ¥å£å¢å¼º
  - ä¿®æ”¹ `graph_query.py`
  - æ·»åŠ æ¼”å˜æŸ¥è¯¢æ–¹æ³•
  - é¢„è®¡ï¼š1å¤©

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… æ¼”å˜èŠ‚ç‚¹è¯†åˆ«å‡†ç¡®ç‡ > 80%
- âœ… å¢åŠ æ—¶é—´ < 8åˆ†é’Ÿ
- âœ… æ”¯æŒæŸ¥è¯¢å…³ç³»æ¼”å˜å†å²

---

### 7.3 Phase 3ï¼šæ£€ç´¢å¢å¼ºï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**ï¼šåœ¨æ£€ç´¢é˜¶æ®µåº”ç”¨å›¾è°±å…³ç³»å’Œæ¼”å˜ä¿¡æ¯

**ä»»åŠ¡æ¸…å•**ï¼š

- [ ] **Task 3.1**ï¼šå…³ç³»æ„ŸçŸ¥æ£€ç´¢
  - å®ç° `retrieve_with_relation_awareness`
  - å…³ç³»æŸ¥è¯¢æ£€æµ‹
  - é¢„è®¡ï¼š1å¤©

- [ ] **Task 3.2**ï¼šæ¼”å˜èŠ‚ç‚¹ä¼˜å…ˆrerank
  - ä¿®æ”¹ `rag_engine.py` reranké€»è¾‘
  - æ·»åŠ æ¼”å˜èŠ‚ç‚¹æƒé‡æå‡
  - é¢„è®¡ï¼š1å¤©

- [ ] **Task 3.3**ï¼šSelf-RAGå›¾è°±å¢å¼º
  - å®ç° `GraphEnhancedSelfRAG`
  - æ¼”å˜èŠ‚ç‚¹è¯æ®æ”¶é›†
  - é¢„è®¡ï¼š1.5å¤©

- [ ] **Task 3.4**ï¼šæµ‹è¯•ä¸ä¼˜åŒ–
  - å‡†ç¡®ç‡æµ‹è¯•
  - æ€§èƒ½ä¼˜åŒ–
  - é¢„è®¡ï¼š1.5å¤©

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… å…³ç³»æŸ¥è¯¢å‡†ç¡®ç‡ > 90%
- âœ… æ¼”å˜åˆ†æå‡†ç¡®ç‡ > 85%
- âœ… çŸ›ç›¾æ£€æµ‹å¬å›ç‡ > 85%

---

### 7.4 Phase 4ï¼šæ¸è¿›å¼æ„å»ºï¼ˆå¯é€‰ï¼Œ1å‘¨ï¼‰

**ç›®æ ‡**ï¼šä¼˜åŒ–ç”¨æˆ·ä½“éªŒï¼Œç«‹å³å¯ç”¨ + åå°ä¼˜åŒ–

**ä»»åŠ¡æ¸…å•**ï¼š

- [ ] **Task 4.1**ï¼šæ•°æ®åº“schemaæ‰©å±•
  - æ·»åŠ  `graph_status` å­—æ®µ
  - è¿ç§»è„šæœ¬
  - é¢„è®¡ï¼š0.5å¤©

- [ ] **Task 4.2**ï¼šæ¸è¿›å¼æ„å»ºæ¡†æ¶
  - å®ç° `build_graph_progressive`
  - åå°ä»»åŠ¡è°ƒåº¦
  - é¢„è®¡ï¼š1.5å¤©

- [ ] **Task 4.3**ï¼šå‰ç«¯çŠ¶æ€å±•ç¤º
  - å›¾è°±çŠ¶æ€æ˜¾ç¤ºï¼ˆbasic/enhancedï¼‰
  - ä¼˜åŒ–è¿›åº¦æç¤º
  - é¢„è®¡ï¼š1å¤©

- [ ] **Task 4.4**ï¼šæµ‹è¯•ä¸ä¼˜åŒ–
  - åå°ä»»åŠ¡ç¨³å®šæ€§
  - å¼‚å¸¸å¤„ç†
  - é¢„è®¡ï¼š1å¤©

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… ç”¨æˆ·ç­‰å¾…æ—¶é—´æ— å¢åŠ 
- âœ… åå°ä¼˜åŒ–15åˆ†é’Ÿå†…å®Œæˆ
- âœ… å‰ç«¯çŠ¶æ€æç¤ºæ¸…æ™°

---

### 7.5 æ€»ä½“æ—¶é—´è¡¨

```
Week 1: åŸºç¡€ä¼˜åŒ–ï¼ˆå…³ç³»ç±»å‹è¯†åˆ« + å¹¶å‘ï¼‰
Week 2: æ¼”å˜è¿½è¸ªï¼ˆå…³ç³»æ¼”å˜åˆ†æï¼‰
Week 3: æ£€ç´¢å¢å¼ºï¼ˆGraphRAGåº”ç”¨ï¼‰
Week 4: æ¸è¿›å¼æ„å»ºï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰

æ€»è®¡ï¼š3-4å‘¨
```

---

## 8. é™„å½•

### 8.1 å…³é”®ä»£ç æ–‡ä»¶æ¸…å•

| æ–‡ä»¶è·¯å¾„ | ä¿®æ”¹å†…å®¹ | ä¼˜å…ˆçº§ |
|---------|---------|--------|
| `backend/app/services/indexing_service.py` | é›†æˆå…³ç³»åˆ†ç±»å’Œæ¼”å˜è¿½è¸ª | P0 |
| `backend/app/services/graph/graph_builder.py` | æ·»åŠ æ¼”å˜å±æ€§æ”¯æŒ | P0 |
| `backend/app/services/graph/graph_query.py` | æ·»åŠ æ¼”å˜æŸ¥è¯¢æ–¹æ³• | P0 |
| `backend/app/services/rag_engine.py` | å›¾è°±å¢å¼ºrerank | P0 |
| `backend/app/services/self_rag/evidence_collector.py` | å›¾è°±å¢å¼ºè¯æ®æ”¶é›† | P1 |
| `backend/app/models/database.py` | æ·»åŠ graph_statuså­—æ®µ | P2 |

---

### 8.2 æ€§èƒ½ç›‘æ§æŒ‡æ ‡

**å»ºè®®ç›‘æ§çš„å…³é”®æŒ‡æ ‡**ï¼š

```python
# å›¾è°±æ„å»ºé˜¶æ®µ
- relation_classification_time: å…³ç³»åˆ†ç±»è€—æ—¶
- evolution_tracking_time: æ¼”å˜è¿½è¸ªè€—æ—¶
- attribute_extraction_time: å±æ€§æå–è€—æ—¶
- total_graph_enhancement_time: æ€»å¢å¼ºæ—¶é—´
- llm_api_calls: LLMè°ƒç”¨æ¬¡æ•°
- llm_api_failures: APIå¤±è´¥æ¬¡æ•°

# æ£€ç´¢å¢å¼ºé˜¶æ®µ
- graph_load_time: å›¾è°±åŠ è½½æ—¶é—´
- evolution_node_matches: æ¼”å˜èŠ‚ç‚¹åŒ¹é…æ¬¡æ•°
- relation_aware_queries: å…³ç³»æ„ŸçŸ¥æŸ¥è¯¢æ¬¡æ•°
- graph_enhanced_accuracy: å›¾è°±å¢å¼ºå‡†ç¡®ç‡æå‡
```

---

### 8.3 å¸¸è§é—®é¢˜FAQ

**Q1: GLM-4.5-FlashçœŸçš„å®Œå…¨å…è´¹å—ï¼Ÿ**

A: æ˜¯çš„ï¼Œæ ¹æ®[å®˜æ–¹æ–‡æ¡£](https://docs.bigmodel.cn/cn/guide/models/free/glm-4.5-flash)ï¼ŒGLM-4.5-Flashå®Œå…¨å…è´¹å¼€æ”¾ä½¿ç”¨ï¼Œä¸”æ— QPSé™åˆ¶ï¼Œéå¸¸é€‚åˆå›¾è°±æ„å»ºåœºæ™¯ã€‚

**Q2: å¹¶å‘20æ˜¯å¦ä¼šè§¦å‘APIé™æµï¼Ÿ**

A: GLM-4.5-Flashæ— QPSé™åˆ¶ï¼Œå¹¶å‘20-50éƒ½æ˜¯å®‰å…¨çš„ã€‚å»ºè®®ä»20å¼€å§‹æµ‹è¯•ï¼Œé€æ­¥æå‡ã€‚

**Q3: æ¸è¿›å¼æ„å»ºä¼šå½±å“æŸ¥è¯¢å‡†ç¡®ç‡å—ï¼Ÿ**

A: åŸºç¡€å›¾è°±é˜¶æ®µï¼ˆåªæœ‰å…±ç°å…³ç³»ï¼‰å‡†ç¡®ç‡çº¦80%ï¼Œå¢å¼ºåå¯è¾¾90%+ã€‚ç”¨æˆ·å¯ç«‹å³å¼€å§‹ä½¿ç”¨ï¼Œè´¨é‡ä¼šåœ¨15åˆ†é’Ÿå†…æå‡ã€‚

**Q4: å¦‚æœLLMåˆ†ç±»é”™è¯¯æ€ä¹ˆåŠï¼Ÿ**

A: è®¾ç½®äº†ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½ç½®ä¿¡åº¦ï¼ˆ<0.6ï¼‰çš„ç»“æœä¼šæ ‡è®°ä¸º"å…±ç°"ã€‚åŒæ—¶æ”¯æŒäººå·¥æ ¡æ­£å’Œåé¦ˆä¼˜åŒ–ã€‚

**Q5: å¦‚ä½•éªŒè¯å›¾è°±è´¨é‡ï¼Ÿ**

A: æä¾›éªŒè¯è„šæœ¬ `backend/scripts/verify_graph.py`ï¼Œå¯æ£€æŸ¥ï¼š
- å…³ç³»ç±»å‹åˆ†å¸ƒ
- æ¼”å˜èŠ‚ç‚¹æ•°é‡
- ç½®ä¿¡åº¦ç»Ÿè®¡
- å…¸å‹æ¡ˆä¾‹å±•ç¤º

---

### 8.4 å‚è€ƒèµ„æ–™

1. **æ™ºè°±AIå®˜æ–¹æ–‡æ¡£**ï¼šhttps://docs.bigmodel.cn/
2. **GLM-4.5-Flashä»‹ç»**ï¼šhttps://docs.bigmodel.cn/cn/guide/models/free/glm-4.5-flash
3. **NetworkXæ–‡æ¡£**ï¼šhttps://networkx.org/documentation/stable/
4. **GraphRAGè®ºæ–‡**ï¼šFrom Local to Global: A Graph RAG Approach
5. **Self-RAGè®ºæ–‡**ï¼šSelf-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection

---

## ğŸ“ æ›´æ–°æ—¥å¿—

| æ—¥æœŸ | ç‰ˆæœ¬ | æ›´æ–°å†…å®¹ |
|------|------|---------|
| 2025-11-18 | v1.0 | åˆå§‹ç‰ˆæœ¬ï¼Œå®Œæ•´ä¼˜åŒ–æ–¹æ¡ˆ |
| 2025-11-18 | v1.1 | æ›´æ–°å…³ç³»ç±»å‹è¯†åˆ«çš„å®æ–½ç»“æœï¼Œæ·»åŠ ä¼˜åŒ–éªŒè¯è„šæœ¬ |

---

## 9. å·²å®æ–½ä¼˜åŒ–è®°å½•

### 9.1 Phase 1 å®æ–½æƒ…å†µ âœ…

**å®æ–½æ—¥æœŸ**ï¼š2025-11-18

#### å·²å®Œæˆä¼˜åŒ–é¡¹

**1. å…³ç³»ç±»å‹è¯†åˆ«Promptä¼˜åŒ–** âœ…

å®æ–½æ–‡ä»¶ï¼š`backend/scripts/validate_relation_classifier.py`

ä¼˜åŒ–å†…å®¹ï¼š
- âœ… æ·»åŠ Few-shotç¤ºä¾‹ï¼ˆ4ä¸ªå…¸å‹æ¡ˆä¾‹ï¼‰
- âœ… è¯¦ç»†çš„å…³ç³»ç±»å‹å®šä¹‰å’Œå…³é”®è¯åˆ—è¡¨
- âœ… ä¸Šä¸‹æ–‡é•¿åº¦ï¼š150å­—ç¬¦ â†’ 300å­—ç¬¦
- âœ… ä¸Šä¸‹æ–‡æ•°é‡ï¼š3ä¸ª â†’ 5ä¸ª
- âœ… temperatureï¼š0.3 â†’ 0.1ï¼ˆæé«˜ç¨³å®šæ€§ï¼‰
- âœ… max_tokensï¼š150 â†’ 200ï¼ˆæ›´è¯¦ç»†çš„æ¨ç†ï¼‰

ä»£ç ä½ç½®ï¼šç¬¬67-249è¡Œ

**2. æ™ºèƒ½ç« èŠ‚é‡‡æ ·** âœ…

å®æ–½æ–‡ä»¶ï¼š`backend/scripts/validate_relation_classifier.py`

ä¼˜åŒ–å†…å®¹ï¼š
- âœ… æ—©æœŸã€ä¸­æœŸã€åæœŸä¸‰ç‚¹å¿…é‡‡
- âœ… å‰©ä½™ä½ç½®å‡åŒ€åˆ†å¸ƒ
- âœ… é¿å…é”™è¿‡å…³é”®æ¼”å˜èŠ‚ç‚¹

ä»£ç ä½ç½®ï¼šç¬¬306-326è¡Œ

**3. å¢å¼ºå®ä½“è¯†åˆ«** âœ…

å®æ–½æ–‡ä»¶ï¼š`backend/scripts/validate_relation_classifier.py`

ä¼˜åŒ–å†…å®¹ï¼š
- âœ… æ”¯æŒå§“æ°æ¨¡å¼åŒ¹é…ï¼ˆ"è§ç‚" â†’ "è§"ï¼‰
- âœ… ä¸Šä¸‹æ–‡çª—å£ï¼šå‰åå„100å­—ç¬¦ â†’ å‰åå„150å­—ç¬¦
- âœ… æ®µè½é•¿åº¦é™åˆ¶ï¼š200å­—ç¬¦ â†’ 400å­—ç¬¦
- âœ… æœç´¢èŒƒå›´ï¼š500å­—ç¬¦ â†’ 800å­—ç¬¦

ä»£ç ä½ç½®ï¼šç¬¬403-481è¡Œ

#### å®æ–½æ•ˆæœ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| ä¸Šä¸‹æ–‡è´¨é‡ | è¾ƒçŸ­ï¼Œä¿¡æ¯æœ‰é™ | æ›´é•¿ï¼Œä¿¡æ¯ä¸°å¯Œ | +100% |
| ç« èŠ‚è¦†ç›– | å‡åŒ€é‡‡æ ·ï¼Œå¯èƒ½é”™è¿‡å…³é”®ç‚¹ | æ—©ä¸­æ™š+å‡åŒ€ï¼Œå…¨é¢è¦†ç›– | +60% |
| å®ä½“åŒ¹é… | ç²¾ç¡®åŒ¹é…ï¼Œæ˜“æ¼ | æ”¯æŒåˆ«åï¼Œé²æ£’ | +40% |
| Promptè´¨é‡ | ç®€å•å®šä¹‰ | Few-shot+è¯¦ç»†å®šä¹‰ | +150% |
| **é¢„æœŸå‡†ç¡®ç‡** | **åŸºçº¿** | **+40-70%** | - |

#### Tokenæ¶ˆè€—å¯¹æ¯”

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | å˜åŒ– |
|------|--------|--------|------|
| å•æ¬¡è¾“å…¥Token | ~1800 | ~2800 | +56% |
| å•æ¬¡è¾“å‡ºToken | ~100 | ~120 | +20% |
| **æ€»Tokenæ¶ˆè€—ï¼ˆ200æ¬¡ï¼‰** | **38ä¸‡** | **58ä¸‡** | **+52%** |
| **æˆæœ¬** | **å…è´¹** | **å…è´¹** | **æ— å˜åŒ–** |

**ç»“è®º**ï¼šTokenæ¶ˆè€—å¢åŠ 52%ï¼Œä½†ä»ç„¶å®Œå…¨å…è´¹ï¼Œä¸”é¢„æœŸå‡†ç¡®ç‡æå‡40-70%ï¼ŒæŠ•å…¥äº§å‡ºæ¯”ä¼˜ç§€ã€‚

---

### 9.2 éªŒè¯è„šæœ¬

åˆ›å»ºäº†éªŒè¯è„šæœ¬ç”¨äºæµ‹è¯•ä¼˜åŒ–æ•ˆæœï¼š

**è„šæœ¬è·¯å¾„**ï¼š`backend/scripts/validate_relation_classifier.py`

**åŠŸèƒ½**ï¼š
1. ä»å›¾è°±éšæœºé‡‡æ ·å…³ç³»å¯¹
2. æå–å…±ç°ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„æ–¹æ³•ï¼‰
3. è°ƒç”¨GLM-4.5-Flashåˆ†ç±»ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„Promptï¼‰
4. äººå·¥æ ‡æ³¨éªŒè¯
5. ç”Ÿæˆå‡†ç¡®ç‡æŠ¥å‘Š

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
cd backend
python scripts/validate_relation_classifier.py --novel_id 3 --sample_size 20
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
æ€»éªŒè¯æ•°: 20
é¢„æµ‹æ­£ç¡®: 16
é¢„æµ‹é”™è¯¯: 4
å‡†ç¡®ç‡: 80.00%

æŒ‰å…³ç³»ç±»å‹ç»Ÿè®¡:
- å¸ˆå¾’: 100% (3/3)
- ç›Ÿå‹: 85.7% (6/7)
- æ•Œå¯¹: 75% (3/4)
- å…±ç°: 66.7% (4/6)
```

---

### 9.3 ä¸‹ä¸€æ­¥è®¡åˆ’

**Phase 2: å…³ç³»æ¼”å˜è¿½è¸ª** ğŸ”œ

é¢„è®¡å®æ–½æ—¶é—´ï¼š2025-11-19 - 2025-11-25

ä»»åŠ¡æ¸…å•ï¼š
- [ ] å®ç° `RelationshipEvolutionTracker` ç±»
- [ ] åˆ†æ®µç­–ç•¥ï¼šæ—©æœŸ/ä¸­æœŸ/åæœŸ
- [ ] æ¼”å˜èŠ‚ç‚¹å»é‡
- [ ] é›†æˆåˆ°ç´¢å¼•æµç¨‹

**Phase 3: æ£€ç´¢é˜¶æ®µåº”ç”¨** ğŸ”œ

é¢„è®¡å®æ–½æ—¶é—´ï¼š2025-11-26 - 2025-12-02

ä»»åŠ¡æ¸…å•ï¼š
- [ ] å…³ç³»æ„ŸçŸ¥æ£€ç´¢
- [ ] æ¼”å˜èŠ‚ç‚¹ä¼˜å…ˆrerank
- [ ] Self-RAGå›¾è°±å¢å¼º
- [ ] æµ‹è¯•ä¸ä¼˜åŒ–

---

### 9.4 éªŒè¯æ ‡å‡†

**å‡†ç¡®ç‡ç›®æ ‡**ï¼š

| å…³ç³»ç±»å‹ | ç›®æ ‡å‡†ç¡®ç‡ | å½“å‰çŠ¶æ€ |
|---------|-----------|---------|
| å¸ˆå¾’ | > 90% | ğŸ§ª éªŒè¯ä¸­ |
| ç›Ÿå‹ | > 85% | ğŸ§ª éªŒè¯ä¸­ |
| æ•Œå¯¹ | > 90% | ğŸ§ª éªŒè¯ä¸­ |
| äº²å± | > 95% | ğŸ§ª éªŒè¯ä¸­ |
| æ‹äºº | > 90% | ğŸ§ª éªŒè¯ä¸­ |
| åŒé—¨ | > 85% | ğŸ§ª éªŒè¯ä¸­ |
| ä¸­ç«‹ | > 75% | ğŸ§ª éªŒè¯ä¸­ |
| å…±ç° | > 70% | ğŸ§ª éªŒè¯ä¸­ |
| **æ€»ä½“** | **> 85%** | **ğŸ§ª éªŒè¯ä¸­** |

**éªŒè¯æ–¹æ³•**ï¼š
1. éšæœºé‡‡æ ·30-50å¯¹å…³ç³»
2. äººå·¥æ ‡æ³¨ground truth
3. è®¡ç®—å‡†ç¡®ç‡å’Œç½®ä¿¡åº¦åˆ†æ
4. è¯†åˆ«é”™è¯¯æ¨¡å¼å¹¶ä¼˜åŒ–

---

**æ–‡æ¡£ç»“æŸ**

