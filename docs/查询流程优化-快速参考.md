# 查询流程优化 - 快速参考

## 🔄 当前流程概览

```
查询理解 → 向量检索 → 重排序(GraphRAG) → Prompt构建 → LLM生成 → Self-RAG验证
   ↓          ↓           ↓                ↓            ↓             ↓
 分类查询   Top-30    +图谱权重        限制块数     流式输出      矛盾检测
  类型              +类型适配       +类型模板                    +答案修正
```

## 📊 可配置参数速查

| 参数 | 作用 | 常规模式 | 高精度模式 | 影响 |
|------|------|----------|------------|------|
| `top_k_retrieval` | 初始检索数量 | 30 | 100 | 召回率↑ 速度↓ |
| `top_k_rerank` | 重排后保留 | 10 | 30 | 精度↑ 成本↑ |
| `max_context_chunks` | 上下文块数 | 10 | 20 | 完整性↑ 成本↑↑ |

## 🎯 Top 5 优化建议

### 1. 自适应Prompt模板 ⭐⭐⭐⭐⭐
**预期提升**：+10-15% 准确性  
**额外成本**：0%  
**实现难度**：低

针对不同查询类型（对话/分析/事实）定制Prompt：
- 对话类：强调引用原文
- 分析类：引导逻辑推理（思维链）
- 事实类：强调准确性

### 2. 混合检索（Semantic + BM25） ⭐⭐⭐⭐⭐
**预期提升**：+10-15% 召回率  
**额外成本**：+20%  
**实现难度**：中

结合语义相似度和关键词精确匹配：
```
最终分数 = 0.7 × 语义分数 + 0.3 × BM25分数
```

### 3. Cross-Encoder精排 ⭐⭐⭐⭐⭐
**预期提升**：+15-20% 精度  
**额外成本**：+30%  
**实现难度**：中

使用更强的模型（如bge-reranker-v2-m3）重排序，替代当前的简单权重策略。

### 4. 查询改写 ⭐⭐⭐⭐
**预期提升**：+5-10% 召回率  
**额外成本**：+5%  
**实现难度**：低

将模糊查询转换为精确查询：
```
原始："张无忌和赵敏怎么在一起的？"
改写："张无忌与赵敏初次相遇、感情发展、确立关系的过程"
```

### 5. 并行化Self-RAG ⭐⭐⭐⭐
**预期提升**：速度提升50%  
**额外成本**：0%  
**实现难度**：中

并行执行断言提取、证据收集、一致性检查等步骤。

## 🚀 快速实施路线

### Week 1-2（零成本优化）
- [ ] 自适应Prompt模板（3个模板）
- [ ] 查询改写（调用GLM-4-Flash）
- [ ] 优化参数默认值

### Week 3-4（核心增强）
- [ ] 混合检索（集成BM25）
- [ ] Cross-Encoder精排（集成bge-reranker）
- [ ] 并行化Self-RAG

### Week 5-8（高级特性）
- [ ] 迭代式检索（多轮检索-推理）
- [ ] 查询路由（简单/中等/复杂）
- [ ] 答案融合（多候选）

## 💡 调参建议

### 场景1：速度优先（在线客服）
```python
top_k_retrieval = 20
top_k_rerank = 5
max_context_chunks = 5
enable_self_rag = False  # 跳过验证
```

### 场景2：平衡模式（默认）
```python
top_k_retrieval = 30
top_k_rerank = 10
max_context_chunks = 10
enable_self_rag = True
```

### 场景3：精度优先（研究分析）
```python
top_k_retrieval = 100
top_k_rerank = 30
max_context_chunks = 20
enable_self_rag = True
enable_iterative_retrieval = True  # 新功能
```

## 📈 预期效果对比

| 指标 | 当前系统 | +基础优化 | +核心增强 | +高级特性 |
|------|---------|----------|----------|----------|
| 准确率 | 70% | 75% | 85% | 90% |
| 召回率 | 60% | 70% | 80% | 85% |
| 平均响应时间 | 8s | 6s | 7s | 12s |
| Token成本 | 100% | 105% | 130% | 250% |

---

**结论**：优先实施"自适应Prompt"和"混合检索"，可在最小成本下获得显著提升（准确率+15%）。

